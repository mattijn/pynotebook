{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 07 10:35:29 2016\n",
    "\n",
    "@author: Job Verkaik, Mattijn van Hoek, HKV Lijn in water\n",
    "\"\"\"\n",
    "from os.path import isdir\n",
    "#rom fewslogger import Logger\n",
    "import datetime\n",
    "import pytz\n",
    "import sys, getopt, shutil\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "#Functions \n",
    "#=======================================================================================\n",
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "def writeState(state_config_read, state_config_write, stateTime):\n",
    "    \"\"\"\n",
    "    stateFile  ::  absolute path to write xml file\n",
    "    stateTime  ::  in 'yyyy-mm-dd' format\n",
    "    \"\"\"\n",
    "    eTree = ElementTree.parse(state_config_read).getroot()\n",
    "    # start xml\n",
    "    xml = Element('State')\n",
    "    xml.set('xmlns','http://www.wldelft.nl/fews')\n",
    "    xml.set('xmlns:xsi','http://www.w3.org/2001/XMLSchema-instance')\n",
    "    xml.set('xsi:schemaLocation','http://www.wldelft.nl/fews/PI http://fews.wldelft.nl/schemas/version1.0/pi-schemas/pi_state.xsd')\n",
    "    xml.set('version','1.2')\n",
    "\n",
    "    stateID = SubElement(xml,'stateId').text = eTree[0].text\n",
    "    timeZone = SubElement(xml,'timeZone').text = eTree[1].text\n",
    "    dateTime = SubElement(xml,'dateTime')\n",
    "    dateTime.set('date',stateTime)\n",
    "    dateTime.set('time',eTree[2].attrib.get('time'))\n",
    "    stateLoc = SubElement(xml,'stateLoc')\n",
    "    stateLoc.set('type','file')\n",
    "    readLocation = SubElement(stateLoc, 'readLocation').text = eTree[3][0].text\n",
    "    writeLocation = SubElement(stateLoc, 'writeLocation').text = eTree[3][1].text\n",
    "\n",
    "    # save xml to file\n",
    "    with open(state_config_write, 'w') as the_file:\n",
    "        the_file.write(prettify(xml))   \n",
    "\n",
    "def createNETCDF(filename, in_nc_arr=\"\", STATE_COPY_CREATE=0, TIME_LIST=[], HM_ARRAY=[], fillValue = -999.0, state_config_read=\"exportStateConfig.xml\", state_config_write=\"importStateConfig.xml\"):\n",
    "    \"\"\"\n",
    "    filename           ::  path to new NETCDF file\n",
    "    in_nc_arr          ::  base NETCDF file\n",
    "    STATE_COPY_CREATE  ::  set 0 for state\n",
    "                           set 1 for copy\n",
    "                           set 2 for create\n",
    "    TIME_LIST          ::  when creating, provide datetime array with dates\n",
    "    HM_ARRAY           ::  provide array with h.m data to create NETCDF\n",
    "    fillValue          ::  only used during creation [default: -999.0]\n",
    "    stateConfigFile    ::  only used for writing state files [default: \"%s/importStateConfig.xml\" % statedir]    \n",
    "    \"\"\"\n",
    "    # 0 is TimeSeriesSet STATE FILE\n",
    "    # 1 is TimeSeriesSet COPY\n",
    "    # 2 is TimeSeriesSet CREATE\n",
    "    # ------------------------------------------            \n",
    "    # create new warmState\n",
    "    # create new.nc url and open file to write\n",
    "    new_nc = filename\n",
    "    nc_new = netCDF4.Dataset(new_nc, 'w', format=\"NETCDF3_CLASSIC\")\n",
    "\n",
    "    # create dimensions for new nc file based on in.nc\n",
    "    if STATE_COPY_CREATE == 0 :\n",
    "        nt = 1\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        nt = in_nc_arr.dimensions['time'].size\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        nt = len(TIME_LIST)        \n",
    "    ny = in_nc_arr.dimensions['y'].size\n",
    "    nx = in_nc_arr.dimensions['x'].size\n",
    "    nc_new.createDimension('time', nt)\n",
    "    nc_new.createDimension('y', ny)\n",
    "    nc_new.createDimension('x', nx)\n",
    "\n",
    "    # copy over time variable from in.nc [only first slice]\n",
    "    time_innc = in_nc_arr.variables['time']\n",
    "    time = nc_new.createVariable('time', 'f8', ('time',))\n",
    "    if STATE_COPY_CREATE == 0:\n",
    "        new = time_innc[-1]\n",
    "\n",
    "        new_min = new * 60\n",
    "        new_date = datetime.datetime.fromtimestamp(new_min)#.strftime('%Y-%m-%d')    \n",
    "        new_date = datetime.datetime(*new_date.timetuple()[:3]) #+ datetime.timedelta(hours=1)\n",
    "\n",
    "        up_dateISO = new_date - datetime.timedelta(days=30)\n",
    "        # write new stateConfig File with gud warmState date\n",
    "        writeState(state_config_read, state_config_write, stateTime=up_dateISO.strftime('%Y-%m-%d'))\n",
    "        up_dateEPOCH = datetime.datetime.timestamp(up_dateISO)\n",
    "        #print(3,\"This is updateDepth.py: warmStateTime in ISO: \"+str(up_date))\n",
    "        up_min = up_dateEPOCH / 60           \n",
    "        time[:] = up_min #time_innc[-1]\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        time[:] = time_innc[:]\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        time[:] = TIME_LIST\n",
    "#     ws_epoch_min = time_innc[-1] * 60\n",
    "#     ws_datetime = datetime.datetime.fromtimestamp(ws_epoch_min).strftime('%Y-%m-%d')\n",
    "#     print(3,\"This is updateDepth.py: warmStateTime in datetime: \"+str(ws_datetime))\n",
    "    time.standard_name = time_innc.standard_name\n",
    "    time.long_name = time_innc.long_name\n",
    "    time.units = time_innc.units\n",
    "    time.axis = time_innc.axis\n",
    "\n",
    "    # copy over y variable from in.nc\n",
    "    y_innc = in_nc_arr.variables['y']\n",
    "    y = nc_new.createVariable('y', 'f8', ('y',), fill_value = y_innc._FillValue ) \n",
    "    y[:] = y_innc[:]\n",
    "    y.standard_name = y_innc.standard_name\n",
    "    y.long_name = y_innc.long_name\n",
    "    y.units = y_innc.units\n",
    "    y.axis = y_innc.axis\n",
    "\n",
    "    # copy over x variable from in.nc\n",
    "    x_innc = in_nc_arr.variables['x']\n",
    "    x = nc_new.createVariable('x', 'f8', ('x'), fill_value = x_innc._FillValue)\n",
    "    x[:] = x_innc[:]\n",
    "    x.standard_name = x_innc.standard_name\n",
    "    x.long_name = x_innc.long_name\n",
    "    x.units = x_innc.units\n",
    "    x.axis = x_innc.axis\n",
    "\n",
    "    # copy over z variable from in.nc\n",
    "    z_innc = in_nc_arr.variables['z']\n",
    "    z = nc_new.createVariable('z', 'f8', ('y', 'x'), fill_value = z_innc._FillValue)\n",
    "    z[:] = z_innc[:]\n",
    "    z.long_name = z_innc.long_name\n",
    "    z.units = z_innc.units\n",
    "    z.axis = z_innc.axis\n",
    "    try:\n",
    "        z.postive = z_innc.positive\n",
    "    except:\n",
    "        l = 1\n",
    "\n",
    "    # copy over lat variable from in.nc\n",
    "    lat_innc = in_nc_arr.variables['lat']\n",
    "    lat = nc_new.createVariable('lat', 'f8', ('y', 'x'), fill_value = lat_innc._FillValue)\n",
    "    lat[:] = lat_innc[:]\n",
    "    lat.standard_name = lat_innc.standard_name\n",
    "    lat.long_name = lat_innc.long_name\n",
    "    lat.units = lat_innc.units\n",
    "\n",
    "    # copy over lat variable from in.nc\n",
    "    lon_innc = in_nc_arr.variables['lon']\n",
    "    lon = nc_new.createVariable('lon', 'f8', ('y', 'x'), fill_value = lon_innc._FillValue)\n",
    "    lon[:] = lon_innc[:]\n",
    "    lon.standard_name = lon_innc.standard_name\n",
    "    lon.long_name = lon_innc.long_name\n",
    "    lon.units = lon_innc.units\n",
    "\n",
    "    # copy over crs variable from in.nc\n",
    "    crs_innc = in_nc_arr.variables['crs']\n",
    "    crs = nc_new.createVariable('crs', 'i4', ())\n",
    "    crs.long_name = crs_innc.long_name\n",
    "    crs.crs_wkt = crs_innc.crs_wkt\n",
    "    crs.proj4_params = crs_innc.proj4_params\n",
    "    crs.epsg_code = crs_innc.epsg_code\n",
    "\n",
    "    # copy over HM variable from in.nc [only first slice]\n",
    "    HM_innc = in_nc_arr.variables['HM']\n",
    "    if STATE_COPY_CREATE == 0:\n",
    "        noDataVal = HM_innc._FillValue\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        noDataVal = HM_innc._FillValue\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        noDataVal = fillValue\n",
    "    HM = nc_new.createVariable('HM', 'f8', ('time', 'y', 'x'), fill_value = noDataVal)\n",
    "    HM[:] = HM_ARRAY[:]\n",
    "    #HM[:] = hm_out[:]\n",
    "    HM.long_name = HM_innc.long_name\n",
    "    HM.units = HM_innc.units\n",
    "    HM.coordinates = HM_innc.coordinates\n",
    "    HM.grid_mapping = HM_innc.grid_mapping\n",
    "\n",
    "    #close newly created warmState nc file\n",
    "    nc_new.close()        \n",
    "#=======================================================================================\n",
    "\n",
    "# MAIN PROGRAM  \n",
    "def main(argv):\n",
    "#     # input argument checking\n",
    "#     try:\n",
    "#         opts, args = getopt.getopt(argv,\"hi:o:s:r:\",[\"ipath=\",\"spath=\",\"opath=\",\"rpath=\"])\n",
    "#     except getopt.GetoptError:\n",
    "#         print ('usage: updateDepth.py -i <inputdir> -s <statedir> -o <outputdir> -r <runfiledir>')\n",
    "#         sys.exit(2)\n",
    "#     for opt, arg in opts:\n",
    "#         if opt == '-h':\n",
    "#             print ('updateDepth.py -i <inputdir> -s <statedir> -o <outputdir> -r <runfiledir>')\n",
    "#             sys.exit()\n",
    "#         elif opt in (\"-i\", \"--inputdir\"):\n",
    "#             inputdir = arg\n",
    "#         elif opt in (\"-s\", \"--statedir\"):\n",
    "#             statedir = arg\n",
    "#         elif opt in (\"-o\", \"--outputdir\"):\n",
    "#             outputdir = arg\n",
    "#         elif opt in (\"-r\", \"--runfiledir\"):\n",
    "#             runfiledir = arg            \n",
    "\n",
    "#     diagnosticsfile = \"diagnostics.xml\"\n",
    "#     log = Logger(diagnosticsfile)\n",
    "#     print(3,\"This is updateDepth.py: doe iets slims; M. van Hoek &amp; J. Verkaik, HKV Lijn in water\")\n",
    "#     print(4,\"Inputdir: %s\" % inputdir)\n",
    "#     print(4,\"Statedir: %s\" % statedir)\n",
    "#     print(4,\"Outputdir: %s\" % outputdir)\n",
    "#     print(4,\"Runfiledir: %s\" % runfiledir)    \n",
    "#     print(4,\"Diagnosticsfile: %s\" % diagnosticsfile)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        # DOE IETS SLIMS VANAF HIER\n",
    "        \n",
    "        #shutil.copyfile(\"%s/in.nc\" % inputdir, \"%s/out.nc\" % outputdir)\n",
    "        \n",
    "        # load input netcdf and state netcdf\n",
    "        in_nc = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\input//in.nc'\n",
    "        state_nc = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\state//state.nc'\n",
    "        out_nc = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\output//out.nc'\n",
    "        statedir = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\state'\n",
    "\n",
    "#         in_nc = \"%s/in.nc\" % inputdir\n",
    "#         state_nc = \"%s/state.nc\" % statedir\n",
    "#         out_nc = \"%s/out.nc\" % outputdir\n",
    "        state_config_read = \"%s/exportStateConfig.xml\" % statedir\n",
    "        state_config_write = \"%s/importStateConfig.xml\" % statedir        \n",
    "\n",
    "        in_nc_arr = netCDF4.Dataset(in_nc, )\n",
    "        state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "        print(in_nc_arr)\n",
    "\n",
    "        # print(in_nc_arr.variables.keys()) # get all variable names\n",
    "        hm = in_nc_arr.variables['HM']  # bodemhoogte peiling\n",
    "        hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "        hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "        cs_epoch_min = hm_state_time[0] * 60\n",
    "        cs_datetime = datetime.datetime.fromtimestamp(cs_epoch_min).strftime('%Y-%m-%d')        \n",
    "        print(3,\"This is updateDepth.py: coldStateTime in ms since epoch: \"+str(cs_datetime))\n",
    "\n",
    "        # create copy in.nc\n",
    "        hm_copy = np.copy(hm)\n",
    "        hm_copy = np.ma.masked_equal(hm_copy, -999.)\n",
    "        \n",
    "        # create deep copy in.nc\n",
    "        hm_deep_copy = np.full(hm.shape, -999.)\n",
    "        hm_deep_copy = np.ma.masked_equal(hm_deep_copy, -999.)       \n",
    "\n",
    "        # use coldState to update first slice in.nc\n",
    "        a = hm[0,::] \n",
    "        b = hm_state[0,::]\n",
    "        # update first slice based on coldState\n",
    "        a[~b.mask] = b.compressed()\n",
    "        hm_copy[0,::] = a\n",
    "        hm_deep_copy[0,::] = np.ma.copy(a)\n",
    "\n",
    "        # create init warmState\n",
    "        hm_out = np.ma.copy(hm_copy[0,::])\n",
    "\n",
    "        for ix in range(hm.shape[0] - 1):    \n",
    "            # print (ix)\n",
    "            # one by one fill/update and ammend arrays\n",
    "            # get first slice of copy, get second slice of original\n",
    "            a = hm_copy[ix,::] \n",
    "            b = np.ma.masked_equal(hm[ix+1,::], -999.)\n",
    "\n",
    "            # update first slice based on second slice\n",
    "            # catch if b contains no masked data\n",
    "            try:\n",
    "                a[~b.mask] = b.compressed()\n",
    "            except:\n",
    "                if b.mask == False:\n",
    "                    a = b\n",
    "            # update timeSeriesSet\n",
    "            hm_copy[ix+1,::] = a\n",
    "            hm_deep_copy[ix+1,::] = np.ma.copy(a)\n",
    "\n",
    "            # update warmState\n",
    "            # hm_out[~a.mask] = a.compressed() \n",
    "\n",
    "    \n",
    "        # update warmState based on T0 minus 30 days\n",
    "        warmStateIx = hm_deep_copy.shape[0] - 30\n",
    "        hm_out = hm_deep_copy[warmStateIx,::]\n",
    "\n",
    "        # ------------------------------------------            \n",
    "        # create new warmState\n",
    "        # create NETCDF file for new timeSeriesSet        \n",
    "        createNETCDF(state_nc, in_nc_arr = in_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = hm_out, state_config_read=state_config_read, state_config_write=state_config_write)\n",
    " \n",
    "\n",
    "        # ------------------------------------------\n",
    "        # create out.nc timeSeriesSet\n",
    "        # create new.nc url and open file to write\n",
    "        createNETCDF(out_nc, in_nc_arr = in_nc_arr, STATE_COPY_CREATE = 1, HM_ARRAY = hm_deep_copy )\n",
    "\n",
    "        \n",
    "    except:\n",
    "        try:        \n",
    "#             state_nc = \"%s/state.nc\" % statedir\n",
    "#             runfile_xml = \"%s/runfile.xml\" % runfiledir\n",
    "\n",
    "            state_nc = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\state//state.nc'\n",
    "            runfile_xml = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\runfile//runfile.xml'\n",
    "            out_nc = r'D:\\Projects\\Pr\\3317.30\\depthUpdate_fixTimezone\\depthUpdate\\output//out.nc'\n",
    "        \n",
    "            state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "            state_config_read = \"%s/exportStateConfig.xml\" % statedir\n",
    "            state_config_write = \"%s/importStateConfig.xml\" % statedir                        \n",
    "            \n",
    "            hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "            hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "            cs_epoch_min = hm_state_time[0] * 60\n",
    "            cs_date = datetime.datetime.fromtimestamp(cs_epoch_min)#.strftime('%Y-%m-%d')    \n",
    "            cs_date = datetime.datetime(*cs_date.timetuple()[:3]) #+ datetime.timedelta(hours=1)\n",
    "            print(3,\"This is updateDepth.py: date coldState runfile: \"+str(cs_date))\n",
    "\n",
    "            # open runfile.xml and get time0 date in datetime format\n",
    "            e = ElementTree.parse(runfile_xml).getroot()\n",
    "            time0 = e[3].attrib.get('date') # e[3] is time0 in xml file\n",
    "            # get timezone element as integer\n",
    "            timezone=int(float(e[0].text))\n",
    "            \n",
    "            # get t0 element as datetime object\n",
    "            time0_date = e[3].attrib.get('date') # e[3] is time0 in xml file\n",
    "            time0_date_list = time0_date.replace('-', ' ').split(' ')\n",
    "            time0_time = e[3].attrib.get('time')\n",
    "            time0_time_list = time0_time.replace(':', ' ').split(' ')\n",
    "            time0_dt = datetime.datetime(int(time0_date_list[0]), # year\n",
    "                                         int(time0_date_list[1]), # month\n",
    "                                         int(time0_date_list[2]), # day                                \n",
    "                                         int(time0_time_list[0]), # hour\n",
    "                                         int(time0_time_list[1]), # minute\n",
    "                                         int(time0_time_list[2]), # second\n",
    "                                         ) \n",
    "            time0_dt = time0_dt + datetime.timedelta(hours=timezone)\n",
    "            time0_dt = datetime.datetime(*time0_dt.timetuple()[:3]) #+ datetime.timedelta(hours=1)            \n",
    "            #set_trace()\n",
    "            #print(3,\"This is updateDepth.py: date time0_date runfile: \"+str(time0_dt)) \n",
    "\n",
    "            # get new datelist in MINUTES since epoch\n",
    "            numdays = time0_dt - cs_date\n",
    "            datesISO = [time0_dt - datetime.timedelta(days=x) for x in range(0, numdays.days + 1)]\n",
    "            print(3,\"This is updateDepth.py: date time0_date runfile: \"+str(datesISO)) \n",
    "\n",
    "            time_zone = pytz.timezone('Europe/Amsterdam')\n",
    "            datesISO2 = []\n",
    "            for date in datesISO:\n",
    "                tz_date = time_zone.localize(date, is_dst=None)\n",
    "                tz_corrected_date = date + tz_date.dst()\n",
    "                datesISO2.append(tz_corrected_date)\n",
    "    \n",
    "            datesEpoch = []\n",
    "            for date in datesISO2:\n",
    "                datesEpoch.append(date.timestamp() / 60.)    \n",
    "            datesEpoch.reverse()\n",
    "            # create numpy array of epoch\n",
    "            #datesEpoch = np.array(datesEpoch)\n",
    "\n",
    "            # repeat array N times where N is number of days between state and time0\n",
    "            N = len(datesEpoch)\n",
    "            A = np.array(hm_state[0,::])\n",
    "            B = np.asarray([A]*N)\n",
    "\n",
    "            # mask nodata values\n",
    "            hm_out = np.ma.masked_equal(B, -999.)\n",
    "\n",
    "            # create NETCDF file for new timeSeriesSet        \n",
    "            createNETCDF(out_nc, in_nc_arr = state_nc_arr, STATE_COPY_CREATE = 2, TIME_LIST = datesEpoch, HM_ARRAY = hm_out )\n",
    "\n",
    "            # open out_NC as input for new WarmStateFile\n",
    "            out_nc_arr = netCDF4.Dataset(out_nc, )    \n",
    "            newHM_out = hm_out[-1]\n",
    "\n",
    "            # create NETCDF file for new WarmStateFile        \n",
    "            createNETCDF(state_nc, in_nc_arr = out_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = newHM_out, state_config_read=state_config_read, state_config_write=state_config_write)\n",
    "        \n",
    "        \n",
    "        except:\n",
    "            if not (isdir(inputdir)):\n",
    "                print(1,\"%s is not a valid path\" % inputdir)\n",
    "            elif not (isdir(statedir)):\n",
    "                print(1,\"%s is not a valid path\" % statedir)\n",
    "            elif not (isdir(outputdir)):\n",
    "                print(1,\"%s is not a valid path\" % outputdir)\n",
    "            elif not (isdir(runfiledir)):\n",
    "                print(1,\"%r is not a valid path\" % runfiledir)\n",
    "            else:\n",
    "                print(1,\"something else is funky\")            \n",
    "        \n",
    "    # TOT HIER\n",
    "    print(3,\"Dat was het, FEWS take over please\")\n",
    "    #log.close()\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 This is updateDepth.py: date coldState runfile: 2018-03-05 00:00:00\n",
      "3 This is updateDepth.py: date time0_date runfile: [datetime.datetime(2018, 4, 4, 0, 0), datetime.datetime(2018, 4, 3, 0, 0), datetime.datetime(2018, 4, 2, 0, 0), datetime.datetime(2018, 4, 1, 0, 0), datetime.datetime(2018, 3, 31, 0, 0), datetime.datetime(2018, 3, 30, 0, 0), datetime.datetime(2018, 3, 29, 0, 0), datetime.datetime(2018, 3, 28, 0, 0), datetime.datetime(2018, 3, 27, 0, 0), datetime.datetime(2018, 3, 26, 0, 0), datetime.datetime(2018, 3, 25, 0, 0), datetime.datetime(2018, 3, 24, 0, 0), datetime.datetime(2018, 3, 23, 0, 0), datetime.datetime(2018, 3, 22, 0, 0), datetime.datetime(2018, 3, 21, 0, 0), datetime.datetime(2018, 3, 20, 0, 0), datetime.datetime(2018, 3, 19, 0, 0), datetime.datetime(2018, 3, 18, 0, 0), datetime.datetime(2018, 3, 17, 0, 0), datetime.datetime(2018, 3, 16, 0, 0), datetime.datetime(2018, 3, 15, 0, 0), datetime.datetime(2018, 3, 14, 0, 0), datetime.datetime(2018, 3, 13, 0, 0), datetime.datetime(2018, 3, 12, 0, 0), datetime.datetime(2018, 3, 11, 0, 0), datetime.datetime(2018, 3, 10, 0, 0), datetime.datetime(2018, 3, 9, 0, 0), datetime.datetime(2018, 3, 8, 0, 0), datetime.datetime(2018, 3, 7, 0, 0), datetime.datetime(2018, 3, 6, 0, 0), datetime.datetime(2018, 3, 5, 0, 0)]\n",
      "3 Dat was het, FEWS take over please\n"
     ]
    }
   ],
   "source": [
    "main('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0_dt = datetime.datetime(2018, 4, 4, 0, 0)\n",
    "cs_date = datetime.datetime(2018, 3, 5, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new datelist in MINUTES since epoch\n",
    "numdays = time0_dt - cs_date\n",
    "datesISO = [time0_dt - datetime.timedelta(days=x)\n",
    "            for x in range(0, numdays.days + 1)]\n",
    "print(3, \"This is updateDepth.py: date time0_date runfile: \" + str(datesISO))\n",
    "\n",
    "# datesEpoch = []\n",
    "# for date in datesISO:\n",
    "#     datesEpoch.append(date.timestamp() / 60.)\n",
    "# datesEpoch.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_zone = pytz.timezone('Europe/Amsterdam')\n",
    "dst_date = time_zone.localize(target_date, is_dst=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "time_zone = pytz.timezone('Europe/Amsterdam')\n",
    "datesISO2 = []\n",
    "for date in datesISO:\n",
    "    tz_date = time_zone.localize(date, is_dst=None)\n",
    "    tz_corrected_date = date + tz_date.dst()\n",
    "    datesISO2.append(tz_corrected_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesISO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesEpoch = []\n",
    "for date in datesISO:\n",
    "    datesEpoch.append(date.timestamp() / 60.)    \n",
    "datesEpoch.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datesEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pytz # $ pip install pytz\n",
    "\n",
    "la = pytz.timezone(\"America/Los_Angeles\")\n",
    "fmt = '%Y-%m-%d %H:%M:%S %Z%z'\n",
    "now = datetime.now(la)\n",
    "now2 = la.localize(datetime.now())\n",
    "now3 = datetime.now()\n",
    "print(now.strftime(fmt))\n",
    "print(now2.strftime(fmt))\n",
    "print(now3.strftime(fmt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "import datetime\n",
    "\n",
    "target_date = datesISO[0]\n",
    "\n",
    "#target_date = datetime.datetime.strptime(arg_date, \"%Y-%m-%d\")\n",
    "time_zone = pytz.timezone('Europe/Amsterdam')\n",
    "dst_date = time_zone.localize(target_date, is_dst=None)\n",
    "est_hour = 24\n",
    "if bool(dst_date.dst()) is True:\n",
    "    est_hour -= 4\n",
    "else:\n",
    "    est_hour -= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date2 = datesISO[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_date2 = time_zone.localize(target_date2, is_dst=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_date2.dst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date - datetime.timedelta(dst_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_date - dst_date.dst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_date.dst()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
