{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Scale data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_waterstand(train_df, test_df):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_df)\n",
    "    data_train = scaler.transform(train_df)\n",
    "    data_test = scaler.transform(test_df)\n",
    "\n",
    "    # Build X and y\n",
    "    X_train = data_train[:,:-1]\n",
    "    y_train = data_train[:, -1]\n",
    "    X_test = data_test[:, :-1]\n",
    "    y_test = data_test[:, -1]    \n",
    "    \n",
    "    # Number of stocks in training data\n",
    "    n_params = X_train.shape[1]\n",
    "    \n",
    "    # Neurons\n",
    "    n_neurons_1 = 1024\n",
    "    n_neurons_2 = 512\n",
    "    n_neurons_3 = 256\n",
    "    n_neurons_4 = 128\n",
    "\n",
    "    # Session\n",
    "    net = tf.InteractiveSession()\n",
    "\n",
    "    # Placeholder\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, n_params])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "    # Initializers\n",
    "    sigma = 1\n",
    "    weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "    bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "    # Hidden weights\n",
    "    W_hidden_1 = tf.Variable(weight_initializer([n_params, n_neurons_1]))\n",
    "    bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "    W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "    bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "    W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "    bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "    W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "    bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "    # Output weights\n",
    "    W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "    bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "    # Hidden layer\n",
    "    hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "    hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "    hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "    hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "    # Output layer (transpose!)\n",
    "    out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "    # Cost function\n",
    "    mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "    # Optimizer\n",
    "    opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "    # Init\n",
    "    net.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit neural net\n",
    "    batch_size = 256\n",
    "    mse_train = []\n",
    "    mse_test = []    \n",
    "\n",
    "    %matplotlib\n",
    "    # Setup plot\n",
    "    plt.ion()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    line1, = ax1.plot(scaler.inverse_transform(data_test)[:, -1])\n",
    "    line2, = ax1.plot((scaler.inverse_transform(\n",
    "        data_test)[:, -1]) * 0.5)\n",
    "\n",
    "    # Run\n",
    "    epochs = 10\n",
    "    y_out = data_test.copy()\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # Shuffle training data\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "        X_train = X_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "        # Minibatch training\n",
    "        for i in range(0, len(y_train) // batch_size):\n",
    "            start = i * batch_size\n",
    "            batch_x = X_train[start:start + batch_size]\n",
    "            batch_y = y_train[start:start + batch_size]\n",
    "            # Run optimizer with batch\n",
    "            net.run(opt, feed_dict={X: batch_x, Y: batch_y})    \n",
    "            # Show progress\n",
    "            if np.mod(i, 50) == 0:\n",
    "                # MSE train and test\n",
    "                mse_train.append(net.run(mse, feed_dict={X: X_train, Y: y_train}))\n",
    "                mse_test.append(net.run(mse, feed_dict={X: X_test, Y: y_test}))\n",
    "                # Prediction\n",
    "                pred = net.run(out, feed_dict={X: X_test})\n",
    "\n",
    "                y_out[:, -1] = pred\n",
    "                line2.set_ydata(scaler.inverse_transform(y_out)[:, -1])\n",
    "                ax1.set_title('Epoch ' + str(e) + ', Batch ' + str(i) + ', MSE Train: ' +\n",
    "                              str(mse_train[-1]) + ', MSE Test: ' + str(mse_test[-1]))\n",
    "\n",
    "                fig.canvas.draw()  \n",
    "    return net, out, X, X_test, y_test, data_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "peilvakken_in = ['peilvak.{}'.format(ix) for ix in [92]]\n",
    "#peilvakken_in = ['peilvak.15', 'peilvak.21', 'peilvak.34', 'peilvak.65', 'peilvak.100', 'peilvak.113', 'peilvak.142']\n",
    "colors_peilvakken = ['#8BB9BA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peilvak.92 #8BB9BA\n",
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n",
      "Using matplotlib backend: TkAgg\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508281800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508281900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508282000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508282100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508282200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508282300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508290900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508291900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508292000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508292100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508292200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508292300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508300900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508301900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508302000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508302100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508302200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508302300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508310900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508311900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508312000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508312100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508312200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201508312300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509010900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011500.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509011900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509012000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509012100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509012200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509012300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.92\\datum_201509020800.png\n"
     ]
    }
   ],
   "source": [
    "for idx, peilvak_in in enumerate(peilvakken_in):\n",
    "    color_peilvak = colors_peilvakken[idx]\n",
    "    print(peilvak_in, color_peilvak)\n",
    "    \n",
    "    pv_in_csv = r'D:\\Projects\\RO\\0815.10 data Challenge 2018\\Neerslag//__{}.csv'.format(peilvak_in)\n",
    "    png_out = r'D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.{}'.format(peilvak_in)\n",
    "\n",
    "    # Import df\n",
    "    df = pd.read_csv(pv_in_csv)\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    # maak een month_day dataframe van de MultiYear DataFrame\n",
    "    month_day = pd.concat([\n",
    "                    df.index.to_series().dt.month, \n",
    "                    df.index.to_series().dt.day\n",
    "                ], axis=1).apply(tuple, axis=1)      \n",
    "    \n",
    "    df.fillna(0, inplace=True)\n",
    "    \n",
    "    #train_df = df  \n",
    "    \n",
    "    before_2015 = df['2010-01-01':'2014-12-31']\n",
    "    during_2015 = df['2015-01-01':'2015-12-31']\n",
    "    after_2015 = df['2016-01-01':'2018-12-31']\n",
    "    train_df = pd.concat([before_2015, during_2015, after_2015], axis=0)\n",
    "    test_df = during_2015    \n",
    "    \n",
    "    train_df['Y.waterlevel.FC.1H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-1 hour'))\n",
    "    train_df['Y.waterlevel.FC.2H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-2 hour'))\n",
    "    train_df['Y.waterlevel.FC.3H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-3 hour'))\n",
    "    train_df['Y.waterlevel.FC.4H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-4 hour'))\n",
    "    train_df['Y.waterlevel.FC.5H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-5 hour'))\n",
    "    train_df['Y.waterlevel.FC.6H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-6 hour'))    \n",
    "    \n",
    "    # selecteer alleen de gebeurtenissen binnen een jaarlijks terugkerende periode \n",
    "    startMM = 4\n",
    "    startdd = 1\n",
    "    endMM = 9\n",
    "    enddd = 30\n",
    "    train_df = train_df[(month_day >= (startMM, startdd)) & (month_day <= (endMM, enddd))]\n",
    "    test_df = train_df['2015-01-01':'2015-12-31']\n",
    "    #train_df.tail()    \n",
    "    \n",
    "    df_train_0H = train_df[train_df.columns.difference(['Y.waterlevel.FC.1H', 'Y.waterlevel.FC.2H', \n",
    "                                                        'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_train_1H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.2H', \n",
    "                                                        'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_train_2H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_train_3H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_train_4H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_train_5H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                        'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_train_6H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                        'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.5H'])]\n",
    "    # df_train_2H.columns\n",
    "\n",
    "    df_test_0H = test_df[test_df.columns.difference(['Y.waterlevel.FC.1H', 'Y.waterlevel.FC.2H', \n",
    "                                                        'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_test_1H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.2H', \n",
    "                                                        'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_test_2H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_test_3H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.4H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_test_4H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                        'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_test_5H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                        'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.6H'])]\n",
    "    df_test_6H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                        'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                        'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.5H'])]    \n",
    "    \n",
    "    net_0H, out_0H, X_0H, X_test_0H, y_test_0H, data_test_0H, scaler_0H = nn_waterstand(df_train_0H, df_test_0H)\n",
    "    net_1H, out_1H, X_1H, X_test_1H, y_test_1H, data_test_1H, scaler_1H = nn_waterstand(df_train_1H, df_test_1H)\n",
    "    net_2H, out_2H, X_2H, X_test_2H, y_test_2H, data_test_2H, scaler_2H = nn_waterstand(df_train_2H, df_test_2H)\n",
    "    net_3H, out_3H, X_3H, X_test_3H, y_test_3H, data_test_3H, scaler_3H = nn_waterstand(df_train_3H, df_test_3H)\n",
    "    net_4H, out_4H, X_4H, X_test_4H, y_test_4H, data_test_4H, scaler_4H = nn_waterstand(df_train_4H, df_test_4H)\n",
    "    net_5H, out_5H, X_5H, X_test_5H, y_test_5H, data_test_5H, scaler_5H = nn_waterstand(df_train_5H, df_test_5H)\n",
    "    net_6H, out_6H, X_6H, X_test_6H, y_test_6H, data_test_6H, scaler_6H = nn_waterstand(df_train_6H, df_test_6H)    \n",
    "    \n",
    "    pred_0H = net_0H.run(out_0H, feed_dict={X_0H: X_test_0H})\n",
    "    pred_1H = net_1H.run(out_1H, feed_dict={X_1H: X_test_1H})\n",
    "    pred_2H = net_2H.run(out_2H, feed_dict={X_2H: X_test_2H})\n",
    "    pred_3H = net_3H.run(out_3H, feed_dict={X_3H: X_test_3H})\n",
    "    pred_4H = net_4H.run(out_4H, feed_dict={X_4H: X_test_4H})\n",
    "    pred_5H = net_5H.run(out_5H, feed_dict={X_5H: X_test_5H})\n",
    "    pred_6H = net_6H.run(out_6H, feed_dict={X_6H: X_test_6H})    \n",
    "\n",
    "    y_test_0H = scaler_0H.inverse_transform(data_test_0H)[:, -1]\n",
    "    data_test_0H[:, -1] = pred_0H\n",
    "    pred_0H = scaler_0H.inverse_transform(data_test_0H)[:, -1]\n",
    "    \n",
    "    y_test_1H = scaler_1H.inverse_transform(data_test_1H)[:, -1]\n",
    "    data_test_1H[:, -1] = pred_1H\n",
    "    pred_1H = scaler_1H.inverse_transform(data_test_1H)[:, -1]\n",
    "    \n",
    "    y_test_2H = scaler_2H.inverse_transform(data_test_2H)[:, -1]\n",
    "    data_test_2H[:, -1] = pred_2H\n",
    "    pred_2H = scaler_2H.inverse_transform(data_test_2H)[:, -1]\n",
    "    \n",
    "    y_test_3H = scaler_3H.inverse_transform(data_test_3H)[:, -1]\n",
    "    data_test_3H[:, -1] = pred_3H\n",
    "    pred_3H = scaler_3H.inverse_transform(data_test_3H)[:, -1]    \n",
    "    \n",
    "    y_test_4H = scaler_4H.inverse_transform(data_test_4H)[:, -1]\n",
    "    data_test_4H[:, -1] = pred_4H\n",
    "    pred_4H = scaler_4H.inverse_transform(data_test_4H)[:, -1]\n",
    "    \n",
    "    y_test_5H = scaler_5H.inverse_transform(data_test_5H)[:, -1]\n",
    "    data_test_5H[:, -1] = pred_5H\n",
    "    pred_5H = scaler_5H.inverse_transform(data_test_5H)[:, -1]\n",
    "    \n",
    "    y_test_6H = scaler_6H.inverse_transform(data_test_6H)[:, -1]\n",
    "    data_test_6H[:, -1] = pred_6H\n",
    "    pred_6H = scaler_6H.inverse_transform(data_test_6H)[:, -1]        \n",
    "    #line2.set_ydata(scaler.inverse_transform(y_out)[:, -1])\n",
    "    \n",
    "    from_date = '2015-08-28 18:00'\n",
    "    to_date = '2015-09-02 08:00'\n",
    "\n",
    "    index_start = df_test_0H.index.get_loc(from_date)\n",
    "    dt_index = df_test_0H[from_date:to_date].index\n",
    "\n",
    "    start_setxlim = df_test_0H[from_date:to_date].index.to_pydatetime()[0]\n",
    "    end_setxlim = df_test_0H[from_date:to_date].index.to_pydatetime()[-1]    \n",
    "    \n",
    "    #import matplotlib.dates as mdates\n",
    "    %matplotlib inline\n",
    "    df_band = pd.DataFrame(columns=['date', 'min_band', 'max_band'])\n",
    "    for idx, val in enumerate(dt_index):\n",
    "        i_val = dt_index[idx]  # +1]\n",
    "        i_end = i_val.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start = (i_val - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        fig = plt.figure(figsize=(14, 3))\n",
    "        ax = fig.add_subplot(111)\n",
    "\n",
    "        # observed\n",
    "        i_end = i_val.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start = (i_val - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line1, = ax.plot(df_test_0H[from_date:i_end].index.to_pydatetime(\n",
    "        ), y_test_0H[index_start:index_start + idx + 1])  # , vmin=0.25, vmax=0.8)\n",
    "\n",
    "        # 0H\n",
    "        line2, = ax.plot(df_test_0H[i_start:i_end].index.to_pydatetime(), pred_0H.flatten()[\n",
    "                         index_start + idx - 2:index_start + idx + 1], color='orange')\n",
    "\n",
    "        # 1H\n",
    "        i_val_1H = (i_val + pd.Timedelta(1, 'h'))\n",
    "        i_end_1H = i_val_1H.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start_1H = (i_val_1H - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line3, = ax.plot(df_test_1H[i_start_1H:i_end_1H].index.to_pydatetime(\n",
    "        ), pred_1H.flatten()[index_start + idx - 2:index_start + idx + 1])\n",
    "\n",
    "        # 2H\n",
    "        i_val_2H = (i_val + pd.Timedelta(2, 'h'))\n",
    "        i_end_2H = i_val_2H.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start_2H = (i_val_2H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line3, = ax.plot(df_test_2H[i_start_2H:i_end_2H].index.to_pydatetime(\n",
    "        ), pred_2H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "        # 3H\n",
    "        i_val_3H = (i_val + pd.Timedelta(3, 'h'))\n",
    "        i_end_3H = i_val_3H.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start_3H = (i_val_3H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line3, = ax.plot(df_test_3H[i_start_3H:i_end_3H].index.to_pydatetime(\n",
    "        ), pred_3H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "        # 4H\n",
    "        i_val_4H = (i_val + pd.Timedelta(4, 'h'))\n",
    "        i_end_4H = i_val_4H.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start_4H = (i_val_4H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line3, = ax.plot(df_test_4H[i_start_4H:i_end_4H].index.to_pydatetime(\n",
    "        ), pred_4H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "        # 5H\n",
    "        i_val_5H = (i_val + pd.Timedelta(5, 'h'))\n",
    "        i_end_5H = i_val_5H.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start_5H = (i_val_5H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line3, = ax.plot(df_test_5H[i_start_5H:i_end_5H].index.to_pydatetime(\n",
    "        ), pred_5H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "        # 6H\n",
    "        i_val_6H = (i_val + pd.Timedelta(6, 'h'))\n",
    "        i_end_6H = i_val_6H.strftime('%Y-%m-%d %H:%M')\n",
    "        i_start_6H = (i_val_6H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "        line3, = ax.plot(df_test_6H[i_start_6H:i_end_6H].index.to_pydatetime(\n",
    "        ), pred_6H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "        full_limits = np.concatenate([pred_6H.flatten(), pred_5H.flatten(), pred_4H.flatten(), pred_3H.flatten(), pred_2H.flatten(), pred_1H.flatten(), pred_0H.flatten(), y_test_0H])\n",
    "\n",
    "        ax.set_ylim(full_limits.min()-0.1, full_limits.max()+0.2)\n",
    "        ax.set_xlim(start_setxlim, end_setxlim)\n",
    "        ax.axvline(x=i_val.to_pydatetime(), color=color_peilvak)\n",
    "\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor(color_peilvak)\n",
    "        #ax.format_xdata = mdates.DateFormatter('%Y-%m-%d %H')\n",
    "        # fig.autofmt_xdate()\n",
    "\n",
    "        band_now = np.array([pred_6H.flatten()[index_start + idx - 6],\n",
    "                             pred_5H.flatten()[index_start + idx - 5],\n",
    "                             pred_4H.flatten()[index_start + idx - 4],\n",
    "                             pred_3H.flatten()[index_start + idx - 3],\n",
    "                             pred_2H.flatten()[index_start + idx - 2],\n",
    "                             pred_1H.flatten()[index_start + idx - 1]])\n",
    "        band_now_max = band_now.max()\n",
    "        band_now_min = band_now.min()\n",
    "        df_band.loc[idx] = [i_val, band_now_min, band_now_max]\n",
    "\n",
    "        plt.fill_between(pd.Index(df_band['date']).to_pydatetime(\n",
    "        ), df_band['min_band'].values, df_band['max_band'].values, color='lightgrey', alpha='0.5')\n",
    "        #ax.fill_between(x, y3, y4, color='grey', alpha='0.5')\n",
    "        file_png_out = os.path.join(\n",
    "            png_out, 'datum_{}.png'.format(i_val.strftime('%Y%m%d%H%M')))\n",
    "        print(file_png_out)\n",
    "        plt.savefig(file_png_out)\n",
    "\n",
    "        # plt.show()\n",
    "        plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pct_schade(schade_pct,max_schade_pct, date_schade):\n",
    "    fig = plt.figure(figsize=(2,3))\n",
    "    \n",
    "    plt.yscale('log')\n",
    "    #ax1 = fig.add_subplot(111)\n",
    "    bar_max, = plt.bar(range(1, 2), 100, bottom=0.1, color='lightgray', edgecolor='black', alpha=0.5)\n",
    "    bar_max_current, =plt.bar(range(1, 2), max_schade_pct, bottom=0.1, color='#8BB9BA', edgecolor='black', alpha=0.25)\n",
    "    bar_current, =plt.bar(range(1, 2), schade_pct, bottom=0.1, color='#8BB9BA', edgecolor='black')    \n",
    "    plt.xticks([1.5])\n",
    "    plt.yticks([0.1,1,10,100], [0.1,1,10,100])\n",
    "    plt.ylabel('schade (%)')\n",
    "\n",
    "    ax = fig.axes[0]\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    # Shrink current axis by 20%\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "    # Put a legend to the right of the current axis\n",
    "    ax.legend((bar_max, bar_max_current, bar_current), ('maximale schade', 'hoogst gemeten schade ({}%)'.format(max_schade_pct),'schade voorspelling 6 uur vooruit ({}%)'.format(schade_pct)), loc='center left', bbox_to_anchor=(1, 0.5)).get_frame().set_linewidth(0.0)\n",
    "    ax.set_title(date_schade.strftime('%Y-%m-%d %H:%M'))\n",
    "    folder_schade_out = r'D:\\Projects\\RO\\DataChallenge2018\\png_out\\schade.peilvak.92'\n",
    "    png_schade_out = os.path.join(\n",
    "        folder_schade_out, 'datum_{}.png'.format(date_schade.strftime('%Y%m%d%H%M')))    \n",
    "    #png_schade_out = os.path.join(folder_schade_out, )\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png_schade_out, bbox_inches='tight')\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "maai_csv = r'D:\\Projects\\RO\\0815.10 Data Challenge 2018\\maaiveldcurves\\BigdataMaaivelcurve_gesorteerd.xls'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maai = pd.read_excel(maai_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3ce74eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peilvak= 92\n",
    "df_sel = df_maai[df_maai['GEBIEDID']==peilvak]\n",
    "ax = df_sel.plot('PERCENTAGE', 'MAAIVELD', legend=False, title='geinundeerd gebied (%) van peilvak {}'.format(peilvak))\n",
    "ax.set_ylabel('hoogte in mNAP')\n",
    "ax.set_xlabel('percentage in %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "max_schade_pct = 0\n",
    "for idx, val in enumerate(dt_index.to_pydatetime()):\n",
    "    date_T0 = val\n",
    "    H_FC_6H = pred_6H[index_start+idx]\n",
    "    \n",
    "    df_nearest = df_sel.iloc[(df_sel['MAAIVELD']-H_FC_6H).abs().argsort()][0:1][['MAAIVELD','PERCENTAGE']]\n",
    "    schade_pct = df_nearest['PERCENTAGE'].values[0]\n",
    "    print(schade_pct)\n",
    "    if schade_pct > max_schade_pct:\n",
    "        max_schade_pct = schade_pct\n",
    "    plot_pct_schade(schade_pct, max_schade_pct, date_T0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34585697317123415"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3594"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4392"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_6H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X.coming1Hsum</th>\n",
       "      <th>X.coming2Hsum</th>\n",
       "      <th>X.coming3Hsum</th>\n",
       "      <th>X.coming4Hsum</th>\n",
       "      <th>X.coming5Hsum</th>\n",
       "      <th>X.coming6Hsum</th>\n",
       "      <th>X.last16Hsum</th>\n",
       "      <th>X.last1Hsum</th>\n",
       "      <th>X.last2Hsum</th>\n",
       "      <th>X.last32Hsum</th>\n",
       "      <th>X.last4Hsum</th>\n",
       "      <th>X.last8Hsum</th>\n",
       "      <th>Y.waterlevel.FC.6H</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>1.810357e-14</td>\n",
       "      <td>4.336809e-15</td>\n",
       "      <td>-1.964401e-14</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>14.3242</td>\n",
       "      <td>3.320000e-02</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>0.36475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>1.810357e-14</td>\n",
       "      <td>4.336809e-15</td>\n",
       "      <td>3.810000e-02</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>14.3242</td>\n",
       "      <td>4.336809e-15</td>\n",
       "      <td>3.4918</td>\n",
       "      <td>0.34825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>1.810357e-14</td>\n",
       "      <td>3.810000e-02</td>\n",
       "      <td>7.686000e-01</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>14.3242</td>\n",
       "      <td>4.336809e-15</td>\n",
       "      <td>3.0136</td>\n",
       "      <td>0.35225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>3.810000e-02</td>\n",
       "      <td>7.686000e-01</td>\n",
       "      <td>9.743000e-01</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>14.3242</td>\n",
       "      <td>4.336809e-15</td>\n",
       "      <td>1.5331</td>\n",
       "      <td>0.35750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.810000e-02</td>\n",
       "      <td>7.686000e-01</td>\n",
       "      <td>9.743000e-01</td>\n",
       "      <td>1.057100e+00</td>\n",
       "      <td>1.2153</td>\n",
       "      <td>3.5716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.253858e-14</td>\n",
       "      <td>14.3242</td>\n",
       "      <td>4.336809e-15</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.36075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     X.coming1Hsum  X.coming2Hsum  X.coming3Hsum  \\\n",
       "datetime                                                           \n",
       "2015-04-01 00:00:00            0.0  -1.253858e-14   1.810357e-14   \n",
       "2015-04-01 01:00:00            0.0  -1.253858e-14   1.810357e-14   \n",
       "2015-04-01 02:00:00            0.0  -1.253858e-14   1.810357e-14   \n",
       "2015-04-01 03:00:00            0.0  -1.253858e-14   3.810000e-02   \n",
       "2015-04-01 04:00:00            0.0   3.810000e-02   7.686000e-01   \n",
       "\n",
       "                     X.coming4Hsum  X.coming5Hsum  X.coming6Hsum  \\\n",
       "datetime                                                           \n",
       "2015-04-01 00:00:00   4.336809e-15  -1.964401e-14         0.0381   \n",
       "2015-04-01 01:00:00   4.336809e-15   3.810000e-02         0.7686   \n",
       "2015-04-01 02:00:00   3.810000e-02   7.686000e-01         0.9743   \n",
       "2015-04-01 03:00:00   7.686000e-01   9.743000e-01         1.0571   \n",
       "2015-04-01 04:00:00   9.743000e-01   1.057100e+00         1.2153   \n",
       "\n",
       "                     X.last16Hsum  X.last1Hsum   X.last2Hsum  X.last32Hsum  \\\n",
       "datetime                                                                     \n",
       "2015-04-01 00:00:00        3.5716          0.0 -1.253858e-14       14.3242   \n",
       "2015-04-01 01:00:00        3.5716          0.0 -1.253858e-14       14.3242   \n",
       "2015-04-01 02:00:00        3.5716          0.0 -1.253858e-14       14.3242   \n",
       "2015-04-01 03:00:00        3.5716          0.0 -1.253858e-14       14.3242   \n",
       "2015-04-01 04:00:00        3.5716          0.0 -1.253858e-14       14.3242   \n",
       "\n",
       "                      X.last4Hsum  X.last8Hsum  Y.waterlevel.FC.6H  \n",
       "datetime                                                            \n",
       "2015-04-01 00:00:00  3.320000e-02       3.5716             0.36475  \n",
       "2015-04-01 01:00:00  4.336809e-15       3.4918             0.34825  \n",
       "2015-04-01 02:00:00  4.336809e-15       3.0136             0.35225  \n",
       "2015-04-01 03:00:00  4.336809e-15       1.5331             0.35750  \n",
       "2015-04-01 04:00:00  4.336809e-15       0.0332             0.36075  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_6H.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2015, 8, 28, 18, 0), datetime.datetime(2015, 9, 2, 8, 0))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_setxlim, end_setxlim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-adcf6afc3cc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_test_6H\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart_setxlim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "df_test_6H.index.to_pydatetime()[start_setxlim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508281800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508281900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508282000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508282100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508282200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508282300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508290900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508291900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508292000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508292100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508292200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508292300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508300900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508301900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508302000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508302100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508302200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508302300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508310900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508311900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508312000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508312100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508312200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201508312300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509010900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011400.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011800.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509011900.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509012000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509012100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509012200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509012300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020000.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020100.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020200.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020300.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020400.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020500.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020600.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020700.png\n",
      "D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.peilvak.74\\new_datum_201509020800.png\n"
     ]
    }
   ],
   "source": [
    "#import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "df_band = pd.DataFrame(columns=['date', 'min_band', 'max_band'])\n",
    "for idx, val in enumerate(dt_index):\n",
    "    i_val = dt_index[idx]  # +1]\n",
    "    i_end = i_val.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start = (i_val - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    fig = plt.figure(figsize=(14, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # observed\n",
    "    i_end = i_val.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start = (i_val - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line1, = ax.plot(df_test_0H[from_date:i_end].index.to_pydatetime(\n",
    "    ), y_test_0H[index_start:index_start + idx + 1])  # , vmin=0.25, vmax=0.8)\n",
    "\n",
    "    # 0H\n",
    "    line2, = ax.plot(df_test_0H[i_start:i_end].index.to_pydatetime(), pred_0H.flatten()[\n",
    "                     index_start + idx - 2:index_start + idx + 1], color='orange')\n",
    "\n",
    "    # 1H\n",
    "    i_val_1H = (i_val + pd.Timedelta(1, 'h'))\n",
    "    i_end_1H = i_val_1H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_1H = (i_val_1H - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_1H[i_start_1H:i_end_1H].index.to_pydatetime(\n",
    "    ), pred_1H.flatten()[index_start + idx - 2:index_start + idx + 1])\n",
    "\n",
    "    # 2H\n",
    "    i_val_2H = (i_val + pd.Timedelta(2, 'h'))\n",
    "    i_end_2H = i_val_2H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_2H = (i_val_2H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_2H[i_start_2H:i_end_2H].index.to_pydatetime(\n",
    "    ), pred_2H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 3H\n",
    "    i_val_3H = (i_val + pd.Timedelta(3, 'h'))\n",
    "    i_end_3H = i_val_3H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_3H = (i_val_3H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_3H[i_start_3H:i_end_3H].index.to_pydatetime(\n",
    "    ), pred_3H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 4H\n",
    "    i_val_4H = (i_val + pd.Timedelta(4, 'h'))\n",
    "    i_end_4H = i_val_4H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_4H = (i_val_4H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_4H[i_start_4H:i_end_4H].index.to_pydatetime(\n",
    "    ), pred_4H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 5H\n",
    "    i_val_5H = (i_val + pd.Timedelta(5, 'h'))\n",
    "    i_end_5H = i_val_5H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_5H = (i_val_5H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_5H[i_start_5H:i_end_5H].index.to_pydatetime(\n",
    "    ), pred_5H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 6H\n",
    "    i_val_6H = (i_val + pd.Timedelta(6, 'h'))\n",
    "    i_end_6H = i_val_6H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_6H = (i_val_6H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_6H[i_start_6H:i_end_6H].index.to_pydatetime(\n",
    "    ), pred_6H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    full_limits = np.concatenate([pred_6H.flatten(), pred_5H.flatten(), pred_4H.flatten(), pred_3H.flatten(), pred_2H.flatten(), pred_1H.flatten(), pred_0H.flatten(), y_test_0H])\n",
    "\n",
    "    ax.set_ylim(full_limits.min()-0.1, full_limits.max()+0.2)\n",
    "    ax.set_xlim(start_setxlim, end_setxlim)\n",
    "    ax.axvline(x=i_val.to_pydatetime(), color=color_peilvak)\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(color_peilvak)\n",
    "    #ax.format_xdata = mdates.DateFormatter('%Y-%m-%d %H')\n",
    "    # fig.autofmt_xdate()\n",
    "\n",
    "    band_now = np.concatenate([pred_6H.flatten()[index_start + idx - 3:index_start + idx + 1],\n",
    "                               pred_5H.flatten()[\n",
    "        index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_4H.flatten()[\n",
    "        index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_3H.flatten()[\n",
    "        index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_2H.flatten()[index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_1H.flatten()[index_start + idx - 2:index_start + idx + 1]])\n",
    "    band_now_max = band_now.max()\n",
    "    band_now_min = band_now.min()\n",
    "    df_band.loc[idx] = [i_val, band_now_min, band_now_max]\n",
    "\n",
    "    plt.fill_between(pd.Index(df_band['date']).to_pydatetime(\n",
    "    ), df_band['min_band'].values, df_band['max_band'].values, color='lightgrey', alpha='0.5')\n",
    "    #ax.fill_between(x, y3, y4, color='grey', alpha='0.5')\n",
    "    file_png_out = os.path.join(\n",
    "        png_out, 'new_datum_{}.png'.format(i_val.strftime('%Y%m%d%H%M')))\n",
    "    print(file_png_out)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_png_out)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_6H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred_6H.flatten())\n",
    "plt.plot(pred_5H.flatten())\n",
    "plt.plot(pred_4H.flatten())\n",
    "plt.plot(pred_3H.flatten())\n",
    "plt.plot(pred_2H.flatten())\n",
    "plt.plot(pred_1H.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import df\n",
    "df = pd.read_csv(pv_in_csv)\n",
    "df.set_index('datetime', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# maak een month_day dataframe van de MultiYear DataFrame\n",
    "month_day = pd.concat([\n",
    "                df.index.to_series().dt.month, \n",
    "                df.index.to_series().dt.day\n",
    "            ], axis=1).apply(tuple, axis=1)      \n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "train_df = df  \n",
    "\n",
    "train_df['Y.waterlevel.FC.1H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-1 hour'))\n",
    "train_df['Y.waterlevel.FC.2H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-2 hour'))\n",
    "train_df['Y.waterlevel.FC.3H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-3 hour'))\n",
    "train_df['Y.waterlevel.FC.4H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-4 hour'))\n",
    "train_df['Y.waterlevel.FC.5H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-5 hour'))\n",
    "train_df['Y.waterlevel.FC.6H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-6 hour'))    \n",
    "\n",
    "# selecteer alleen de gebeurtenissen binnen een jaarlijks terugkerende periode \n",
    "startMM = 4\n",
    "startdd = 1\n",
    "endMM = 9\n",
    "enddd = 30\n",
    "train_df = train_df[(month_day >= (startMM, startdd)) & (month_day <= (endMM, enddd))]\n",
    "test_df = train_df['2015-01-01':'2015-12-31']\n",
    "\n",
    "df_train_0H = train_df[train_df.columns.difference(['Y.waterlevel.FC.1H', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_1H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_2H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_3H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_4H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_5H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_6H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.5H'])]\n",
    "# df_train_2H.columns\n",
    "\n",
    "df_test_0H = test_df[test_df.columns.difference(['Y.waterlevel.FC.1H', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_1H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_2H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_3H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_4H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_5H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_6H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.5H'])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_6H.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_5H.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_5H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_band = pd.DataFrame(columns=['date', 'min_band', 'max_band'])\n",
    "band_now = np.array([pred_6H.flatten()[index_start + idx - 6],\n",
    "                           pred_5H.flatten()[index_start + idx - 5],\n",
    "                           pred_4H.flatten()[index_start + idx - 4],\n",
    "                           pred_3H.flatten()[index_start + idx - 3],\n",
    "                           pred_2H.flatten()[index_start + idx - 2],\n",
    "                           pred_1H.flatten()[index_start + idx - 1]])\n",
    "band_now_max = band_now.max()\n",
    "band_now_min = band_now.min()\n",
    "df_band.loc[idx] = [i_val, band_now_min, band_now_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_6H.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_start + idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peilvak_in = 'peilvak.95'\n",
    "color_peilvak = 'red'\n",
    "pv_in_csv = r'D:\\Projects\\RO\\0815.10 data Challenge 2018\\Neerslag//{}.csv'.format(peilvak_in)\n",
    "png_out = r'D:\\Projects\\RO\\DataChallenge2018\\png_out\\waterlevel.{}'.format(peilvak_in)\n",
    "\n",
    "# Import df\n",
    "df = pd.read_csv(pv_in_csv)\n",
    "df.set_index('datetime', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# maak een month_day dataframe van de MultiYear DataFrame\n",
    "month_day = pd.concat([\n",
    "                df.index.to_series().dt.month, \n",
    "                df.index.to_series().dt.day\n",
    "            ], axis=1).apply(tuple, axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zomerpeil = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Y.waterlevel'] = df['Y.waterlevel'] - zomerpeil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[['X.last1Hsum', 'X.last2Hsum', 'X.last4Hsum', 'X.last8Hsum', 'X.last16Hsum', 'X.last24Hsum',\n",
    "#     'X.coming1Hsum', 'X.coming2Hsum', 'X.coming3Hsum', 'X.coming4Hsum', 'X.coming5Hsum', 'X.coming6Hsum',\n",
    "#     'Y.waterlevel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_2015 = df['2010-01-01':'2014-12-31']\n",
    "during_2015 = df['2015-01-01':'2015-12-31']\n",
    "after_2015 = df['2016-01-01':'2018-12-31']\n",
    "train_df = pd.concat([before_2015, during_2015, after_2015], axis=0)\n",
    "test_df = during_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([before_2015, during_2015, after_2015], axis=0)\n",
    "#train_df = during_2015\n",
    "#test_df = during_2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Y.waterlevel.FC.1H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-1 hour'))\n",
    "train_df['Y.waterlevel.FC.2H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-2 hour'))\n",
    "train_df['Y.waterlevel.FC.3H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-3 hour'))\n",
    "train_df['Y.waterlevel.FC.4H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-4 hour'))\n",
    "train_df['Y.waterlevel.FC.5H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-5 hour'))\n",
    "train_df['Y.waterlevel.FC.6H'] = train_df['Y.waterlevel'].shift(freq=pd.Timedelta('-6 hour'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecteer alleen de gebeurtenissen binnen een jaarlijks terugkerende periode \n",
    "startMM = 4\n",
    "startdd = 1\n",
    "endMM = 9\n",
    "enddd = 30\n",
    "train_df = train_df[(month_day >= (startMM, startdd)) & (month_day <= (endMM, enddd))]\n",
    "test_df = train_df['2015-01-01':'2015-12-31']\n",
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_0H = train_df[train_df.columns.difference(['Y.waterlevel.FC.1H', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_1H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_2H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_3H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_4H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_5H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.6H'])]\n",
    "df_train_6H = train_df[train_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.5H'])]\n",
    "# df_train_2H.columns\n",
    "\n",
    "df_test_0H = test_df[test_df.columns.difference(['Y.waterlevel.FC.1H', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_1H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.2H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_2H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.3H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_3H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.4H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_4H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.5H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_5H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.6H'])]\n",
    "df_test_6H = test_df[test_df.columns.difference(['Y.waterlevel', 'Y.waterlevel.FC.1H', \n",
    "                                                    'Y.waterlevel.FC.2H', 'Y.waterlevel.FC.3H', \n",
    "                                                    'Y.waterlevel.FC.4H', 'Y.waterlevel.FC.5H'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train_6H)\n",
    "data_train = scaler.transform(df_train_6H)\n",
    "data_test = scaler.transform(df_test_6H)\n",
    "\n",
    "# Build X and y\n",
    "X_train = data_train[:,:-1]\n",
    "y_train = data_train[:, -1]\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.plot(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_6H.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_waterstand(train_df, test_df):\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_df)\n",
    "    data_train = scaler.transform(train_df)\n",
    "    data_test = scaler.transform(test_df)\n",
    "\n",
    "    # Build X and y\n",
    "    X_train = data_train[:,:-1]\n",
    "    y_train = data_train[:, -1]\n",
    "    X_test = data_test[:, :-1]\n",
    "    y_test = data_test[:, -1]    \n",
    "    \n",
    "    # Number of stocks in training data\n",
    "    n_params = X_train.shape[1]\n",
    "    \n",
    "    # Neurons\n",
    "    n_neurons_1 = 1024\n",
    "    n_neurons_2 = 512\n",
    "    n_neurons_3 = 256\n",
    "    n_neurons_4 = 128\n",
    "\n",
    "    # Session\n",
    "    net = tf.InteractiveSession()\n",
    "\n",
    "    # Placeholder\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[None, n_params])\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "\n",
    "    # Initializers\n",
    "    sigma = 1\n",
    "    weight_initializer = tf.variance_scaling_initializer(mode=\"fan_avg\", distribution=\"uniform\", scale=sigma)\n",
    "    bias_initializer = tf.zeros_initializer()\n",
    "\n",
    "    # Hidden weights\n",
    "    W_hidden_1 = tf.Variable(weight_initializer([n_params, n_neurons_1]))\n",
    "    bias_hidden_1 = tf.Variable(bias_initializer([n_neurons_1]))\n",
    "    W_hidden_2 = tf.Variable(weight_initializer([n_neurons_1, n_neurons_2]))\n",
    "    bias_hidden_2 = tf.Variable(bias_initializer([n_neurons_2]))\n",
    "    W_hidden_3 = tf.Variable(weight_initializer([n_neurons_2, n_neurons_3]))\n",
    "    bias_hidden_3 = tf.Variable(bias_initializer([n_neurons_3]))\n",
    "    W_hidden_4 = tf.Variable(weight_initializer([n_neurons_3, n_neurons_4]))\n",
    "    bias_hidden_4 = tf.Variable(bias_initializer([n_neurons_4]))\n",
    "\n",
    "    # Output weights\n",
    "    W_out = tf.Variable(weight_initializer([n_neurons_4, 1]))\n",
    "    bias_out = tf.Variable(bias_initializer([1]))\n",
    "\n",
    "    # Hidden layer\n",
    "    hidden_1 = tf.nn.relu(tf.add(tf.matmul(X, W_hidden_1), bias_hidden_1))\n",
    "    hidden_2 = tf.nn.relu(tf.add(tf.matmul(hidden_1, W_hidden_2), bias_hidden_2))\n",
    "    hidden_3 = tf.nn.relu(tf.add(tf.matmul(hidden_2, W_hidden_3), bias_hidden_3))\n",
    "    hidden_4 = tf.nn.relu(tf.add(tf.matmul(hidden_3, W_hidden_4), bias_hidden_4))\n",
    "\n",
    "    # Output layer (transpose!)\n",
    "    out = tf.transpose(tf.add(tf.matmul(hidden_4, W_out), bias_out))\n",
    "\n",
    "    # Cost function\n",
    "    mse = tf.reduce_mean(tf.squared_difference(out, Y))\n",
    "\n",
    "    # Optimizer\n",
    "    opt = tf.train.AdamOptimizer().minimize(mse)\n",
    "\n",
    "    # Init\n",
    "    net.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Fit neural net\n",
    "    batch_size = 256\n",
    "    mse_train = []\n",
    "    mse_test = []    \n",
    "\n",
    "    %matplotlib\n",
    "    # Setup plot\n",
    "    plt.ion()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    line1, = ax1.plot(scaler.inverse_transform(data_test)[:, -1])\n",
    "    line2, = ax1.plot((scaler.inverse_transform(\n",
    "        data_test)[:, -1]) * 0.5)\n",
    "\n",
    "    # Run\n",
    "    epochs = 10\n",
    "    y_out = data_test.copy()\n",
    "    for e in range(epochs):\n",
    "\n",
    "        # Shuffle training data\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y_train)))\n",
    "        X_train = X_train[shuffle_indices]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "        # Minibatch training\n",
    "        for i in range(0, len(y_train) // batch_size):\n",
    "            start = i * batch_size\n",
    "            batch_x = X_train[start:start + batch_size]\n",
    "            batch_y = y_train[start:start + batch_size]\n",
    "            # Run optimizer with batch\n",
    "            net.run(opt, feed_dict={X: batch_x, Y: batch_y})    \n",
    "            # Show progress\n",
    "            if np.mod(i, 50) == 0:\n",
    "                # MSE train and test\n",
    "                mse_train.append(net.run(mse, feed_dict={X: X_train, Y: y_train}))\n",
    "                mse_test.append(net.run(mse, feed_dict={X: X_test, Y: y_test}))\n",
    "                # Prediction\n",
    "                pred = net.run(out, feed_dict={X: X_test})\n",
    "\n",
    "                y_out[:, -1] = pred\n",
    "                line2.set_ydata(scaler.inverse_transform(y_out)[:, -1])\n",
    "                ax1.set_title('Epoch ' + str(e) + ', Batch ' + str(i) + ', MSE Train: ' +\n",
    "                              str(mse_train[-1]) + ', MSE Test: ' + str(mse_test[-1]))\n",
    "\n",
    "                fig.canvas.draw()  \n",
    "    return net, out, X, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_0H, out_0H, X_0H, X_test_0H, y_test_0H = nn_waterstand(df_train_0H, df_test_0H)\n",
    "net_1H, out_1H, X_1H, X_test_1H, y_test_1H = nn_waterstand(df_train_1H, df_test_1H)\n",
    "net_2H, out_2H, X_2H, X_test_2H, y_test_2H = nn_waterstand(df_train_2H, df_test_2H)\n",
    "net_3H, out_3H, X_3H, X_test_3H, y_test_3H = nn_waterstand(df_train_3H, df_test_3H)\n",
    "net_4H, out_4H, X_4H, X_test_4H, y_test_4H = nn_waterstand(df_train_4H, df_test_4H)\n",
    "net_5H, out_5H, X_5H, X_test_5H, y_test_5H = nn_waterstand(df_train_5H, df_test_5H)\n",
    "net_6H, out_6H, X_6H, X_test_6H, y_test_6H = nn_waterstand(df_train_6H, df_test_6H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0H = net_0H.run(out_0H, feed_dict={X_0H: X_test_0H})\n",
    "pred_1H = net_1H.run(out_1H, feed_dict={X_1H: X_test_1H})\n",
    "pred_2H = net_2H.run(out_2H, feed_dict={X_2H: X_test_2H})\n",
    "pred_3H = net_3H.run(out_3H, feed_dict={X_3H: X_test_3H})\n",
    "pred_4H = net_4H.run(out_4H, feed_dict={X_4H: X_test_4H})\n",
    "pred_5H = net_5H.run(out_5H, feed_dict={X_5H: X_test_5H})\n",
    "pred_6H = net_6H.run(out_6H, feed_dict={X_6H: X_test_6H})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = '2015-08-28 18:00'\n",
    "to_date = '2015-09-02 08:00'\n",
    "\n",
    "index_start = df_test_0H.index.get_loc(from_date)\n",
    "dt_index = df_test_0H[from_date:to_date].index\n",
    "\n",
    "start_setxlim = df_test_0H[from_date:to_date].index.to_pydatetime()[0]\n",
    "end_setxlim = df_test_0H[from_date:to_date].index.to_pydatetime()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "df_band = pd.DataFrame(columns=['date', 'min_band', 'max_band'])\n",
    "for idx, val in enumerate(dt_index):\n",
    "    i_val = dt_index[idx]  # +1]\n",
    "    i_end = i_val.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start = (i_val - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    fig = plt.figure(figsize=(14, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # observed\n",
    "    i_end = i_val.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start = (i_val - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line1, = ax.plot(df_test_0H[from_date:i_end].index.to_pydatetime(\n",
    "    ), y_test_0H[index_start:index_start + idx + 1])  # , vmin=0.25, vmax=0.8)\n",
    "\n",
    "    # 0H\n",
    "    line2, = ax.plot(df_test_0H[i_start:i_end].index.to_pydatetime(), pred_0H.flatten()[\n",
    "                     index_start + idx - 2:index_start + idx + 1], color='orange')\n",
    "\n",
    "    # 1H\n",
    "    i_val_1H = (i_val + pd.Timedelta(1, 'h'))\n",
    "    i_end_1H = i_val_1H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_1H = (i_val_1H - pd.Timedelta(2, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_1H[i_start_1H:i_end_1H].index.to_pydatetime(\n",
    "    ), pred_1H.flatten()[index_start + idx - 2:index_start + idx + 1])\n",
    "\n",
    "    # 2H\n",
    "    i_val_2H = (i_val + pd.Timedelta(2, 'h'))\n",
    "    i_end_2H = i_val_2H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_2H = (i_val_2H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_2H[i_start_2H:i_end_2H].index.to_pydatetime(\n",
    "    ), pred_2H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 3H\n",
    "    i_val_3H = (i_val + pd.Timedelta(3, 'h'))\n",
    "    i_end_3H = i_val_3H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_3H = (i_val_3H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_3H[i_start_3H:i_end_3H].index.to_pydatetime(\n",
    "    ), pred_3H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 4H\n",
    "    i_val_4H = (i_val + pd.Timedelta(4, 'h'))\n",
    "    i_end_4H = i_val_4H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_4H = (i_val_4H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_4H[i_start_4H:i_end_4H].index.to_pydatetime(\n",
    "    ), pred_4H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 5H\n",
    "    i_val_5H = (i_val + pd.Timedelta(5, 'h'))\n",
    "    i_end_5H = i_val_5H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_5H = (i_val_5H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_5H[i_start_5H:i_end_5H].index.to_pydatetime(\n",
    "    ), pred_5H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    # 6H\n",
    "    i_val_6H = (i_val + pd.Timedelta(6, 'h'))\n",
    "    i_end_6H = i_val_6H.strftime('%Y-%m-%d %H:%M')\n",
    "    i_start_6H = (i_val_6H - pd.Timedelta(3, 'h')).strftime('%Y-%m-%d %H:%M')\n",
    "    line3, = ax.plot(df_test_6H[i_start_6H:i_end_6H].index.to_pydatetime(\n",
    "    ), pred_6H.flatten()[index_start + idx - 3:index_start + idx + 1])\n",
    "\n",
    "    ax.set_ylim(0.25, 1.1)\n",
    "    ax.set_xlim(start_setxlim, end_setxlim)\n",
    "    ax.axvline(x=i_val.to_pydatetime(), color=color_peilvak)\n",
    "\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(color_peilvak)\n",
    "    #ax.format_xdata = mdates.DateFormatter('%Y-%m-%d %H')\n",
    "    # fig.autofmt_xdate()\n",
    "\n",
    "    band_now = np.concatenate([pred_6H.flatten()[index_start + idx - 3:index_start + idx + 1],\n",
    "                               pred_5H.flatten()[\n",
    "        index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_4H.flatten()[\n",
    "        index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_3H.flatten()[\n",
    "        index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_2H.flatten()[index_start + idx - 3:index_start + idx + 1],\n",
    "        pred_1H.flatten()[index_start + idx - 2:index_start + idx + 1]])\n",
    "    band_now_max = band_now.max()\n",
    "    band_now_min = band_now.min()\n",
    "    df_band.loc[idx] = [i_val, band_now_min, band_now_max]\n",
    "\n",
    "    plt.fill_between(pd.Index(df_band['date']).to_pydatetime(\n",
    "    ), df_band['min_band'].values, df_band['max_band'].values, color='lightgrey', alpha='0.5')\n",
    "    #ax.fill_between(x, y3, y4, color='grey', alpha='0.5')\n",
    "    file_png_out = os.path.join(\n",
    "        png_out, 'datum_{}.png'.format(i_val.strftime('%Y%m%d%H%M')))\n",
    "    print(file_png_out)\n",
    "    plt.savefig(file_png_out)\n",
    "\n",
    "    # plt.show()\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
