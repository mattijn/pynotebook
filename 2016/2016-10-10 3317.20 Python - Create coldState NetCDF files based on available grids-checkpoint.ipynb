{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "import glob, os, sys, time\n",
    "from shutil import copy\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment\n",
    "import subprocess as sp\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from osgeo import ogr\n",
    "import logging\n",
    "import re\n",
    "from itertools import *\n",
    "non_decimal = re.compile(r'[^\\d.,-]+')\n",
    "\n",
    "from __future__ import print_function # make sure print behaves the same in 2.7 and 3.x\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import shutil\n",
    "import pyproj\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootDir = r'D:\\OmsWaddenzee\\trunk\\fews\\Import\\geoxyz\\bodempeilingen\\asciiData'\n",
    "tmpDir = r'D:\\OMS_Waddenzee\\trunk\\fews\\ImportInterim\\geoxyz\\bodempeilingen'\n",
    "logDir = r'D:\\OMS_Waddenzee\\trunk\\src\\log'\n",
    "logFile = os.path.join(logDir, 'logfile4minmaxDepth2scalar.out')\n",
    "xmldir = os.path.join(tmpDir, 'ColdStatesGenerated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'netCDF4._netCDF4.Dataset'>\n",
      "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
      "    Conventions: CF-1.6,UGRID-0.9\n",
      "    title: Data\n",
      "    institution: Deltares\n",
      "    source: Export NETCDF-CF_GRID from Delft-FEWS\n",
      "    history: 2016-11-08 02:11:19 GMT: exported from Delft-FEWS\n",
      "    references: http://www.delft-fews.com\n",
      "    Metadata_Conventions: Unidata Dataset Discovery v1.0\n",
      "    summary: Data exported from Delft-FEWS\n",
      "    date_created: 2016-11-08 02:11:19 GMT\n",
      "    fews_implementation_version: 2016.01\n",
      "    fews_build_number: 63749\n",
      "    fews_patch_number: 62571\n",
      "    dimensions(sizes): time(15), y(330), x(500)\n",
      "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float64 \u001b[4my\u001b[0m(y), float64 \u001b[4mx\u001b[0m(x), float64 \u001b[4mz\u001b[0m(y,x), float64 \u001b[4mlat\u001b[0m(y,x), float64 \u001b[4mlon\u001b[0m(y,x), int32 \u001b[4mcrs\u001b[0m(), float32 \u001b[4mHM\u001b[0m(time,y,x)\n",
      "    groups: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load input netcdf and state netcdf\n",
    "in_nc = r'D:\\OmsWaddenzee\\trunk\\fews\\ImportInterim\\geoxyz\\bodempeilingen\\baseState\\in.nc'\n",
    "out_folder = r'D:\\fews\\data\\ImportInterim\\zip'\n",
    "# state_nc = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\state//state.nc'\n",
    "\n",
    "in_nc_arr = netCDF4.Dataset(in_nc, )\n",
    "# state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "print(in_nc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "asciiFiles = []\n",
    "asciiFile_fullPath = []\n",
    "for root, dirs, files in os.walk(rootDir):\n",
    "    for file in files:\n",
    "        if file.startswith('grid') and file.endswith('.asc'):\n",
    "            asciiFiles.append(file)\n",
    "            asciiFile_fullPath.append(os.path.join( os.path.abspath(root), file ))\n",
    "\n",
    "asciiLocs = []\n",
    "for file in asciiFiles:\n",
    "    asciiLocs.append(file[0:7])\n",
    "\n",
    "asciiLocsUnique = list(set(asciiLocs))\n",
    "asciiLocsUnique.sort()\n",
    "\n",
    "\n",
    "asciiFilesUnique = []\n",
    "asciiFilesUnique_fullPath = []\n",
    "for i in asciiLocsUnique:\n",
    "    asciiFilesUnique.append(next(obj for obj in asciiFiles if obj[0:7]==i))\n",
    "    asciiFilesUnique_fullPath.append(next(obj for obj in asciiFile_fullPath if obj[-26:-19]==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grid465_20170705000000.asc', 'grid466_20170705000000.asc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('new asciis {}'.format(asciiFilesUnique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows 418\n",
      "columns 507\n",
      "grid_id l.grid465\n",
      "zip_path D:\\Projects\\Pr\\3317.20\\zip_netcdf//pr.Surveyor.geoxyz.depthUpdate.l.grid465 Default\n",
      "rows 500\n",
      "columns 307\n",
      "grid_id l.grid466\n",
      "zip_path D:\\Projects\\Pr\\3317.20\\zip_netcdf//pr.Surveyor.geoxyz.depthUpdate.l.grid466 Default\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
       "    Conventions: CF-1.6,UGRID-0.9\n",
       "    title: Data\n",
       "    institution: Deltares\n",
       "    source: Export NETCDF-CF_GRID from Delft-FEWS\n",
       "    history: 2016-11-08 02:11:19 GMT: exported from Delft-FEWS\n",
       "    references: http://www.delft-fews.com\n",
       "    Metadata_Conventions: Unidata Dataset Discovery v1.0\n",
       "    summary: Data exported from Delft-FEWS\n",
       "    date_created: 2016-11-08 02:11:19 GMT\n",
       "    fews_implementation_version: 2016.01\n",
       "    fews_build_number: 63749\n",
       "    fews_patch_number: 62571\n",
       "    dimensions(sizes): time(15), y(330), x(500)\n",
       "    variables(dimensions): float64 \u001b[4mtime\u001b[0m(time), float64 \u001b[4my\u001b[0m(y), float64 \u001b[4mx\u001b[0m(x), float64 \u001b[4mz\u001b[0m(y,x), float64 \u001b[4mlat\u001b[0m(y,x), float64 \u001b[4mlon\u001b[0m(y,x), int32 \u001b[4mcrs\u001b[0m(), float32 \u001b[4mHM\u001b[0m(time,y,x)\n",
       "    groups: "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enumerate over unique asciifiles\n",
    "\n",
    "for idx, grid in enumerate(asciiFilesUnique):\n",
    "    #print ('idx',idx, 'grid',grid)\n",
    "    init_file = asciiFilesUnique_fullPath[idx]\n",
    "    #print ('init_file',init_file)\n",
    "    \n",
    "    # open unique ascii file and get columns/rows    \n",
    "    with open(init_file, 'r') as f:\n",
    "        head = list(islice(f, 6))\n",
    "        head_rp = non_decimal.sub('', str(head).replace('-',','))\n",
    "        head_strp = [int(float(x.strip())) for x in head_rp.split(',') if x]        \n",
    "#         print ('head',head)\n",
    "#         print ('head',head_strp)\n",
    "        print ('rows', head_strp[1])\n",
    "        y_rows = head_strp[1]\n",
    "        print ('columns', head_strp[0])\n",
    "        x_columns = head_strp[0]\n",
    "        \n",
    "        first_cell_x = head_strp[2]+0.5\n",
    "        first_cell_y = head_strp[3]+head_strp[1]-0.5\n",
    "        print ('grid_id', 'l.'+grid[0:7])               \n",
    "        \n",
    "        zip_path = os.path.join(out_folder,'pr.Surveyor.geoxyz.depthUpdate.l.'+grid[0:7]+' Default')\n",
    "        print ('zip_path', zip_path)\n",
    "        \n",
    "        # create evenly spaced interval with x and y coordinates\n",
    "        y_lin = np.linspace(first_cell_y, first_cell_y+y_rows, y_rows+1)[0:-1]\n",
    "        x_lin = np.linspace(first_cell_x, first_cell_x+x_columns, x_columns+1)[0:-1]\n",
    "\n",
    "        # init rd projection\n",
    "        p = pyproj.Proj(init=\"epsg:28992\", preserve_units=True)\n",
    "\n",
    "        # init empty arrays for netcdf lon/lat arrays\n",
    "        x_lin2lon = np.zeros(shape=(y_rows,x_columns))\n",
    "        y_lin2lat = np.zeros(shape=(y_rows,x_columns))\n",
    "\n",
    "        # fill lon/lat arrays based on x/y coordinates and rd proj\n",
    "        for idx,xl in enumerate(x_lin):\n",
    "            #print (idx, xl)\n",
    "            for idy,yl in enumerate(y_lin):\n",
    "                #print (idy, yl)    \n",
    "                new_p = p(xl,yl,inverse=True)\n",
    "                x_lin2lon[idy,idx] = new_p[0]\n",
    "                y_lin2lat[idy,idx] = new_p[1]          \n",
    "        \n",
    "        # init z array\n",
    "        z_nc = np.zeros(shape=(y_rows,x_columns))\n",
    "        \n",
    "        # init hm array\n",
    "        hm_nc = np.full((y_rows,x_columns), -999)        \n",
    "        \n",
    "        # prepare netcdf\n",
    "        # create new.nc url and open file to write\n",
    "        state_file = r'D:\\Projects\\Pr\\3317.20\\zip_netcdf\\state_file_temp\\state.nc'\n",
    "        state_folder = r'D:\\Projects\\Pr\\3317.20\\zip_netcdf\\state_file_temp'\n",
    "        nc_new = netCDF4.Dataset(state_file, 'w', format=\"NETCDF3_CLASSIC\")\n",
    "\n",
    "        # create dimensions for new nc file based on in.nc\n",
    "        nt = 1\n",
    "        ny = y_rows\n",
    "        nx = x_columns\n",
    "        nc_new.createDimension('time', nt)\n",
    "        nc_new.createDimension('y', ny)\n",
    "        nc_new.createDimension('x', nx)\n",
    "\n",
    "        # copy over time variable from in.nc [only first slice]\n",
    "        time_innc = in_nc_arr.variables['time']\n",
    "        time = nc_new.createVariable('time', 'f8', ('time',))\n",
    "        time[:] = 24193440.0 # 1/1/2016 0:00 be4: time_innc[0]\n",
    "        time.standard_name = time_innc.standard_name\n",
    "        time.long_name = time_innc.long_name\n",
    "        time.units = time_innc.units\n",
    "        time.axis = time_innc.axis\n",
    "\n",
    "        # copy over y variable from in.nc\n",
    "        y_innc = in_nc_arr.variables['y']\n",
    "        y = nc_new.createVariable('y', 'f8', ('y',), fill_value = y_innc._FillValue ) \n",
    "        y[:] = y_lin\n",
    "        y.standard_name = y_innc.standard_name\n",
    "        y.long_name = y_innc.long_name\n",
    "        y.units = y_innc.units\n",
    "        y.axis = y_innc.axis\n",
    "\n",
    "        # copy over x variable from in.nc\n",
    "        x_innc = in_nc_arr.variables['x']\n",
    "        x = nc_new.createVariable('x', 'f8', ('x'), fill_value = x_innc._FillValue)\n",
    "        x[:] = x_lin\n",
    "        x.standard_name = x_innc.standard_name\n",
    "        x.long_name = x_innc.long_name\n",
    "        x.units = x_innc.units\n",
    "        x.axis = x_innc.axis\n",
    "\n",
    "        # copy over z variable from in.nc\n",
    "        z_innc = in_nc_arr.variables['z']\n",
    "        z = nc_new.createVariable('z', 'f8', ('y', 'x'), fill_value = z_innc._FillValue)\n",
    "        z[:] = z_nc #z_innc[:]\n",
    "        z.long_name = z_innc.long_name\n",
    "        z.units = z_innc.units\n",
    "        z.axis = z_innc.axis\n",
    "        z.postive = z_innc.positive\n",
    "\n",
    "        # copy over lat variable from in.nc\n",
    "        lat_innc = in_nc_arr.variables['lat']\n",
    "        lat = nc_new.createVariable('lat', 'f8', ('y', 'x'), fill_value = lat_innc._FillValue)\n",
    "        lat[:] = y_lin2lat #lat_innc[:]\n",
    "        lat.standard_name = lat_innc.standard_name\n",
    "        lat.long_name = lat_innc.long_name\n",
    "        lat.units = lat_innc.units\n",
    "\n",
    "        # copy over lat variable from in.nc\n",
    "        lon_innc = in_nc_arr.variables['lon']\n",
    "        lon = nc_new.createVariable('lon', 'f8', ('y', 'x'), fill_value = lon_innc._FillValue)\n",
    "        lon[:] = x_lin2lon # lon_innc[:]\n",
    "        lon.standard_name = lon_innc.standard_name\n",
    "        lon.long_name = lon_innc.long_name\n",
    "        lon.units = lon_innc.units\n",
    "\n",
    "        # copy over crs variable from in.nc\n",
    "        crs_innc = in_nc_arr.variables['crs']\n",
    "        crs = nc_new.createVariable('crs', 'i4', ())\n",
    "        crs.long_name = crs_innc.long_name\n",
    "        crs.crs_wkt = crs_innc.crs_wkt\n",
    "        crs.proj4_params = crs_innc.proj4_params\n",
    "        crs.epsg_code = crs_innc.epsg_code\n",
    "\n",
    "        # copy over HM variable from in.nc [only first slice]\n",
    "        HM_innc = in_nc_arr.variables['HM']\n",
    "        HM = nc_new.createVariable('HM', 'f8', ('time', 'y', 'x'), fill_value = HM_innc._FillValue)\n",
    "        HM[:] = hm_nc # HM_innc[0]\n",
    "        HM.long_name = HM_innc.long_name\n",
    "        HM.units = HM_innc.units\n",
    "        HM.coordinates = HM_innc.coordinates\n",
    "        HM.grid_mapping = HM_innc.grid_mapping\n",
    "\n",
    "        #close newly created nc file\n",
    "        nc_new.close()        \n",
    "        \n",
    "        shutil.make_archive(zip_path, 'zip', state_folder)\n",
    "\n",
    "# close base nc file        \n",
    "in_nc_arr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
