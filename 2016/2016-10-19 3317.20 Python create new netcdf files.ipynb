{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os.path import isdir\n",
    "#from fewslogger import Logger\n",
    "import datetime\n",
    "import sys, getopt, shutil\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createNETCDF(filename, in_nc_arr=\"\", STATE_COPY_CREATE=0, TIME_LIST=[], HM_ARRAY=[], fillValue = -999.0):\n",
    "    \"\"\"\n",
    "    filename           ::  path to new NETCDF file\n",
    "    in_nc_arr          ::  base NETCDF file\n",
    "    STATE_COPY_CREATE  ::  set 0 for state\n",
    "                           set 1 for copy\n",
    "                           set 2 for create\n",
    "    TIME_LIST          ::  when creating, provide datetime array with dates\n",
    "    HM_ARRAY           ::  provide array with h.m data to create NETCDF\n",
    "    fillValue          ::  only used during creation [default: -999.0] \n",
    "    \"\"\"\n",
    "    # 0 is TimeSeriesSet STATE FILE\n",
    "    # 1 is TimeSeriesSet COPY\n",
    "    # 2 is TimeSeriesSet CREATE\n",
    "    # ------------------------------------------            \n",
    "    # create new warmState\n",
    "    # create new.nc url and open file to write\n",
    "    new_nc = filename\n",
    "    nc_new = netCDF4.Dataset(new_nc, 'w', format=\"NETCDF3_CLASSIC\")\n",
    "\n",
    "    # create dimensions for new nc file based on in.nc\n",
    "    if STATE_COPY_CREATE == 0 :\n",
    "        nt = 1\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        nt = in_nc_arr.dimensions['time'].size\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        nt = len(TIME_LIST)        \n",
    "    ny = in_nc_arr.dimensions['y'].size\n",
    "    nx = in_nc_arr.dimensions['x'].size\n",
    "    nc_new.createDimension('time', nt)\n",
    "    nc_new.createDimension('y', ny)\n",
    "    nc_new.createDimension('x', nx)\n",
    "\n",
    "    # copy over time variable from in.nc [only first slice]\n",
    "    time_innc = in_nc_arr.variables['time']\n",
    "    time = nc_new.createVariable('time', 'f8', ('time',))\n",
    "    if STATE_COPY_CREATE == 0:\n",
    "        time[:] = time_innc[-1]\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        time[:] = time_innc[:]\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        time[:] = TIME_LIST\n",
    "#     ws_epoch_min = time_innc[-1] * 60\n",
    "#     ws_datetime = datetime.datetime.fromtimestamp(ws_epoch_min).strftime('%Y-%m-%d')\n",
    "#     log.write(3,\"This is updateDepth.py: warmStateTime in datetime: \"+str(ws_datetime))\n",
    "    time.standard_name = time_innc.standard_name\n",
    "    time.long_name = time_innc.long_name\n",
    "    time.units = time_innc.units\n",
    "    time.axis = time_innc.axis\n",
    "\n",
    "    # copy over y variable from in.nc\n",
    "    y_innc = in_nc_arr.variables['y']\n",
    "    y = nc_new.createVariable('y', 'f8', ('y',), fill_value = y_innc._FillValue ) \n",
    "    y[:] = y_innc[:]\n",
    "    y.standard_name = y_innc.standard_name\n",
    "    y.long_name = y_innc.long_name\n",
    "    y.units = y_innc.units\n",
    "    y.axis = y_innc.axis\n",
    "\n",
    "    # copy over x variable from in.nc\n",
    "    x_innc = in_nc_arr.variables['x']\n",
    "    x = nc_new.createVariable('x', 'f8', ('x'), fill_value = x_innc._FillValue)\n",
    "    x[:] = x_innc[:]\n",
    "    x.standard_name = x_innc.standard_name\n",
    "    x.long_name = x_innc.long_name\n",
    "    x.units = x_innc.units\n",
    "    x.axis = x_innc.axis\n",
    "\n",
    "    # copy over z variable from in.nc\n",
    "    z_innc = in_nc_arr.variables['z']\n",
    "    z = nc_new.createVariable('z', 'f8', ('y', 'x'), fill_value = z_innc._FillValue)\n",
    "    z[:] = z_innc[:]\n",
    "    z.long_name = z_innc.long_name\n",
    "    z.units = z_innc.units\n",
    "    z.axis = z_innc.axis\n",
    "    try:\n",
    "        z.postive = z_innc.positive\n",
    "    except:\n",
    "        l = 1\n",
    "\n",
    "    # copy over lat variable from in.nc\n",
    "    lat_innc = in_nc_arr.variables['lat']\n",
    "    lat = nc_new.createVariable('lat', 'f8', ('y', 'x'), fill_value = lat_innc._FillValue)\n",
    "    lat[:] = lat_innc[:]\n",
    "    lat.standard_name = lat_innc.standard_name\n",
    "    lat.long_name = lat_innc.long_name\n",
    "    lat.units = lat_innc.units\n",
    "\n",
    "    # copy over lat variable from in.nc\n",
    "    lon_innc = in_nc_arr.variables['lon']\n",
    "    lon = nc_new.createVariable('lon', 'f8', ('y', 'x'), fill_value = lon_innc._FillValue)\n",
    "    lon[:] = lon_innc[:]\n",
    "    lon.standard_name = lon_innc.standard_name\n",
    "    lon.long_name = lon_innc.long_name\n",
    "    lon.units = lon_innc.units\n",
    "\n",
    "    # copy over crs variable from in.nc\n",
    "    crs_innc = in_nc_arr.variables['crs']\n",
    "    crs = nc_new.createVariable('crs', 'i4', ())\n",
    "    crs.long_name = crs_innc.long_name\n",
    "    crs.crs_wkt = crs_innc.crs_wkt\n",
    "    crs.proj4_params = crs_innc.proj4_params\n",
    "    crs.epsg_code = crs_innc.epsg_code\n",
    "\n",
    "    # copy over HM variable from in.nc [only first slice]\n",
    "    HM_innc = in_nc_arr.variables['HM']\n",
    "    if STATE_COPY_CREATE == 0:\n",
    "        noDataVal = HM_innc._FillValue\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        noDataVal = HM_innc._FillValue\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        noDataVal = fillValue\n",
    "    HM = nc_new.createVariable('HM', 'f8', ('time', 'y', 'x'), fill_value = noDataVal)\n",
    "    HM[:] = HM_ARRAY[:]\n",
    "    #HM[:] = hm_out[:]\n",
    "    HM.long_name = HM_innc.long_name\n",
    "    HM.units = HM_innc.units\n",
    "    HM.coordinates = HM_innc.coordinates\n",
    "    HM.grid_mapping = HM_innc.grid_mapping\n",
    "\n",
    "    #close newly created warmState nc file\n",
    "    nc_new.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputdir = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate\\input'\n",
    "outputdir = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate\\output'\n",
    "runfiledir = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate\\runfile'\n",
    "statedir = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate\\state'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_nc = \"%s/in.nc\" % inputdir\n",
    "state_nc = \"%s/state.nc\" % statedir\n",
    "out_nc = \"%s/out.nc\" % outputdir\n",
    "runfile_xml = \"%s/runfile.xml\" % runfiledir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try: \n",
    "    in_nc_arr = netCDF4.Dataset(in_nc, )\n",
    "except:\n",
    "    state_nc = \"%s/state.nc\" % statedir\n",
    "    runfile_xml = \"%s/runfile.xml\" % runfiledir\n",
    "    state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "    hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "    hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "    cs_epoch_min = hm_state_time[0] * 60\n",
    "    cs_date = datetime.datetime.fromtimestamp(cs_epoch_min)#.strftime('%Y-%m-%d')    \n",
    "\n",
    "    # open runfile.xml and get time0 date in datetime format\n",
    "    e = ElementTree.parse(runfile_xml).getroot()\n",
    "    time0 = e[3].attrib.get('date') # e[3] is time0 in xml file\n",
    "\n",
    "    time0_list = time0.replace('-', ' ').split(' ')\n",
    "    time0_date = datetime.datetime(int(time0_list[0]), int(time0_list[1]), int(time0_list[2]),2)   \n",
    "\n",
    "    # get new datelist in MINUTES since epoch\n",
    "    numdays = time0_date - cs_date\n",
    "    datesISO = [time0_date - datetime.timedelta(days=x) for x in range(0, numdays.days + 1)]\n",
    "\n",
    "    datesEpoch = []\n",
    "    for date in datesISO:\n",
    "        datesEpoch.append(date.timestamp() / 60.)    \n",
    "    datesEpoch.reverse()\n",
    "    # create numpy array of epoch\n",
    "    #datesEpoch = np.array(datesEpoch)\n",
    "\n",
    "    # repeat array N times where N is number of days between state and time0\n",
    "    N = len(datesEpoch)\n",
    "    A = np.array(hm_state[0,::])\n",
    "    B = np.asarray([A]*N)\n",
    "\n",
    "    # mask nodata values\n",
    "    hm_out = np.ma.masked_equal(B, -999)\n",
    "    \n",
    "    # create NETCDF file for new timeSeriesSet        \n",
    "    createNETCDF(out_nc, in_nc_arr = state_nc_arr, STATE_COPY_CREATE = 2, TIME_LIST = datesEpoch, HM_ARRAY = hm_out )\n",
    "    \n",
    "    # open out_NC as input for new WarmStateFile\n",
    "    out_nc_arr = netCDF4.Dataset(out_nc, )    \n",
    "    newHM_out = hm_out[-1]\n",
    "    \n",
    "    # create NETCDF file for new WarmStateFile        \n",
    "    createNETCDF(state_nc, in_nc_arr = out_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = newHM_out ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    try:\n",
    "        # DOE IETS SLIMS VANAF HIER\n",
    "        \n",
    "        #shutil.copyfile(\"%s/in.nc\" % inputdir, \"%s/out.nc\" % outputdir)\n",
    "        \n",
    "        # load input netcdf and state netcdf\n",
    "        # in_nc = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\input//in.nc'\n",
    "        # state_nc = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\state//state.nc'\n",
    "        # out_nc = r'D:\\OMS_Waddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\output//out.nc'\n",
    "\n",
    "        in_nc = \"%s/in.nc\" % inputdir\n",
    "        state_nc = \"%s/state.nc\" % statedir\n",
    "        out_nc = \"%s/out.nc\" % outputdir\n",
    "\n",
    "        in_nc_arr = netCDF4.Dataset(in_nc, )\n",
    "        state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "        # print(in_nc_arr)\n",
    "\n",
    "        # print(in_nc_arr.variables.keys()) # get all variable names\n",
    "        hm = in_nc_arr.variables['HM']  # bodemhoogte peiling\n",
    "        hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "        hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "        cs_epoch_min = hm_state_time[0] * 60\n",
    "        cs_datetime = datetime.datetime.fromtimestamp(cs_epoch_min).strftime('%Y-%m-%d')        \n",
    "        log.write(3,\"This is updateDepth.py: coldStateTime in ms since epoch: \"+str(cs_datetime))\n",
    "\n",
    "        # create copy in.nc\n",
    "        hm_copy = np.copy(hm)\n",
    "        hm_copy = np.ma.masked_equal(hm_copy, -999)\n",
    "\n",
    "        # use coldState to update first slice in.nc\n",
    "        a = hm_copy[0,::] \n",
    "        b = hm_state[0,::]\n",
    "        # update first slice based on coldState\n",
    "        a[~b.mask] = b.compressed()\n",
    "        hm_copy[0,::] = a\n",
    "\n",
    "        # create init warmState\n",
    "        hm_out = hm_copy[0,::]\n",
    "\n",
    "        for ix in range(hm.shape[0] - 1):    \n",
    "            # print (ix)\n",
    "            # one by one fill/update and ammend arrays\n",
    "            # get first slice of copy, get second slice of original\n",
    "            a = hm_copy[ix,::] \n",
    "            b = hm[ix+1,::]  \n",
    "\n",
    "            # update first slice based on second slice\n",
    "            a[~b.mask] = b.compressed()\n",
    "            # update timeSeriesSet\n",
    "            hm_copy[ix+1,::] = a    \n",
    "            # update warmState\n",
    "            hm_out[~a.mask] = a.compressed()        \n",
    "\n",
    "        # ------------------------------------------            \n",
    "        # create new warmState\n",
    "        # create NETCDF file for new timeSeriesSet        \n",
    "        createNETCDF(state_nc, in_nc_arr = in_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = hm_out )\n",
    " \n",
    "\n",
    "        # ------------------------------------------\n",
    "        # create out.nc timeSeriesSet\n",
    "        # create new.nc url and open file to write\n",
    "        createNETCDF(out_nc, in_nc_arr = in_nc_arr, STATE_COPY_CREATE = 1, HM_ARRAY = hm_out )\n",
    "\n",
    "        \n",
    "    except:\n",
    "        try:        \n",
    "            state_nc = \"%s/state.nc\" % statedir\n",
    "            runfile_xml = \"%s/runfile.xml\" % runfiledir\n",
    "            state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "            hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "            hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "            cs_epoch_min = hm_state_time[0] * 60\n",
    "            cs_date = datetime.datetime.fromtimestamp(cs_epoch_min)#.strftime('%Y-%m-%d')    \n",
    "\n",
    "            # open runfile.xml and get time0 date in datetime format\n",
    "            e = ElementTree.parse(runfile_xml).getroot()\n",
    "            time0 = e[3].attrib.get('date') # e[3] is time0 in xml file\n",
    "\n",
    "            time0_list = time0.replace('-', ' ').split(' ')\n",
    "            time0_date = datetime.datetime(int(time0_list[0]), int(time0_list[1]), int(time0_list[2]),2)   \n",
    "\n",
    "            # get new datelist in MINUTES since epoch\n",
    "            numdays = time0_date - cs_date\n",
    "            datesISO = [time0_date - datetime.timedelta(days=x) for x in range(0, numdays.days + 1)]\n",
    "\n",
    "            datesEpoch = []\n",
    "            for date in datesISO:\n",
    "                datesEpoch.append(date.timestamp() / 60.)    \n",
    "            datesEpoch.reverse()\n",
    "            # create numpy array of epoch\n",
    "            #datesEpoch = np.array(datesEpoch)\n",
    "\n",
    "            # repeat array N times where N is number of days between state and time0\n",
    "            N = len(datesEpoch)\n",
    "            A = np.array(hm_state[0,::])\n",
    "            B = np.asarray([A]*N)\n",
    "\n",
    "            # mask nodata values\n",
    "            hm_out = np.ma.masked_equal(B, -999)\n",
    "\n",
    "            # create NETCDF file for new timeSeriesSet        \n",
    "            createNETCDF(out_nc, in_nc_arr = state_nc_arr, STATE_COPY_CREATE = 2, TIME_LIST = datesEpoch, HM_ARRAY = hm_out )\n",
    "\n",
    "            # open out_NC as input for new WarmStateFile\n",
    "            out_nc_arr = netCDF4.Dataset(out_nc, )    \n",
    "            newHM_out = hm_out[-1]\n",
    "\n",
    "            # create NETCDF file for new WarmStateFile        \n",
    "            createNETCDF(state_nc, in_nc_arr = out_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = newHM_out )             \n",
    "        \n",
    "        \n",
    "        except:\n",
    "            if not (isdir(inputdir)):\n",
    "                log.write(1,\"%s is not a valid path\" % inputdir)\n",
    "            elif not (isdir(statedir)):\n",
    "                log.write(1,\"%s is not a valid path\" % statedir)\n",
    "            elif not (isdir(outputdir)):\n",
    "                log.write(1,\"%s is not a valid path\" % outputdir)\n",
    "            elif not (isdir(runfiledir)):\n",
    "                log.write(1,\"%r is not a valid path\" % runfiledir)\n",
    "            else:\n",
    "                log.write(1,\"something else is funky\")            \n",
    "        \n",
    "    # TOT HIER\n",
    "    log.write(3,\"Dat was het, FEWS take over please\")\n",
    "    log.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
