{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CACHEDIR=C:\\Users\\hoek.HKV\\.matplotlib\n",
      "Using fontManager instance from C:\\Users\\hoek.HKV\\.matplotlib\\fontList.json\n",
      "backend module://ipykernel.pylab.backend_inline version unknown\n",
      "backend module://ipykernel.pylab.backend_inline version unknown\n",
      "backend module://ipykernel.pylab.backend_inline version unknown\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "from time import time\n",
    "import sompy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_shp = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments\\Stations_total_v3.shp'\n",
    "file_csv = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments\\BN_data_full.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and parse data\n",
    "df = pd.read_csv(file_csv,sep=';', decimal=',')\n",
    "df.replace(np.inf, 0, inplace=True)\n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "\n",
    "shp_key = df['WSO1_ID'].copy()\n",
    "# exclude some columns\n",
    "df = df[df.columns.difference(['OBJECTID', 'Station_ID','WSO1_ID','Catchment_ID','Indicator_of_daily_discharge_availability'])]\n",
    "df = df.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize matrix\n",
    "X = df.as_matrix()\n",
    "# _mu = np.nanmean(X, axis=0)\n",
    "# _sigma = np.sqrt(np.nanmean((X - _mu) ** 2.0, axis=0))\n",
    "# X = (X - _mu) / _sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go back to pandas dataframe and drop NaN columns\n",
    "df = pd.DataFrame(data=X, columns=df.columns)\n",
    "df.dropna(axis=1, how='all', inplace=True)\n",
    "X = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.plot(subplots=True,figsize=(12,35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a kohonen network\n",
    "mapsize = [50,60]\n",
    "som = sompy.SOMFactory.build(X, mapsize, mask=None, mapshape='planar', lattice='rect', normalization='var', initialization='pca', neighborhood='gaussian', training='batch',component_names=df.columns, name='sompy')  # this will use the default parameters, but i can change the initialization and neighborhood methods\n",
    "som.train(n_job=1, verbose='debug')  # verbose='debug' will print more, and verbose=None wont print anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topographic_error = som.calculate_topographic_error()\n",
    "quantization_error = np.mean(som._bmu[1])\n",
    "print (\"Topographic error = %s; Quantization error = %s\" % (topographic_error, quantization_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sompy.visualization.mapview import View2D\n",
    "view2D  = View2D(10,10,\"rand data\",text_size=10)\n",
    "view2D.show(som, col_sz=7, which_dim=\"all\", desnormalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook = som._normalizer.denormalize_by(som.data_raw, som.codebook.matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_side = som.codebook.mapsize[0]\n",
    "y_side = som.codebook.mapsize[1]\n",
    "im = plt.imshow(codebook[:,0].reshape(x_side, y_side), vmin=100, vmax=1000)\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msz = som.codebook.mapsize\n",
    "cents = som.bmu_ind_to_xy(np.arange(0, msz[0] * msz[1]))\n",
    "\n",
    "yv = cents[:, 0]\n",
    "xv = cents[:, 1]\n",
    "xyv = cents[:, 2]  # coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But Umatrix finds the clusters easily\n",
    "u = sompy.umatrix.UMatrixView(50, 50, 'umatrix', show_axis=True, text_size=8, show_text=True)\n",
    "\n",
    "# #This is the Umat value\n",
    "UMAT = u.build_u_matrix(som, distance=1, row_normalized=False)\n",
    "UMAT2 = u.show(som, distance2=1, row_normalized=False, show_data=True, contooor=False, blob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook[:,0].reshape(x_side, y_side).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(xyv.reshape(x_side, y_side))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(UMAT.flatten('C').reshape(x_side, y_side))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from itertools import product\n",
    "# from string import ascii_lowercase\n",
    "# keywords = [''.join(i) for i in product(ascii_lowercase, repeat = 2)]\n",
    "# keywords = keywords[0:len(df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb = pd.DataFrame(data=codebook, columns=df.columns.str.replace('_',' '))#keywords)\n",
    "df_cb['U-matrix'] = UMAT.flatten('C')\n",
    "df_cb['X'] = xv\n",
    "df_cb['Y'] = yv\n",
    "df_cb['XY'] = xyv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns = keywords\n",
    "df['WSO1_ID'] = shp_key.values\n",
    "df['som_key'] = som._bmu[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outjson_raw = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments//ruwedata.json'\n",
    "# outgzip_raw = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments//ruwedata.gzip'\n",
    "# df.to_json(outjson_raw, orient='records')\n",
    "# df.to_json(outgzip_raw, orient='records', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_file_in = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments\\Stations_total_v3.shp'\n",
    "gdf = gpd.read_file(shp_file_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a copy of our layer\n",
    "gdf_proj = gdf.copy()\n",
    "\n",
    "# Reproject the geometries by replacing the values with projected ones\n",
    "gdf_proj['geometry'] = gdf_proj['geometry'].to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_proj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merge_df = gdf.merge(df, on='WSO1_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sel = gdf_merge_df.loc[:,['WSO1_ID', 'station', 'som_key', 'Country', 'geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som_key_all = np.sort(gdf_sel['som_key'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(som_key_all, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = pd.DataFrame(np.array((unique.astype(int), counts)).T, columns=['som_key_unique', 'Total stations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb_counts = pd.merge(df_cb, df_counts, left_on='XY', right_on='som_key_unique', how='left')\n",
    "df_cb_counts.drop('som_key_unique', axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dropdp = gdf_sel.drop_duplicates(subset = ['WSO1_ID', 'station', 'som_key', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_dropdp.loc[:,'som_key'] = gdf_dropdp.loc[:,'som_key'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_locs_out = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments\\stations_EU_discharge.json'\n",
    "with open(json_locs_out, 'w') as f:\n",
    "    f.write(gdf_dropdp.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_som_out = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments\\som_EU_discharge.csv'\n",
    "df_cb_counts.to_csv(csv_som_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DATAPORTAL\n",
    "from hkvportal.io.services import dataportal as dp\n",
    "dp = dp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.setDataservice(dataservice = 'https://data.hkvservices.nl/dataservices/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.createDatabase(database = 'EU_extreme_discharge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vega specs vanuit bestand laden\n",
    "import json\n",
    "#vega_spec_path = r'D:\\jupyter notebooks\\3348.10 WAP Awash - Ethiopie\\JSON-files\\Awash_weredas.json'\n",
    "vega_spec = json.load(open(json_locs_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json data uploaden naar data portal\n",
    "dp.setEntryDatabase(database = 'EU_extreme_discharge', key = 'stations', data = json.dumps(vega_spec), description = 'Stations EU extreme river discharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb_counts = df_cb_counts.applymap(\"{0:.3f}\".format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb_counts.loc[:,['X','Y','XY']] = df_cb_counts.loc[:,['X','Y','XY']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cb_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = io.BytesIO()\n",
    "output = StringIO()\n",
    "df_cb_counts.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.setEntryDatabase(database = 'EU_extreme_discharge', key = 'som', data = output.getvalue(), description = 'Self-organizing map EU extreme river discharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vega specs vanuit bestand laden\n",
    "import json\n",
    "vega_spec_path = r'D:\\Projects\\RO\\Jong HKV\\Toeleveringen\\DominikPaprotny\\ExtremeDischargesEUCatchments\\vega3_EU_discharge.json'\n",
    "vega_spec_SOM = json.load(open(vega_spec_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json data uploaden naar data portal\n",
    "dp.setEntryDatabase(database = 'EU_extreme_discharge', key = 'vegaspec', data = json.dumps(vega_spec_SOM), description = 'Vega3 specification EU extreme river discharges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
