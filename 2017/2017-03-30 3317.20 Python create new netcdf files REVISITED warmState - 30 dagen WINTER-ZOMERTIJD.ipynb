{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 07 10:35:29 2016\n",
    "\n",
    "@author: Job Verkaik, Mattijn van Hoek, HKV Lijn in water\n",
    "\"\"\"\n",
    "from os.path import isdir\n",
    "#from fewslogger import Logger\n",
    "import datetime\n",
    "import sys, getopt, shutil\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "from xml.etree.ElementTree import Element, SubElement, Comment\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Functions \n",
    "#=======================================================================================\n",
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "def writeState(state_config_read, state_config_write, stateTime):\n",
    "    \"\"\"\n",
    "    stateFile  ::  absolute path to write xml file\n",
    "    stateTime  ::  in 'yyyy-mm-dd' format\n",
    "    \"\"\"\n",
    "    eTree = ElementTree.parse(state_config_read).getroot()\n",
    "    # start xml\n",
    "    xml = Element('State')\n",
    "    xml.set('xmlns','http://www.wldelft.nl/fews')\n",
    "    xml.set('xmlns:xsi','http://www.w3.org/2001/XMLSchema-instance')\n",
    "    xml.set('xsi:schemaLocation','http://www.wldelft.nl/fews/PI http://fews.wldelft.nl/schemas/version1.0/pi-schemas/pi_state.xsd')\n",
    "    xml.set('version','1.2')\n",
    "\n",
    "    stateID = SubElement(xml,'stateId').text = eTree[0].text\n",
    "    timeZone = SubElement(xml,'timeZone').text = eTree[1].text\n",
    "    dateTime = SubElement(xml,'dateTime')\n",
    "    dateTime.set('date',stateTime)\n",
    "    dateTime.set('time',eTree[2].attrib.get('time'))\n",
    "    stateLoc = SubElement(xml,'stateLoc')\n",
    "    stateLoc.set('type','file')\n",
    "    readLocation = SubElement(stateLoc, 'readLocation').text = eTree[3][0].text\n",
    "    writeLocation = SubElement(stateLoc, 'writeLocation').text = eTree[3][1].text\n",
    "\n",
    "    # save xml to file\n",
    "    with open(state_config_write, 'w') as the_file:\n",
    "        the_file.write(prettify(xml))   \n",
    "\n",
    "def createNETCDF(filename, in_nc_arr=\"\", STATE_COPY_CREATE=0, TIME_LIST=[], HM_ARRAY=[], fillValue = -999.0, state_config_read=\"exportStateConfig.xml\", state_config_write=\"importStateConfig.xml\"):\n",
    "    \"\"\"\n",
    "    filename           ::  path to new NETCDF file\n",
    "    in_nc_arr          ::  base NETCDF file\n",
    "    STATE_COPY_CREATE  ::  set 0 for state\n",
    "                           set 1 for copy\n",
    "                           set 2 for create\n",
    "    TIME_LIST          ::  when creating, provide datetime array with dates\n",
    "    HM_ARRAY           ::  provide array with h.m data to create NETCDF\n",
    "    fillValue          ::  only used during creation [default: -999.0] \n",
    "    stateConfigFile    ::  only used for writing state files [default: \"%s/importStateConfig.xml\" % statedir]    \n",
    "    \"\"\"\n",
    "    # 0 is TimeSeriesSet STATE FILE\n",
    "    # 1 is TimeSeriesSet COPY\n",
    "    # 2 is TimeSeriesSet CREATE\n",
    "    # ------------------------------------------            \n",
    "    # create new warmState\n",
    "    # create new.nc url and open file to write\n",
    "    print(\"entered\")\n",
    "    new_nc = filename\n",
    "    nc_new = netCDF4.Dataset(new_nc, 'w', format=\"NETCDF3_CLASSIC\")\n",
    "\n",
    "    # create dimensions for new nc file based on in.nc\n",
    "    if STATE_COPY_CREATE == 0 :\n",
    "        nt = 1\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        nt = in_nc_arr.dimensions['time'].size\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        nt = len(TIME_LIST)        \n",
    "    ny = in_nc_arr.dimensions['y'].size\n",
    "    nx = in_nc_arr.dimensions['x'].size\n",
    "    nc_new.createDimension('time', nt)\n",
    "    nc_new.createDimension('y', ny)\n",
    "    nc_new.createDimension('x', nx)\n",
    "\n",
    "    # copy over time variable from in.nc [only first slice]\n",
    "    time_innc = in_nc_arr.variables['time']\n",
    "    time = nc_new.createVariable('time', 'f8', ('time',))\n",
    "    if STATE_COPY_CREATE == 0:\n",
    "        print (\"time is: \"+str(time_innc[-1]))\n",
    "        new = time_innc[-1]\n",
    "\n",
    "        new_min = new * 60\n",
    "        new_date = datetime.datetime.fromtimestamp(new_min)#.strftime('%Y-%m-%d')    \n",
    "        new_date = datetime.datetime(*new_date.timetuple()[:3]) #+ datetime.timedelta(hours=1)\n",
    "\n",
    "        up_dateISO = new_date - datetime.timedelta(days=30)\n",
    "        print(3,\"This is updateDepth.py: state_config_read: \"+str(state_config_read))\n",
    "        print(3,\"This is updateDepth.py: state_config_write: \"+str(state_config_write))\n",
    "        print(3,\"This is updateDepth.py: state_config_write: \"+str(up_dateISO.strftime('%Y-%m-%d')))\n",
    "        writeState(state_config_read, state_config_write, stateTime=up_dateISO.strftime('%Y-%m-%d'))\n",
    "        up_date = datetime.datetime.timestamp(up_dateISO)\n",
    "        print(3,\"This is updateDepth.py: warmStateTime in ISO: \"+str(up_date))\n",
    "        up_min = up_date / 60                \n",
    "        time[:] = up_min #time_innc[-1]\n",
    "        \n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        time[:] = time_innc[:]\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        time[:] = TIME_LIST\n",
    "#     ws_epoch_min = time_innc[-1] * 60\n",
    "#     ws_datetime = datetime.datetime.fromtimestamp(ws_epoch_min).strftime('%Y-%m-%d')\n",
    "#     print(3,\"This is updateDepth.py: warmStateTime in datetime: \"+str(ws_datetime))\n",
    "    time.standard_name = time_innc.standard_name\n",
    "    time.long_name = time_innc.long_name\n",
    "    time.units = time_innc.units\n",
    "    time.axis = time_innc.axis\n",
    "\n",
    "    # copy over y variable from in.nc\n",
    "    y_innc = in_nc_arr.variables['y']\n",
    "    y = nc_new.createVariable('y', 'f8', ('y',), fill_value = y_innc._FillValue ) \n",
    "    y[:] = y_innc[:]\n",
    "    y.standard_name = y_innc.standard_name\n",
    "    y.long_name = y_innc.long_name\n",
    "    y.units = y_innc.units\n",
    "    y.axis = y_innc.axis\n",
    "\n",
    "    # copy over x variable from in.nc\n",
    "    x_innc = in_nc_arr.variables['x']\n",
    "    x = nc_new.createVariable('x', 'f8', ('x'), fill_value = x_innc._FillValue)\n",
    "    x[:] = x_innc[:]\n",
    "    x.standard_name = x_innc.standard_name\n",
    "    x.long_name = x_innc.long_name\n",
    "    x.units = x_innc.units\n",
    "    x.axis = x_innc.axis\n",
    "\n",
    "    # copy over z variable from in.nc\n",
    "    z_innc = in_nc_arr.variables['z']\n",
    "    z = nc_new.createVariable('z', 'f8', ('y', 'x'), fill_value = z_innc._FillValue)\n",
    "    z[:] = z_innc[:]\n",
    "    z.long_name = z_innc.long_name\n",
    "    z.units = z_innc.units\n",
    "    z.axis = z_innc.axis\n",
    "    try:\n",
    "        z.postive = z_innc.positive\n",
    "    except:\n",
    "        l = 1\n",
    "\n",
    "    # copy over lat variable from in.nc\n",
    "    lat_innc = in_nc_arr.variables['lat']\n",
    "    lat = nc_new.createVariable('lat', 'f8', ('y', 'x'), fill_value = lat_innc._FillValue)\n",
    "    lat[:] = lat_innc[:]\n",
    "    lat.standard_name = lat_innc.standard_name\n",
    "    lat.long_name = lat_innc.long_name\n",
    "    lat.units = lat_innc.units\n",
    "\n",
    "    # copy over lat variable from in.nc\n",
    "    lon_innc = in_nc_arr.variables['lon']\n",
    "    lon = nc_new.createVariable('lon', 'f8', ('y', 'x'), fill_value = lon_innc._FillValue)\n",
    "    lon[:] = lon_innc[:]\n",
    "    lon.standard_name = lon_innc.standard_name\n",
    "    lon.long_name = lon_innc.long_name\n",
    "    lon.units = lon_innc.units\n",
    "\n",
    "    # copy over crs variable from in.nc\n",
    "    crs_innc = in_nc_arr.variables['crs']\n",
    "    crs = nc_new.createVariable('crs', 'i4', ())\n",
    "    crs.long_name = crs_innc.long_name\n",
    "    crs.crs_wkt = crs_innc.crs_wkt\n",
    "    crs.proj4_params = crs_innc.proj4_params\n",
    "    crs.epsg_code = crs_innc.epsg_code\n",
    "\n",
    "    # copy over HM variable from in.nc [only first slice]\n",
    "    HM_innc = in_nc_arr.variables['HM']\n",
    "    if STATE_COPY_CREATE == 0:\n",
    "        noDataVal = HM_innc._FillValue\n",
    "    elif STATE_COPY_CREATE == 1:\n",
    "        noDataVal = HM_innc._FillValue\n",
    "    elif STATE_COPY_CREATE == 2:\n",
    "        noDataVal = fillValue\n",
    "    HM = nc_new.createVariable('HM', 'f8', ('time', 'y', 'x'), fill_value = noDataVal)\n",
    "    HM[:] = HM_ARRAY[:]\n",
    "    #HM[:] = hm_out[:]\n",
    "    HM.long_name = HM_innc.long_name\n",
    "    HM.units = HM_innc.units\n",
    "    HM.coordinates = HM_innc.coordinates\n",
    "    HM.grid_mapping = HM_innc.grid_mapping\n",
    "\n",
    "    #close newly created warmState nc file\n",
    "    nc_new.close()        \n",
    "#======================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_config_read = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/exportStateConfig.xml' \n",
    "state_config_write = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/importStateConfig.xml'\n",
    "stateTime = '2016-09-01'\n",
    "writeState(state_config_read, state_config_write, stateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#local = pytz.timezone ('Europe/Amsterdam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 This is updateDepth.py: doe iets slims; M. van Hoek &amp; J. Verkaik, HKV Lijn in water\n",
      "4 Inputdir: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\input\n",
      "4 Statedir: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state\n",
      "4 Outputdir: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\output\n",
      "4 Runfiledir: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\runfile\n",
      "4 Diagnosticsfile: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate//diagnostics.xml\n",
      "3 This is updateDepth.py: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/exportStateConfig.xml :: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/importStateConfig.xml\n",
      "D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\input/in.nc D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/state.nc D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\output/out.nc\n",
      "3 This is updateDepth.py: arrived exception, no new data after warmState\n",
      "3 This is updateDepth.py: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/exportStateConfig.xml :: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/importStateConfig.xml\n",
      "3 This is updateDepth.py: date coldState runfile: 2017-02-28 00:00:00+01:00\n",
      "3 This is updateDepth.py: date time0_date runfile: 2017-03-30 00:00:00+01:00\n",
      "3 This is updateDepth.py: date time0_date runfile: [datetime.datetime(2017, 3, 30, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 29, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 28, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 27, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 26, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 25, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 24, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 23, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 22, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 21, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 20, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 19, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 18, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 17, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 16, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 15, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 14, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 13, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 12, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 11, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 10, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 9, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 8, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 7, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 6, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 5, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 4, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 3, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 2, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 3, 1, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>), datetime.datetime(2017, 2, 28, 0, 0, tzinfo=<StaticTzInfo 'Etc/GMT-1'>)]\n",
      "entered\n",
      "3 upon entering\n",
      "entered\n",
      "time is: 24847140.0\n",
      "3 This is updateDepth.py: state_config_read: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/exportStateConfig.xml\n",
      "3 This is updateDepth.py: state_config_write: D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state/importStateConfig.xml\n",
      "3 This is updateDepth.py: state_config_write: 2017-02-28\n",
      "3 This is updateDepth.py: warmStateTime in ISO: 1488236400.0\n",
      "3 Dat was het, FEWS take over please\n"
     ]
    }
   ],
   "source": [
    "# MAIN PROGRAM  \n",
    "# def main(argv):\n",
    "#     # input argument checking\n",
    "#     try:\n",
    "#         opts, args = getopt.getopt(argv,\"hi:o:s:r:\",[\"ipath=\",\"spath=\",\"opath=\",\"rpath=\"])\n",
    "#     except getopt.GetoptError:\n",
    "#         print ('usage: updateDepth.py -i <inputdir> -s <statedir> -o <outputdir> -r <runfiledir>')\n",
    "#         sys.exit(2)\n",
    "#     for opt, arg in opts:\n",
    "#         if opt == '-h':\n",
    "#             print ('updateDepth.py -i <inputdir> -s <statedir> -o <outputdir> -r <runfiledir>')\n",
    "#             sys.exit()\n",
    "#         elif opt in (\"-i\", \"--inputdir\"):\n",
    "#             inputdir = arg\n",
    "#         elif opt in (\"-s\", \"--statedir\"):\n",
    "#             statedir = arg\n",
    "#         elif opt in (\"-o\", \"--outputdir\"):\n",
    "#             outputdir = arg\n",
    "#         elif opt in (\"-r\", \"--runfiledir\"):\n",
    "#             runfiledir = arg            \n",
    "inputdir = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\input'\n",
    "statedir = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\state'\n",
    "outputdir = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\output'\n",
    "runfiledir = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate\\runfile'\n",
    "diagnosticsfile = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate//diagnostics.xml'\n",
    "\n",
    "#     diagnosticsfile = \"diagnostics.xml\"\n",
    "#     log = Logger(diagnosticsfile)\n",
    "print(3,\"This is updateDepth.py: doe iets slims; M. van Hoek &amp; J. Verkaik, HKV Lijn in water\")\n",
    "print(4,\"Inputdir: %s\" % inputdir)\n",
    "print(4,\"Statedir: %s\" % statedir)\n",
    "print(4,\"Outputdir: %s\" % outputdir)\n",
    "print(4,\"Runfiledir: %s\" % runfiledir)    \n",
    "print(4,\"Diagnosticsfile: %s\" % diagnosticsfile)\n",
    "\n",
    "\n",
    "try:\n",
    "    # DOE IETS SLIMS VANAF HIER\n",
    "\n",
    "    #shutil.copyfile(\"%s/in.nc\" % inputdir, \"%s/out.nc\" % outputdir)\n",
    "\n",
    "    # load input netcdf and state netcdf\n",
    "    # in_nc = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\input//in.nc'\n",
    "    # state_nc = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\state//state.nc'\n",
    "    # out_nc = r'D:\\OmsWaddenzee\\trunk\\fews\\Modules\\depthUpdate4pythontesting\\output//out.nc'\n",
    "\n",
    "    in_nc = \"%s/in.nc\" % inputdir\n",
    "    state_nc = \"%s/state.nc\" % statedir\n",
    "    state_config_read = \"%s/exportStateConfig.xml\" % statedir\n",
    "    state_config_write = \"%s/importStateConfig.xml\" % statedir\n",
    "    out_nc = \"%s/out.nc\" % outputdir\n",
    "    print(3,\"This is updateDepth.py: \"+str(state_config_read)+\" :: \"+str(state_config_write))            \n",
    "    print(in_nc, state_nc, out_nc)\n",
    "    \n",
    "    in_nc_arr = netCDF4.Dataset(in_nc, )\n",
    "    state_nc_arr = netCDF4.Dataset(state_nc, )\n",
    "    print(in_nc_arr)\n",
    "\n",
    "    print(in_nc_arr.variables.keys()) # get all variable names\n",
    "    hm = in_nc_arr.variables['HM']  # bodemhoogte peiling\n",
    "    hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "    hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "    cs_epoch_min = hm_state_time[0] * 60\n",
    "    cs_datetime = datetime.datetime.fromtimestamp(cs_epoch_min).strftime('%Y-%m-%d')        \n",
    "    print(3,\"This is updateDepth.py: coldStateTime in ms since epoch: \"+str(cs_datetime))\n",
    "\n",
    "    # create copy in.nc\n",
    "    hm_copy = np.copy(hm)\n",
    "    hm_copy = np.ma.masked_equal(hm_copy, -999)\n",
    "\n",
    "    # create deep copy in.nc\n",
    "    hm_deep_copy = np.full(hm.shape, -999)\n",
    "    hm_deep_copy = np.ma.masked_equal(hm_deep_copy, -999)       \n",
    "\n",
    "    # use coldState to update first slice in.nc\n",
    "    a = hm[0,::] \n",
    "    b = hm_state[0,::]\n",
    "    # update first slice based on coldState\n",
    "    a[~b.mask] = b.compressed()\n",
    "    hm_copy[0,::] = a\n",
    "    hm_deep_copy[0,::] = np.ma.copy(a)\n",
    "\n",
    "    # create init warmState\n",
    "    hm_out = hm_copy[0,::]\n",
    "\n",
    "    for ix in range(hm.shape[0] - 1):    \n",
    "        # print (ix)\n",
    "        # one by one fill/update and ammend arrays\n",
    "        # get first slice of copy, get second slice of original\n",
    "        a = hm_copy[ix,::] \n",
    "        b = hm[ix+1,::]  \n",
    "\n",
    "        # update first slice based on second slice\n",
    "        a[~b.mask] = b.compressed()\n",
    "        # update timeSeriesSet\n",
    "        hm_copy[ix+1,::] = a\n",
    "        hm_deep_copy[ix+1,::] = np.ma.copy(a)\n",
    "        # update warmState\n",
    "        hm_out[~a.mask] = a.compressed()          \n",
    "\n",
    "    # ------------------------------------------            \n",
    "    # create new warmState\n",
    "    # create NETCDF file for new timeSeriesSet        \n",
    "    createNETCDF(state_nc, in_nc_arr = in_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = hm_out, state_config_read=state_config_read, state_config_write=state_config_write)\n",
    "\n",
    "\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # create out.nc timeSeriesSet\n",
    "    # create new.nc url and open file to write\n",
    "    createNETCDF(out_nc, in_nc_arr = in_nc_arr, STATE_COPY_CREATE = 1, HM_ARRAY = hm_deep_copy )\n",
    "\n",
    "\n",
    "except:\n",
    "    try:\n",
    "        print(3,\"This is updateDepth.py: arrived exception, no new data after warmState\")\n",
    "        state_nc = \"%s/state.nc\" % statedir\n",
    "        state_config_read = \"%s/exportStateConfig.xml\" % statedir\n",
    "        state_config_write = \"%s/importStateConfig.xml\" % statedir        \n",
    "        runfile_xml = \"%s/runfile.xml\" % runfiledir\n",
    "        print(3,\"This is updateDepth.py: \"+str(state_config_read)+\" :: \"+str(state_config_write))        \n",
    "\n",
    "        # set timezone naar GMT-1\n",
    "        local = pytz.timezone ('Etc/GMT-1')\n",
    "        \n",
    "        state_nc_arr = netCDF4.Dataset(state_nc, )        \n",
    "        hm_state = state_nc_arr.variables['HM']  # coldState\n",
    "        hm_state_time = state_nc_arr.variables['time']  # coldState\n",
    "        cs_epoch_min = hm_state_time[0] * 60\n",
    "        cs_date = datetime.datetime.fromtimestamp(cs_epoch_min)#.strftime('%Y-%m-%d')    \n",
    "        cs_date = datetime.datetime(*cs_date.timetuple()[:3]) #+ datetime.timedelta(hours=1)\n",
    "        cs_date = local.localize(cs_date, is_dst=None)\n",
    "        print(3,\"This is updateDepth.py: date coldState runfile: \"+str(cs_date.isoformat()))\n",
    "\n",
    "        # open runfile.xml and get time0 date in datetime format\n",
    "        e = ElementTree.parse(runfile_xml).getroot()\n",
    "        time0 = e[3].attrib.get('date') # e[3] is time0 in xml file\n",
    "        # get timezone element as integer\n",
    "        timezone=int(float(e[0].text))\n",
    "\n",
    "        # get t0 element as datetime object\n",
    "        time0_date = e[3].attrib.get('date') # e[3] is time0 in xml file\n",
    "        time0_date_list = time0_date.replace('-', ' ').split(' ')\n",
    "        time0_time = e[3].attrib.get('time')\n",
    "        time0_time_list = time0_time.replace(':', ' ').split(' ')\n",
    "        time0_dt = datetime.datetime(int(time0_date_list[0]), # year\n",
    "                                     int(time0_date_list[1]), # month\n",
    "                                     int(time0_date_list[2]), # day                                \n",
    "                                     int(time0_time_list[0]), # hour\n",
    "                                     int(time0_time_list[1]), # minute\n",
    "                                     int(time0_time_list[2]), # second\n",
    "                                     ) \n",
    "        time0_dt = time0_dt + datetime.timedelta(hours=timezone)        \n",
    "        time0_dt = datetime.datetime(*time0_dt.timetuple()[:3]) #+ datetime.timedelta(hours=1)\n",
    "        time0_dt = local.localize(time0_dt, is_dst=None)\n",
    "\n",
    "        print(3,\"This is updateDepth.py: date time0_date runfile: \"+str(time0_dt.isoformat())) \n",
    "\n",
    "        # get new datelist in MINUTES since epoch\n",
    "        numdays = time0_dt - cs_date\n",
    "        datesISO = [time0_dt - datetime.timedelta(days=x) for x in range(0, numdays.days + 1)]\n",
    "        datesISO_isoString = [date.isoformat() for date in datesISO]\n",
    "        print(3,\"This is updateDepth.py: date time0_date runfile: \"+str(datesISO_isoString)) \n",
    "\n",
    "        datesEpoch = []\n",
    "        for date in datesISO:\n",
    "            datesEpoch.append(date.timestamp() / 60.)    \n",
    "        datesEpoch.reverse()\n",
    "        # create numpy array of epoch\n",
    "        #datesEpoch = np.array(datesEpoch)\n",
    "\n",
    "        # repeat array N times where N is number of days between state and time0\n",
    "        N = len(datesEpoch)\n",
    "        A = np.array(hm_state[0,::])\n",
    "        B = np.asarray([A]*N)\n",
    "\n",
    "        # mask nodata values\n",
    "        hm_out = np.ma.masked_equal(B, -999)\n",
    "\n",
    "        # create NETCDF file for new timeSeriesSet        \n",
    "        createNETCDF(out_nc, in_nc_arr = state_nc_arr, STATE_COPY_CREATE = 2, TIME_LIST = datesEpoch, HM_ARRAY = hm_out )\n",
    "\n",
    "        # open out_NC as input for new WarmStateFile\n",
    "        out_nc_arr = netCDF4.Dataset(out_nc, )    \n",
    "        newHM_out = hm_out[-1]\n",
    "\n",
    "        # create NETCDF file for new WarmStateFile        \n",
    "        print(3,\"upon entering\")         \n",
    "        createNETCDF(state_nc, in_nc_arr = out_nc_arr, STATE_COPY_CREATE = 0, HM_ARRAY = newHM_out, state_config_read=state_config_read, state_config_write=state_config_write)\n",
    "\n",
    "\n",
    "    except Exception as e: \n",
    "        print (str(e))\n",
    "        if not (isdir(inputdir)):\n",
    "            print(1,\"%s is not a valid path\" % inputdir)\n",
    "        elif not (isdir(statedir)):\n",
    "            print(1,\"%s is not a valid path\" % statedir)\n",
    "        elif not (isdir(outputdir)):\n",
    "            print(1,\"%s is not a valid path\" % outputdir)\n",
    "        elif not (isdir(runfiledir)):\n",
    "            print(1,\"%r is not a valid path\" % runfiledir)\n",
    "        else:\n",
    "            print(1,\"something else is funky\")            \n",
    "\n",
    "# TOT HIER\n",
    "print(3,\"Dat was het, FEWS take over please\")\n",
    "# log.close()\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-02-28T00:00:00+01:00'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(cs_date.isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-03-30 00:00:00+01:00'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(time0_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-03-30T00:00:00+01:00',\n",
       " '2017-03-29T00:00:00+01:00',\n",
       " '2017-03-28T00:00:00+01:00',\n",
       " '2017-03-27T00:00:00+01:00',\n",
       " '2017-03-26T00:00:00+01:00',\n",
       " '2017-03-25T00:00:00+01:00',\n",
       " '2017-03-24T00:00:00+01:00',\n",
       " '2017-03-23T00:00:00+01:00',\n",
       " '2017-03-22T00:00:00+01:00',\n",
       " '2017-03-21T00:00:00+01:00',\n",
       " '2017-03-20T00:00:00+01:00',\n",
       " '2017-03-19T00:00:00+01:00',\n",
       " '2017-03-18T00:00:00+01:00',\n",
       " '2017-03-17T00:00:00+01:00',\n",
       " '2017-03-16T00:00:00+01:00',\n",
       " '2017-03-15T00:00:00+01:00',\n",
       " '2017-03-14T00:00:00+01:00',\n",
       " '2017-03-13T00:00:00+01:00',\n",
       " '2017-03-12T00:00:00+01:00',\n",
       " '2017-03-11T00:00:00+01:00',\n",
       " '2017-03-10T00:00:00+01:00',\n",
       " '2017-03-09T00:00:00+01:00',\n",
       " '2017-03-08T00:00:00+01:00',\n",
       " '2017-03-07T00:00:00+01:00',\n",
       " '2017-03-06T00:00:00+01:00',\n",
       " '2017-03-05T00:00:00+01:00',\n",
       " '2017-03-04T00:00:00+01:00',\n",
       " '2017-03-03T00:00:00+01:00',\n",
       " '2017-03-02T00:00:00+01:00',\n",
       " '2017-03-01T00:00:00+01:00',\n",
       " '2017-02-28T00:00:00+01:00']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[date.isoformat() for date in datesISO]#datesISO#.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "local = pytz.timezone ('Europe/Amsterdam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datetime.datetime(2017, 3, 30, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "utc_datetime = datetime.datetime.utcnow()\n",
    "utc_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "datetime.datetime(2017, 3, 30, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.daylight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wintertime = 'W. Europe'# Standard Time'\n",
    "summertime = 'W. Europe Daylight Time'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pytz, datetime\n",
    "#local = pytz.timezone ('Etc/GMT+0')\n",
    "local = pytz.timezone ('Europe/Amsterdam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "naive = datetime.datetime.strptime (\"2017-3-31 12:0:0\", \"%Y-%m-%d %H:%M:%S\")\n",
    "local_dt = local.localize(naive, is_dst=None)\n",
    "utc_dt = local_dt.astimezone (pytz.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 3, 31, 12, 0, tzinfo=<DstTzInfo 'Europe/Amsterdam' CEST+2:00:00 DST>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_dt#.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 3, 31, 10, 0, tzinfo=<UTC>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utc_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-03-31T12:00:00+02:00'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_dt.isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
