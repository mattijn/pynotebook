{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime\n",
    "import netCDF4 as nc4\n",
    "import h5py as h5py \n",
    "import requests\n",
    "#from IPython.core.debugger import set_trace\n",
    "import gpm2local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundingbox_country(country, output_as='boundingbox'):\n",
    "    \"\"\"\n",
    "    get the bounding box of a country in EPSG4326 given a country name\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    country : str\n",
    "        name of the country in english and lowercase\n",
    "    output_as : 'str\n",
    "        chose from 'boundingbox' or 'center'. \n",
    "         - 'boundingbox' for [latmin/ymin, latmax/ymax, \n",
    "                              lonmin/xmin, lonmax/xmax]\n",
    "         - 'center' for [latcenter, loncenter]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output : list\n",
    "        list with coordinates as str\n",
    "    \"\"\"\n",
    "    url = '{0}{1}{2}'.format('http://nominatim.openstreetmap.org/search?country=',\n",
    "                             country,\n",
    "                             '&format=json&polygon=0')\n",
    "    response = requests.get(url).json()[0]\n",
    "    # set_trace()\n",
    "    if output_as == 'boundingbox':\n",
    "        lst = response[output_as]\n",
    "        output = [float(i) for i in lst]\n",
    "    if output_as == 'center':\n",
    "        lst = [response.get(key) for key in ['lat','lon']]\n",
    "        output = [float(i) for i in lst]\n",
    "    try:\n",
    "        return output\n",
    "    except:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hdf2nc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7c8501278b3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# get extent from country\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mextent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhdf2nc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_boundingbox_country\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# list ftp of last two months\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hdf2nc' is not defined"
     ]
    }
   ],
   "source": [
    "country = 'nl'\n",
    "datetime_of_interest = datetime(2017,11,1,12)\n",
    "period = 2\n",
    "\n",
    "# get extent from country    \n",
    "extent = hdf2nc.get_boundingbox_country(country)\n",
    "\n",
    "# list ftp of last two months\n",
    "df = gpm2hdf.list_ftp(date=datetime_of_interest)\n",
    "\n",
    "# get selection that fits the period\n",
    "T0 = df.iloc[df.index.get_loc(gpm2hdf.get_utc(datetime_of_interest), method='nearest')]\n",
    "sel_gpm_files = df.loc[T0.name - relativedelta(hours=period):T0.name]\n",
    "\n",
    "# fetch gpm-files\n",
    "outfiles = gpm2hdf.fetch_GPM_IMERG(sel_gpm_files, outdir = outdir)\n",
    "\n",
    "# init netcdf by using first hdf-file\n",
    "hdf_file = os.path.join(outdir,sel_gpm_files.iloc[0]['name'])\n",
    "array, x, y, nan_value = hdf2nc.hdf2tif(hdf_file, extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 11, 1, 12, 0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def window_from_extent(xmin, xmax, ymin, ymax, aff):\n",
    "#     col_start, row_start = ~aff * (xmin, ymax)\n",
    "#     col_stop, row_stop = ~aff * (xmax, ymin)\n",
    "#     return ((int(row_start), int(row_stop)), (int(col_start), int(col_stop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord(file):\n",
    "    \"\"\"\n",
    "    function to get coordinates of gdal array computed from GeoTransform\n",
    "    \"\"\"\n",
    "    padfTransform = file.GetGeoTransform()\n",
    "    indices = np.indices(file.ReadAsArray().shape)\n",
    "    xp = padfTransform[0] + indices[1]*padfTransform[1] + indices[1]*padfTransform[2]   \n",
    "    yp = padfTransform[3] + indices[0]*padfTransform[4] + indices[0]*padfTransform[5]  \n",
    "    return xp,yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tif(destName, array, fill_value, rows, cols, top_left_x, top_left_y, x_step=0.1, y_step=0.1, rotation=0):\n",
    "    \"\"\"\n",
    "    function to create tif file\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output tiff file.\n",
    "    # driver.Create() parameters are: output path, number of columns, number of rows,\n",
    "    # number of bands, data type\n",
    "    driver = gdal.GetDriverByName(\"GTiff\")\n",
    "    out_tif = driver.Create(destName, cols, rows, 1, gdal.GDT_Float32)\n",
    "\n",
    "    # Create Spatial Reference object and set GeoTIFF projection.\n",
    "    # This information may be found in either the data documentation or the netCDF file.\n",
    "    prj = osr.SpatialReference()\n",
    "    prj.ImportFromEPSG(4326) # WGS84\n",
    "    out_tif.SetProjection(prj.ExportToWkt())\n",
    "\n",
    "    # Set GeoTransformation.\n",
    "    # This information may be found in either the data documentation, the netCDF file, or\n",
    "    # can be derived. For example, if you know the longitude range and number of columns\n",
    "    # you can calculate the x step as float(lon_range)/float(num_cols).\n",
    "    geotrans = [top_left_x,x_step,rotation,top_left_y,rotation,-y_step]\n",
    "    out_tif.SetGeoTransform(geotrans)\n",
    "\n",
    "    # Finally we can write the array to the raster band.\n",
    "    out_band = out_tif.GetRasterBand(1)    \n",
    "    out_band.SetNoDataValue(fill_value)\n",
    "    out_band.WriteArray(array)\n",
    "\n",
    "    # Clear the memory and close the output file.\n",
    "    out_tif.FlushCache()\n",
    "    out_tif = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf2tif(hdf_file, extent):\n",
    "    \"\"\"\n",
    "    function to convert hdf file to tif using an given extent\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    hdf_file : str\n",
    "        path to hdf file\n",
    "    extent : list\n",
    "        bounding box of extent to clip from hdf_file \n",
    "        list is [ymin, ymax, xmin, xmax] (coords in epsg4326)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    array : np.array\n",
    "        array containing the values of clipped extent\n",
    "    x : np.array\n",
    "        longitude coordinates of array\n",
    "    y : np.array\n",
    "        latitude coordinates of array\n",
    "    nan_value : float\n",
    "        fill value of array\n",
    "    \"\"\"\n",
    "    dataset = h5py.File(hdf_file, 'r')\n",
    "\n",
    "    # # get metadata\n",
    "    # for attr_name in dataset['Grid/precipitationCal'].attrs:\n",
    "    #     print('attr_name : {0}\\nattr_value: {1}\\n'.format(\n",
    "    #         attr_name,\n",
    "    #         dataset['Grid/precipitationCal'].attrs[attr_name]))\n",
    "\n",
    "    fill_value = dataset['Grid/precipitationCal'].attrs['_FillValue'].astype(float)\n",
    "\n",
    "    # get data\n",
    "    precip = dataset['Grid/precipitationCal'][:]\n",
    "    precip = np.transpose(precip) \n",
    "\n",
    "    # get lon/lat array\n",
    "    lats = dataset['Grid/lat'][:]\n",
    "    lons = dataset['Grid/lon'][:]\n",
    "\n",
    "    # get array dimensions\n",
    "    rows, cols = (len(lats), len(lons))\n",
    "\n",
    "    # get top-left coordinate + stepsize\n",
    "    top_left_x = lons.min()\n",
    "    top_left_y = lats.max()\n",
    "    x_step = 0.1\n",
    "    y_step = 0.1\n",
    "    rotation = 0\n",
    "\n",
    "    # write to tif\n",
    "    destName = r'D:\\My Projects\\gpm2thredds\\trunk\\test\\tmp.tif'\n",
    "    create_tif(destName, precip, fill_value, rows, cols, top_left_x, top_left_y, x_step, y_step)\n",
    "\n",
    "    # prepare for gdalwrap\n",
    "    xmin = extent[2]\n",
    "    xmax = extent[3]\n",
    "    ymin = extent[0]\n",
    "    ymax = extent[1]\n",
    "\n",
    "    srcDS = destName\n",
    "    desDS = r'D:\\My Projects\\gpm2thredds\\trunk\\test//clipped_data.tif'\n",
    "    warp_options = gdal.WarpOptions(outputBounds=(xmin, ymin, xmax, ymax))\n",
    "    res = gdal.Warp(desDS, srcDS, options=warp_options)\n",
    "\n",
    "    # open cipped array and check extent\n",
    "    ds = gdal.Open(desDS, gdal.GA_ReadOnly) # A GeoTiff file\n",
    "    x,y = coord(ds)\n",
    "    band = ds.GetRasterBand(1)\n",
    "    nan_value = band.GetNoDataValue()\n",
    "    array = band.ReadAsArray()\n",
    "    print('x: {0}\\ny: {1}'.format(x[0][np.r_[0, -1]],y[:,0][np.r_[0, -1]]))\n",
    "    ds = None\n",
    "    return array, x, y, nan_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_netcdf(x, y, nan_value, desNC = r'D:\\My Projects\\gpm2thredds\\trunk\\test//hours_two.nc'):\n",
    "    \"\"\"\n",
    "    function to initate a netcdf file given the longitude, latitude and nan_value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : numpy.array\n",
    "        1 dimensional array providing the values on longitude axis (from left to right)\n",
    "    y : numpy.array\n",
    "        1 dimensional array providing the values on latiude axis (from top to bottom)\n",
    "    nan_value : float\n",
    "        value that is used as fill value for the precipitation variable\n",
    "    desNC : str\n",
    "        destination netcdf file, path to write\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    f : nc4.Dataset\n",
    "        netcdf4 parent dataset\n",
    "    nc_prc : nc4.Variable\n",
    "        netcdf4 child variable, in this case the precipitation variable\n",
    "    nc_time : nc4.Variable\n",
    "        netcdf4 child variable, in this case the time variable\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    f = nc4.Dataset(desNC,'w', format='NETCDF4') #'w' stands for write\n",
    "\n",
    "    # create group\n",
    "    precipgrp = f.createGroup('3IMERG')    \n",
    "    \n",
    "    # create dimensions\n",
    "    precipgrp.createDimension('lon', len(x[0]))\n",
    "    precipgrp.createDimension('lat', len(y[:,0]))\n",
    "    precipgrp.createDimension('time', None)    \n",
    "    \n",
    "    # create variables\n",
    "    nc_lon = precipgrp.createVariable('Longitude', 'f4', 'lon')\n",
    "    nc_lat = precipgrp.createVariable('Latitude', 'f4', 'lat')  \n",
    "    nc_prc = precipgrp.createVariable('Precipitation', 'f4', ('time', 'lon', 'lat'), fill_value=nan_value)\n",
    "    nc_time = precipgrp.createVariable('Time', 'i4', 'time')    \n",
    "    \n",
    "    # fill variables\n",
    "    nc_lon[:] = x[0]\n",
    "    nc_lat[:] = y[:,0]\n",
    "\n",
    "    # add global attributes\n",
    "    f.description = \"NETCDF File containing GPM 3IMERG data\"    \n",
    "\n",
    "    # add local attributes to variable instances\n",
    "    nc_lon.units = 'degrees_east'\n",
    "    nc_lon.axis = 'X'\n",
    "    \n",
    "    nc_lat.units = 'degrees_north'\n",
    "    nc_lat.axis = 'Y'\n",
    "    \n",
    "    nc_prc.units = 'millimeter hour-1'\n",
    "    nc_prc.long_name = 'precipitation in millimeter per hour'\n",
    "    \n",
    "    nc_time.units = 'seconds since 1970-01-01 00:00:00 UTC'\n",
    "    nc_time.long_name = 'time in seconds since epoch'\n",
    "    nc_time.standard_name = 'time'\n",
    "    nc_time.axis = 'T'      \n",
    "\n",
    "    return f, nc_prc, nc_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "test the fetch_gpm function to get all images from last two hours available\n",
    "\"\"\"\n",
    "period = [2,8,12,48] # hours\n",
    "outdir = r'D:\\My Projects\\gpm2thredds\\trunk\\test\\test_fetch_gpm'\n",
    "#outdir = os.path.join(os.path.dirname(__file__), 'test_fetch_gpm')\n",
    "outfiles = []\n",
    "datetime_of_interest = datetime.now()\n",
    "\n",
    "# list ftp\n",
    "df = gpm2local.list_ftp(date=datetime_of_interest)\n",
    "T0 = df.iloc[df.index.get_loc(gpm2local.get_utc(datetime_of_interest),method='nearest')]\n",
    "logging.info('from : {0}'.format(T0.name - relativedelta(hours=period[0])))\n",
    "logging.info('to   : {0}'.format(T0.name))\n",
    "sel_gpm_files = df.loc[T0.name - relativedelta(hours=period[0]):T0.name]\n",
    "\n",
    "# fetch gpm-files\n",
    "outfiles = gpm2local.fetch_GPM_IMERG(sel_gpm_files, outdir = outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date_start\n",
       "2018-01-11 06:30:00+00:00    3B-HHR-E.MS.MRG.3IMERG.20180111-S063000-E06595...\n",
       "2018-01-11 07:00:00+00:00    3B-HHR-E.MS.MRG.3IMERG.20180111-S070000-E07295...\n",
       "2018-01-11 07:30:00+00:00    3B-HHR-E.MS.MRG.3IMERG.20180111-S073000-E07595...\n",
       "2018-01-11 08:00:00+00:00    3B-HHR-E.MS.MRG.3IMERG.20180111-S080000-E08295...\n",
       "2018-01-11 08:30:00+00:00    3B-HHR-E.MS.MRG.3IMERG.20180111-S083000-E08595...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_gpm_files.name#.strftime('%Y%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-min_max -70.2695876 7.2274985\n",
      "y-min_max 11.777 53.7253321\n"
     ]
    }
   ],
   "source": [
    "# get extent from country\n",
    "extent = get_boundingbox_country(country='nl')\n",
    "print('x-min_max {2} {3}\\ny-min_max {0} {1}'.format(\n",
    "    extent[0], extent[1], extent[2], extent[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\My Projects\\\\gpm2thredds\\\\trunk\\\\test\\\\test_fetch_gpm\\\\3B-HHR-E.MS.MRG.3IMERG.20180111-S063000-E065959.0390.V05B.RT-H5',\n",
       " 'D:\\\\My Projects\\\\gpm2thredds\\\\trunk\\\\test\\\\test_fetch_gpm\\\\3B-HHR-E.MS.MRG.3IMERG.20180111-S070000-E072959.0420.V05B.RT-H5',\n",
       " 'D:\\\\My Projects\\\\gpm2thredds\\\\trunk\\\\test\\\\test_fetch_gpm\\\\3B-HHR-E.MS.MRG.3IMERG.20180111-S073000-E075959.0450.V05B.RT-H5',\n",
       " 'D:\\\\My Projects\\\\gpm2thredds\\\\trunk\\\\test\\\\test_fetch_gpm\\\\3B-HHR-E.MS.MRG.3IMERG.20180111-S080000-E082959.0480.V05B.RT-H5',\n",
       " 'D:\\\\My Projects\\\\gpm2thredds\\\\trunk\\\\test\\\\test_fetch_gpm\\\\3B-HHR-E.MS.MRG.3IMERG.20180111-S083000-E085959.0510.V05B.RT-H5']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [-70.2695876    7.12750226]\n",
      "y: [ 53.7253321   11.87711535]\n"
     ]
    }
   ],
   "source": [
    "#path_in = r'D:\\My Projects\\gpm2thredds\\trunk\\test\\test_fetch_gpm'\n",
    "\n",
    "hdf_file = os.path.join(outdir,sel_gpm_files.iloc[0]['name'])\n",
    "array, x, y, nan_value = hdf2tif(hdf_file, extent)\n",
    "f, nc_prc, nc_time = init_netcdf(x, y, nan_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-11-24 02:30:00+00:00\n",
      "3B-HHR-E.MS.MRG.3IMERG.20171124-S023000-E025959.0150.V04B.RT-H5\n",
      "\n",
      "\n",
      "2017-11-24 03:00:00+00:00\n",
      "3B-HHR-E.MS.MRG.3IMERG.20171124-S030000-E032959.0180.V04B.RT-H5\n",
      "\n",
      "\n",
      "2017-11-24 03:30:00+00:00\n",
      "3B-HHR-E.MS.MRG.3IMERG.20171124-S033000-E035959.0210.V04B.RT-H5\n",
      "\n",
      "\n",
      "2017-11-24 04:00:00+00:00\n",
      "3B-HHR-E.MS.MRG.3IMERG.20171124-S040000-E042959.0240.V04B.RT-H5\n",
      "\n",
      "\n",
      "2017-11-24 04:30:00+00:00\n",
      "3B-HHR-E.MS.MRG.3IMERG.20171124-S043000-E045959.0270.V04B.RT-H5\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, gpm_file in sel_gpm_files.iterrows():\n",
    "    print(idx)\n",
    "    print(gpm_file['name'])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_E = sel_gpm_files.index[np.r_[0, -1]]\n",
    "S = S_E[0].strftime('S%Y%m%d-%H%M.%p')\n",
    "E = S_E[1].strftime('E%Y%m%d-%H%M.%p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "x: [-70.2695876    7.12750226]\n",
      "y: [ 53.7253321   11.87711535]\n",
      "1\n",
      "x: [-70.2695876    7.12750226]\n",
      "y: [ 53.7253321   11.87711535]\n",
      "2\n",
      "x: [-70.2695876    7.12750226]\n",
      "y: [ 53.7253321   11.87711535]\n",
      "3\n",
      "x: [-70.2695876    7.12750226]\n",
      "y: [ 53.7253321   11.87711535]\n",
      "4\n",
      "x: [-70.2695876    7.12750226]\n",
      "y: [ 53.7253321   11.87711535]\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "for i, row in sel_gpm_files.iterrows(): \n",
    "    #print(idx)\n",
    "    # get start timestamp\n",
    "    tstamp = sel_gpm_files.iloc[idx].name\n",
    "    # get name hdf file\n",
    "    hdf_file = os.path.join(outdir,sel_gpm_files.iloc[idx]['name'])\n",
    "    # get subset array\n",
    "    array, x, y, nan_value = hdf2tif(hdf_file, extent)\n",
    "    # set array in netcdf\n",
    "    nc_prc[idx,:,:] = np.flipud(array.T)  \n",
    "    # set timestamp in netcdf (in seconds since epoch)\n",
    "    nc_time[idx] = tstamp.timestamp()\n",
    "    idx += 1\n",
    "f.history = \"Created \" + datetime.now().strftime(\"%d/%m/%Y | %H:%M %p\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
