{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal, ogr, osr\n",
    "from osgeo.gdalconst import *\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "gdal.PushErrorHandler('CPLQuietErrorHandler')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shapely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shapely.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.geos import geos_version_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.2-CAPI-1.8.2 r3921'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geos_version_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStatsCounty(cnty_array, feat):\n",
    "    \"\"\"\n",
    "    Core function to calculate statistics to be applied for each county\n",
    "    \n",
    "    Input:  \n",
    "    cnty_array   = Masked raster array of a single county    \n",
    "    feat         = feature of shapefile to extract ID\n",
    "    Output: \n",
    "    county_stats = Dictionary containing the stats for the county\n",
    "    \"\"\"\n",
    "    \n",
    "    dc=0\n",
    "    #percentage of no drought\n",
    "    p0=(cnty_array[(cnty_array <= 0) ]).size*1.0/cnty_array.size\n",
    "    if p0>=0.5: dc=1\n",
    "    #percentage of no drought\n",
    "    p1=(cnty_array[(cnty_array<=-0.15)]).size*1.0/cnty_array.size\n",
    "    if p1>0.5: dc=2\n",
    "    #percentage of no drought\n",
    "    p2=(cnty_array[(cnty_array<=-0.25) ]).size*1.0/cnty_array.size\n",
    "    if p2>=0.5: dc=3\n",
    "    #percentage of no drought\n",
    "    p3=(cnty_array[cnty_array <=-0.35]).size*1.0/cnty_array.size\n",
    "    if p3>=0.5: dc=4\n",
    "    #print cnty_array.count(),np.nanmin(cnty_array)\n",
    "    ct=cnty_array.count()\n",
    "    county_stats = {\n",
    "        'MINIMUM': np.nan if ct<2 else float(np.nanmin(cnty_array)),\n",
    "        'MEAN': np.nan if ct<2 else float(np.nanmean(cnty_array)),\n",
    "        'MAX': np.nan if ct<2 else float(np.nanmax(cnty_array)),\n",
    "        'STD': np.nan if ct<2 else float(np.nanstd(cnty_array)),\n",
    "        'SUM': np.nan if ct<2 else float(np.nansum(cnty_array)),\n",
    "        'COUNT': int(cnty_array.count()),\n",
    "        'FID': int(feat.GetFID()),  \n",
    "        'P0':p0,\n",
    "        'P1':p1,\n",
    "        'P2':p2,\n",
    "        'P3':p3,\n",
    "        'DC':dc}\n",
    "    \n",
    "    return county_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bbox_to_pixel_offsets(gt, bbox):\n",
    "    originX = gt[0]\n",
    "    originY = gt[3]\n",
    "    pixel_width = gt[1]\n",
    "    pixel_height = gt[5]\n",
    "    x1 = int((bbox[0] - originX) / pixel_width)\n",
    "    x2 = int((bbox[1] - originX) / pixel_width) + 1\n",
    "\n",
    "    y1 = int((bbox[3] - originY) / pixel_height)\n",
    "    y2 = int((bbox[2] - originY) / pixel_height) + 1\n",
    "\n",
    "    xsize = x2 - x1\n",
    "    ysize = y2 - y1\n",
    "    return (x1, y1, xsize, ysize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zonal_stats(vector_path, raster_path, nodata_value):\n",
    "    \n",
    "    # open raster layer\n",
    "    rds = gdal.Open(raster_path, GA_ReadOnly)\n",
    "    assert(rds)\n",
    "    rb = rds.GetRasterBand(1)\n",
    "    rgt = rds.GetGeoTransform()\n",
    "    \n",
    "    # set raster nodata value\n",
    "    if nodata_value:\n",
    "        nodata_value = float(nodata_value)\n",
    "        rb.SetNoDataValue(nodata_value)\n",
    "    \n",
    "    # open vector layer\n",
    "    vds = ogr.Open(vector_path, GA_ReadOnly)  \n",
    "    assert(vds)\n",
    "    vlyr = vds.GetLayer(0)    \n",
    "    \n",
    "    # compare EPSG values of vector and raster and change projection if necessary\n",
    "    sourceSR = vlyr.GetSpatialRef()\n",
    "    sourceSR.AutoIdentifyEPSG()\n",
    "    EPSG_sourceSR = sourceSR.GetAuthorityCode(None)\n",
    "    \n",
    "    targetSR = osr.SpatialReference(wkt=rds.GetProjection())\n",
    "    targetSR.AutoIdentifyEPSG()\n",
    "    EPSG_targetSR = targetSR.GetAuthorityCode(None)\n",
    "    \n",
    "    if EPSG_sourceSR != EPSG_sourceSR:\n",
    "        # reproject vector geometry to same projection as raster\n",
    "        print 'unequal projections'    \n",
    "        sourceSR = vlyr.GetSpatialRef()\n",
    "        targetSR = osr.SpatialReference()\n",
    "        targetSR.ImportFromWkt(rds.GetProjectionRef())\n",
    "        coordTrans = osr.CreateCoordinateTransformation(sourceSR,targetSR)    \n",
    "        \n",
    "    \"\"\"do the work\"\"\"\n",
    "    global_src_extent = None\n",
    "    mem_drv = ogr.GetDriverByName('Memory')\n",
    "    driver = gdal.GetDriverByName('MEM')\n",
    "    \n",
    "    # Loop through vectors\n",
    "    stats = []\n",
    "    feat = vlyr.GetNextFeature() \n",
    "    \n",
    "    while feat is not None:\n",
    "        # print statement after each hunderds features\n",
    "        fid = int(feat.GetFID())        \n",
    "        if fid % 500 == 0:\n",
    "            print(\"finished first %s features\" % (fid))\n",
    "    \n",
    "        if not global_src_extent:\n",
    "            #print 'bbox county'\n",
    "            # use local source extent\n",
    "            # fastest option when you have fast disks and well indexed raster (ie tiled Geotiff)\n",
    "            # advantage: each feature uses the smallest raster chunk\n",
    "            # disadvantage: lots of reads on the source raster\n",
    "            src_offset = bbox_to_pixel_offsets(rgt, feat.geometry().GetEnvelope())\n",
    "            src_array = rb.ReadAsArray(*src_offset)\n",
    "        \n",
    "            # calculate new geotransform of the feature subset\n",
    "            new_gt = (\n",
    "                (rgt[0] + (src_offset[0] * rgt[1])),\n",
    "                rgt[1],\n",
    "                0.0,\n",
    "                (rgt[3] + (src_offset[1] * rgt[5])),\n",
    "                0.0,\n",
    "                rgt[5]\n",
    "            )\n",
    "        \n",
    "        # Create a temporary vector layer in memory\n",
    "        mem_ds = mem_drv.CreateDataSource('out')\n",
    "        mem_layer = mem_ds.CreateLayer('poly', None, ogr.wkbPolygon)\n",
    "        mem_layer.CreateFeature(feat.Clone())\n",
    "        \n",
    "        # Rasterize it\n",
    "        rvds = driver.Create('', src_offset[2], src_offset[3], 1, gdal.GDT_Byte)\n",
    "        rvds.SetGeoTransform(new_gt)\n",
    "        gdal.RasterizeLayer(rvds, [1], mem_layer, burn_values=[1])\n",
    "        rv_array = rvds.ReadAsArray()\n",
    "        \n",
    "        # Mask the source data array with our current feature\n",
    "        # we take the logical_not to flip 0<->1 to get the correct mask effect\n",
    "        # we also mask out nodata values explictly\n",
    "        try:\n",
    "            masked = np.ma.MaskedArray(\n",
    "                src_array,\n",
    "                mask=np.logical_or(\n",
    "                    src_array == nodata_value,\n",
    "                    np.logical_not(rv_array)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            #print 'feature ID: ',int(feat.GetFID())\n",
    "            \n",
    "            # GET STATISTICS FOR EACH COUNTY\n",
    "            county_stats = getStatsCounty(cnty_array = masked, feat=feat)            \n",
    "            stats.append(county_stats)\n",
    "            \n",
    "            rvds = None\n",
    "            mem_ds = None\n",
    "            feat = vlyr.GetNextFeature()\n",
    "            \n",
    "        except np.ma.MaskError: \n",
    "            # catch MaskError, ignore feature containing no valid corresponding raster data set\n",
    "            # in my case the the most southern county of hainan is not totally within the raster extent            \n",
    "            print 'feature ID: ',fid, ' maskError, ignore county and lets continue'\n",
    "            \n",
    "            rvds = None\n",
    "            mem_ds = None\n",
    "            feat = vlyr.GetNextFeature()            \n",
    "    \n",
    "    vds = None\n",
    "    rds = None\n",
    "    return stats#, src_array, rv_array, masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vector_path = r'D:\\Data\\ChinaShapefile\\Chinese_version_counties//counties_test.shp'\n",
    "raster_path = r'D:\\Data\\NDAI\\NDAI_2014//NDAI_2014_008.tif'\n",
    "nodata_value = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished first 0 features\n",
      "finished first 500 features\n",
      "feature ID:  622  maskError, ignore county and lets continue\n",
      "finished first 1000 features\n",
      "finished first 1500 features\n",
      "finished first 2000 features\n",
      "feature ID:  2292  maskError, ignore county and lets continue\n",
      "finished first 2500 features\n",
      "finished first 3000 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python27x64\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:232: RuntimeWarning: All-NaN axis encountered\n",
      "  warnings.warn(\"All-NaN axis encountered\", RuntimeWarning)\n",
      "D:\\Python27x64\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:598: RuntimeWarning: Mean of empty slice\n",
      "  warnings.warn(\"Mean of empty slice\", RuntimeWarning)\n",
      "D:\\Python27x64\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:331: RuntimeWarning: All-NaN axis encountered\n",
      "  warnings.warn(\"All-NaN axis encountered\", RuntimeWarning)\n",
      "D:\\Python27x64\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1057: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "stats = zonal_stats(vector_path, raster_path, nodata_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(stats)\n",
    "df_stats.set_index('FID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read shapefile and concatate on index using a 'inner' join\n",
    "# meaning counties without statistics info will be ignored\n",
    "gdf = gpd.read_file(vector_path)\n",
    "frames  = [df_stats,gdf]\n",
    "gdf_df_stats = gpd.pd.concat(frames, axis=1, join='inner')\n",
    "gdf_df_stats.index.rename('FID', inplace=True)\n",
    "gdf_df_stats.geometry = gdf_df_stats.geometry.astype(gpd.geoseries.GeoSeries) # overcome bug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdf_df_stats.to_file(r'D:\\Data\\ChinaShapefile\\Chinese_version_counties//counties_test_concat.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# open vector layer\n",
    "vds = ogr.Open(vector_path, GA_ReadOnly)  \n",
    "assert(vds)\n",
    "vlyr = vds.GetLayer(0)    \n",
    "\n",
    "# compare EPSG values of vector and raster and change projection if necessary\n",
    "sourceSR = vlyr.GetSpatialRef()\n",
    "sourceSR.AutoIdentifyEPSG()\n",
    "EPSG_sourceSR = sourceSR.GetAuthorityCode(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vlyr_def = vlyr.GetLayerDefn() #get definitions of the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ADCODE99', 'LAST_NAME9', 'AVE_PROVIN', 'FIRST_NAME']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_names = [vlyr_def.GetFieldDefn(i).GetName() for i in range(vlyr_def.GetFieldCount())] #store the field names as a list of strings\n",
    "print len(field_names)# so there should be just one at the moment called \"FID\"\n",
    "field_names #will show you the current field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named geopandas",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-f8b81fe8ca07>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named geopandas"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tenfold: 0\n",
      "tenfold: 1000\n",
      "tenfold: 2000\n",
      "tenfold: 3000\n",
      "tenfold: 4000\n"
     ]
    }
   ],
   "source": [
    "new_field = ogr.FieldDefn('DC', ogr.OFTInteger) #\n",
    "layer.CreateField(new_field) #self explaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
