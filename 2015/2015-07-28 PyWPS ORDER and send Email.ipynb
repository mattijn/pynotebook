{
 "metadata": {
  "name": "",
  "signature": "sha256:b82194dd211bf15b5f4a02232b2c30762048f843a3593e56f0df66b983b75f32"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pywps.Process import WPSProcess \n",
      "import logging\n",
      "import os\n",
      "import sys\n",
      "import urllib2\n",
      "import urllib\n",
      "from osgeo import gdal\n",
      "import numpy\n",
      "import numpy as np\n",
      "import numpy.ma as ma\n",
      "from lxml import etree\n",
      "#import datetime\n",
      "from datetime import datetime\n",
      "#import matplotlib\n",
      "#import matplotlib.colors as mcolors\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "from cStringIO import StringIO\n",
      "#import cStringIO\n",
      "import jdcal\n",
      "import json\n",
      "import smtplib\n",
      "from email.MIMEMultipart import MIMEMultipart\n",
      "from email.MIMEText import MIMEText\n",
      "import base64\n",
      "import uuid\n",
      "import re\n",
      "from pydap.client import open_url\n",
      "import datetime as dt\n",
      "import os\n",
      "import sys\n",
      "import gdal\n",
      "import shutil\n",
      "import logging\n",
      "#%matplotlib inline\n",
      "#plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gdal.GDT_Float64"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def PRECIP_DI_CAL(coverageID, request_name, from_date_order,bbox_order, directory):\n",
      "    opendap_url_mon='http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/gpcp/precip.mon.mean.nc'\n",
      "    opendap_url_ltm='http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/gpcp/precip.mon.ltm.nc'\n",
      "\n",
      "    # what is the input of the module\n",
      "    logging.info(from_date_order) \n",
      "    logging.info(bbox_order) \n",
      "\n",
      "    # convert iso-date to gregorian calendar and get the month\n",
      "    dta=(dt.datetime.strptime(from_date_order,'%Y-%m-%d').date()-dt.datetime.strptime('1800-01-01','%Y-%m-%d').date()).days\n",
      "    mon=(dt.datetime.strptime(from_date_order,'%Y-%m-%d').date()).month\n",
      "\n",
      "    # open opendap connection and request the avaialable time + lon/lat\n",
      "    dataset_mon = open_url(opendap_url_mon)\n",
      "    time=dataset_mon.time[:]\n",
      "    lat=dataset_mon.lat[:]\n",
      "    lon=dataset_mon.lon[:]\n",
      "    dt_ind=next((index for index,value in enumerate(time) if value > dta),0)-1\n",
      "\n",
      "\n",
      "    # convert bbox into coordinates and convert OL lon to GPCP lon where needed\n",
      "    minlon = bbox_order[0]\n",
      "    if minlon < 0: minlon += 360 #+ 180 # GPCP is from 0-360, OL is from -180-180\n",
      "    maxlon = bbox_order[2]\n",
      "    if maxlon < 0: maxlon += 360 #+ 180 # GPCP is from 0-360, OL is from -180-180\n",
      "    minlat = bbox_order[1]\n",
      "    maxlat = bbox_order[3]\n",
      "\n",
      "    lat_sel = (lat>minlat)&(lat<maxlat)\n",
      "    lat_sel[np.nonzero(lat_sel)[0]-1] = True\n",
      "\n",
      "    # ugly method to decide if there are two areas to select\n",
      "    # prepare lon/lat subset arrays\n",
      "    check_if = 0 # If this one is 1, than there are two areas to check\n",
      "    if minlon >= maxlon:\n",
      "        check_if = 1\n",
      "        lon_sel = np.invert((lon<minlon)&(lon>maxlon))\n",
      "    else:\n",
      "        lon_sel = (lon>minlon)&(lon<maxlon)    \n",
      "\n",
      "    # request the subset from opendap\n",
      "    dataset_mon=dataset_mon['precip'][dt_ind,lat_sel,lon_sel]\n",
      "    dataset_ltm = open_url(opendap_url_ltm)\n",
      "    dataset_ltm=dataset_ltm['precip'][mon-1,lat_sel,lon_sel]\n",
      "    \n",
      "    mon = np.ma.masked_less((dataset_mon['precip'][:]).squeeze(),0)\n",
      "    ltm = np.ma.masked_less((dataset_ltm['precip'][:]).squeeze(),0)\n",
      "\n",
      "    # if two areas make sure the subset is applied appropriate \n",
      "    if check_if == 1:\n",
      "        subset = np.ones((mon.shape[0]), dtype=bool)[None].T * lon_sel\n",
      "        mon = np.roll(mon, \n",
      "                      len(lon)/2, \n",
      "                      axis=1)[np.roll(subset, \n",
      "                                      len(lon)/2, \n",
      "                                      axis=1)].reshape(mon.shape[0],\n",
      "                                                       subset.sum()/mon.shape[0])    \n",
      "        ltm = np.roll(ltm, \n",
      "                      len(lon)/2, \n",
      "                      axis=1)[np.roll(subset, \n",
      "                                      len(lon)/2, \n",
      "                                      axis=1)].reshape(ltm.shape[0],\n",
      "                                                       subset.sum()/ltm.shape[0])    \n",
      "\n",
      "\n",
      "    # calculate PAP\n",
      "    PAP=(mon-ltm)/(ltm+1)*100\n",
      "    \n",
      "#     PAP[np.where(PAP>200)]=200\n",
      "#     PAP[np.where(PAP<-200)]=-200\n",
      "#     PAP += 200\n",
      "#     PAP //= (400 - 0 + 1) / 256.\n",
      "#     PAP = PAP.astype(np.uint8)    \n",
      "\n",
      "    # prepare output for GDAL\n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm\n",
      "    \n",
      "    #papFileName = 'PRECIP_DI'+date +'.tif'        \n",
      "    driver = gdal.GetDriverByName( \"GTiff\" )\n",
      "    ds = driver.Create(directory, mon.shape[1], mon.shape[0], 1)\n",
      "    \n",
      "    # set projection information\n",
      "    projWKT='GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]]'\n",
      "    ds.SetProjection(projWKT) \n",
      "\n",
      "    # set geotransform information\n",
      "    geotransform_input = dataset_mon.lon[:]\n",
      "    if check_if == 1:\n",
      "        dataset_mon.lon[:][np.where(dataset_mon.lon[:] > 180)] -= 360\n",
      "        geotransform_input = np.roll(dataset_mon.lon[:], len(lon)/2, axis=0)[np.roll(subset, len(lon)/2, axis=1)[0]]\n",
      "    geotransform = (min(geotransform_input),2.5, 0,max(dataset_mon.lat[:]),0,-2.5) \n",
      "    ds.SetGeoTransform(geotransform) \n",
      "\n",
      "    # write the data\n",
      "    ds.GetRasterBand(1).WriteArray(PAP)\n",
      "    ds=None\n",
      "    \n",
      "    print directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _NTAI_CAL(coverageID, request_name, from_date_order,bbox_order, directory):\n",
      "\n",
      "    ##request image cube for the specified date and area by WCS.\n",
      "    #firstly we get the temporal length of avaliable NDVI data from the DescribeCoverage of WCS\n",
      "    endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='DescribeCoverage'\n",
      "    field['COVERAGEID']='modis_11c2_cov'#'trmm_3b42_coverage_1'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    data = urllib.urlopen(full_url).read()\n",
      "    root = etree.fromstring(data)\n",
      "    lc = root.find(\".//{http://www.opengis.net/gml/3.2}lowerCorner\").text\n",
      "    uc = root.find(\".//{http://www.opengis.net/gml/3.2}upperCorner\").text\n",
      "    start_date=int((lc.split(' '))[2])\n",
      "    end_date=int((uc.split(' '))[2])\n",
      "    #print [start_date, end_date]\n",
      "\n",
      "    #generate the dates list \n",
      "    cur_date=datetime.strptime(from_date_order,\"%Y-%m-%d\")\n",
      "    startt=145775\n",
      "    start=datetime.fromtimestamp((start_date-(datetime(1970,01,01)-datetime(1601,01,01)).days)*24*60*60)\n",
      "    #print start\n",
      "    tmp_date=datetime(start.year,cur_date.month,cur_date.day)\n",
      "    if tmp_date > start :\n",
      "        start=(tmp_date-datetime(1601,01,01)).days\n",
      "    else: start=(datetime(start.year+1,cur_date.month,cur_date.day)-datetime(1601,01,01)).days\n",
      "    datelist=range(start+1,end_date-1,365)\n",
      "    #print datelist\n",
      "\n",
      "    #find the position of the requested date in the datelist\n",
      "    cur_epoch=(cur_date-datetime(1601,01,01)).days\n",
      "    cur_pos=min(range(len(datelist)),key=lambda x:abs(datelist[x]-cur_epoch))\n",
      "    #print ('Current position:',cur_pos)\n",
      "    #retrieve the data cube\n",
      "    cube_arr=[]\n",
      "    for d in datelist:\n",
      "        field={}\n",
      "        field['SERVICE']='WCS'\n",
      "        field['VERSION']='2.0.1'\n",
      "        field['REQUEST']='GetCoverage'\n",
      "        field['COVERAGEID']='modis_11c2_cov'#'trmm_3b42_coverage_1'\n",
      "        field['SUBSET']=['ansi('+str(d)+')',\n",
      "                         'Lat('+str(bbox_order[1])+','+str(bbox_order[3])+')',\n",
      "                        'Long('+str(bbox_order[0])+','+str(bbox_order[2])+')']\n",
      "        field['FORMAT']='image/tiff'\n",
      "        url_values = urllib.urlencode(field,doseq=True)\n",
      "        full_url = endpoint + '?' + url_values\n",
      "        #print full_url\n",
      "        tmpfilename='test'+str(d)+'.tif'\n",
      "        f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "        #print h\n",
      "        ds=gdal.Open(tmpfilename)\n",
      "\n",
      "        cube_arr.append(ds.ReadAsArray())\n",
      "        #print d\n",
      "\n",
      "    ##calculate the regional VCI\n",
      "    cube_arr_ma=ma.masked_equal(numpy.asarray(cube_arr),-3000)\n",
      "    NTAI=(cube_arr_ma[cur_pos,:,:]-numpy.mean(cube_arr_ma,0))*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    \n",
      "#     NTAI += 1\n",
      "#     NTAI *= 1000\n",
      "#     NTAI //= (2000 - 0 + 1) / 255. # instead of 256 to make space for zero values\n",
      "#     NTAI = NTAI.astype(numpy.uint8)\n",
      "#     NTAI += 1 # So 0 values are reserved for mask\n",
      "\n",
      "    ##write the result VCI to disk\n",
      "    # get parameters\n",
      "    geotransform = ds.GetGeoTransform()\n",
      "    spatialreference = ds.GetProjection()\n",
      "    ncol = ds.RasterXSize\n",
      "    nrow = ds.RasterYSize\n",
      "    nband = 1\n",
      "\n",
      "    # create dataset for output\n",
      "    fmt = 'GTiff'\n",
      "    #NTAIFileName = 'NTAI'+cur_date.strftime(\"%Y%m%d\")+'.tif'\n",
      "    \n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm\n",
      "    \n",
      "    driver = gdal.GetDriverByName(fmt)\n",
      "    dst_dataset = driver.Create(directory, ncol, nrow, nband, gdal.GDT_Byte)\n",
      "    dst_dataset.SetGeoTransform(geotransform)\n",
      "    dst_dataset.SetProjection(spatialreference)\n",
      "    dst_dataset.GetRasterBand(1).WriteArray(NTAI)\n",
      "    dst_dataset = None\n",
      "    print directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _NVAI_CAL(coverageID, request_name, from_date_order,bbox_order, directory):\n",
      "\n",
      "    ##request image cube for the specified date and area by WCS.\n",
      "    #firstly we get the temporal length of avaliable NDVI data from the DescribeCoverage of WCS\n",
      "    endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='DescribeCoverage'\n",
      "    field['COVERAGEID']='modis_13c1_cov'#'trmm_3b42_coverage_1'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    data = urllib.urlopen(full_url).read()\n",
      "    root = etree.fromstring(data)\n",
      "    lc = root.find(\".//{http://www.opengis.net/gml/3.2}lowerCorner\").text\n",
      "    uc = root.find(\".//{http://www.opengis.net/gml/3.2}upperCorner\").text\n",
      "    start_date=int((lc.split(' '))[2])\n",
      "    end_date=int((uc.split(' '))[2])\n",
      "    #print [start_date, end_date]\n",
      "\n",
      "    #generate the dates list \n",
      "    cur_date=datetime.strptime(from_date_order,\"%Y-%m-%d\")\n",
      "    startt=145775\n",
      "    start=datetime.fromtimestamp((start_date-(datetime(1970,01,01)-datetime(1601,01,01)).days)*24*60*60)\n",
      "    #print start\n",
      "    tmp_date=datetime(start.year,cur_date.month,cur_date.day)\n",
      "    if tmp_date > start :\n",
      "        start=(tmp_date-datetime(1601,01,01)).days\n",
      "    else: start=(datetime(start.year+1,cur_date.month,cur_date.day)-datetime(1601,01,01)).days\n",
      "    datelist=range(start+1,end_date-1,365)\n",
      "    #print datelist\n",
      "\n",
      "    #find the position of the requested date in the datelist\n",
      "    cur_epoch=(cur_date-datetime(1601,01,01)).days\n",
      "    cur_pos=min(range(len(datelist)),key=lambda x:abs(datelist[x]-cur_epoch))\n",
      "    #print ('Current position:',cur_pos)\n",
      "    #retrieve the data cube\n",
      "    cube_arr=[]\n",
      "    for d in datelist:\n",
      "        field={}\n",
      "        field['SERVICE']='WCS'\n",
      "        field['VERSION']='2.0.1'\n",
      "        field['REQUEST']='GetCoverage'\n",
      "        field['COVERAGEID']='modis_13c1_cov'#'trmm_3b42_coverage_1'\n",
      "        field['SUBSET']=['ansi('+str(d)+')',\n",
      "                         'Lat('+str(bbox_order[1])+','+str(bbox_order[3])+')',\n",
      "                        'Long('+str(bbox_order[0])+','+str(bbox_order[2])+')']\n",
      "        field['FORMAT']='image/tiff'\n",
      "        url_values = urllib.urlencode(field,doseq=True)\n",
      "        full_url = endpoint + '?' + url_values\n",
      "        #print full_url\n",
      "        tmpfilename='test'+str(d)+'.tif'\n",
      "        f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "        #print h\n",
      "        ds=gdal.Open(tmpfilename)\n",
      "\n",
      "        cube_arr.append(ds.ReadAsArray())\n",
      "        #print d\n",
      "\n",
      "    ##calculate the regional VCI\n",
      "    cube_arr_ma=ma.masked_equal(numpy.asarray(cube_arr),-3000)\n",
      "    NVAI=(cube_arr_ma[cur_pos,:,:]-numpy.mean(cube_arr_ma,0))*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    \n",
      "#     NVAI += 1\n",
      "#     NVAI *= 1000\n",
      "#     NVAI //= (2000 - 0 + 1) / 255. # instead of 256 to make space for zero values\n",
      "#     NVAI = NVAI.astype(numpy.uint8)\n",
      "#     NVAI += 1 # So 0 values are reserved for mask\n",
      "\n",
      "    ##write the result VCI to disk\n",
      "    # get parameters\n",
      "    geotransform = ds.GetGeoTransform()\n",
      "    spatialreference = ds.GetProjection()\n",
      "    ncol = ds.RasterXSize\n",
      "    nrow = ds.RasterYSize\n",
      "    nband = 1\n",
      "\n",
      "    # create dataset for output\n",
      "    fmt = 'GTiff'\n",
      "    #nvaiFileName = 'NVAI'+cur_date.strftime(\"%Y%m%d\")+'.tif'\n",
      "    \n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm\n",
      "    \n",
      "    driver = gdal.GetDriverByName(fmt)\n",
      "    dst_dataset = driver.Create(directory, ncol, nrow, nband, gdal.GDT_Byte)\n",
      "    dst_dataset.SetGeoTransform(geotransform)\n",
      "    dst_dataset.SetProjection(spatialreference)\n",
      "    dst_dataset.GetRasterBand(1).WriteArray(NVAI)\n",
      "    dst_dataset = None\n",
      "    print directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _VCI_CAL(coverageID, request_name, from_date_order,bbox_order, directory):\n",
      "\n",
      "    ##request image cube for the specified date and area by WCS.\n",
      "    #firstly we get the temporal length of avaliable NDVI data from the DescribeCoverage of WCS\n",
      "    endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='DescribeCoverage'\n",
      "    field['COVERAGEID']='modis_13c1_cov'#'trmm_3b42_coverage_1'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    data = urllib.urlopen(full_url).read()\n",
      "    root = etree.fromstring(data)\n",
      "    lc = root.find(\".//{http://www.opengis.net/gml/3.2}lowerCorner\").text\n",
      "    uc = root.find(\".//{http://www.opengis.net/gml/3.2}upperCorner\").text\n",
      "    start_date=int((lc.split(' '))[2])\n",
      "    end_date=int((uc.split(' '))[2])\n",
      "    #print [start_date, end_date]\n",
      "\n",
      "    #generate the dates list \n",
      "    cur_date=dt.datetime.strptime(from_date_order,\"%Y-%m-%d\")\n",
      "    startt=145775\n",
      "    start=datetime.fromtimestamp((start_date-(datetime(1970,01,01)-datetime(1601,01,01)).days)*24*60*60)\n",
      "    #print start\n",
      "    tmp_date=datetime(start.year,cur_date.month,cur_date.day)\n",
      "    if tmp_date > start :\n",
      "        start=(tmp_date-datetime(1601,01,01)).days\n",
      "    else: start=(datetime(start.year+1,cur_date.month,cur_date.day)-datetime(1601,01,01)).days\n",
      "    datelist=range(start+1,end_date-1,365)\n",
      "    #print datelist\n",
      "\n",
      "    #find the position of the requested date in the datelist\n",
      "    cur_epoch=(cur_date-datetime(1601,01,01)).days\n",
      "    cur_pos=min(range(len(datelist)),key=lambda x:abs(datelist[x]-cur_epoch))\n",
      "    #print ('Current position:',cur_pos)\n",
      "    #retrieve the data cube\n",
      "    cube_arr=[]\n",
      "    for d in datelist:\n",
      "        field={}\n",
      "        field['SERVICE']='WCS'\n",
      "        field['VERSION']='2.0.1'\n",
      "        field['REQUEST']='GetCoverage'\n",
      "        field['COVERAGEID']='modis_13c1_cov'#'trmm_3b42_coverage_1'\n",
      "        field['SUBSET']=['ansi('+str(d)+')',\n",
      "                         'Lat('+str(bbox_order[1])+','+str(bbox_order[3])+')',\n",
      "                        'Long('+str(bbox_order[0])+','+str(bbox_order[2])+')']\n",
      "        field['FORMAT']='image/tiff'\n",
      "        url_values = urllib.urlencode(field,doseq=True)\n",
      "        full_url = endpoint + '?' + url_values\n",
      "        #print full_url\n",
      "        tmpfilename='test'+str(d)+'.tif'\n",
      "        f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "        #print h\n",
      "        ds=gdal.Open(tmpfilename)\n",
      "\n",
      "        cube_arr.append(ds.ReadAsArray())\n",
      "        #print d\n",
      "\n",
      "    ##calculate the regional VCI\n",
      "    cube_arr_ma=ma.masked_equal(numpy.asarray(cube_arr),-3000)\n",
      "    VCI=(cube_arr_ma[cur_pos,:,:]-numpy.amin(cube_arr_ma,0))*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    \n",
      "#     VCI *= 1000\n",
      "#     VCI //= (1000 - 0 + 1) / 255. # instead of 256 to make space for zero values\n",
      "#     VCI = VCI.astype(numpy.uint8)\n",
      "#     VCI += 1 # So 0 values are reserved for mask\n",
      "\n",
      "    ##write the result VCI to disk\n",
      "    # get parameters\n",
      "    geotransform = ds.GetGeoTransform()\n",
      "    spatialreference = ds.GetProjection()\n",
      "    ncol = ds.RasterXSize\n",
      "    nrow = ds.RasterYSize\n",
      "    nband = 1\n",
      "\n",
      "    # create dataset for output\n",
      "    fmt = 'GTiff'\n",
      "    #vciFileName = 'VCI'+cur_date.strftime(\"%Y%m%d\")+'.tif'\n",
      "    \n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm    \n",
      "    \n",
      "    driver = gdal.GetDriverByName(fmt)\n",
      "    dst_dataset = driver.Create(directory, ncol, nrow, nband, gdal.GDT_Byte)\n",
      "    dst_dataset.SetGeoTransform(geotransform)\n",
      "    dst_dataset.SetProjection(spatialreference)\n",
      "    dst_dataset.GetRasterBand(1).WriteArray(VCI)\n",
      "    dst_dataset = None\n",
      "    print directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _TCI_CAL(coverageID, request_name, from_date_order,bbox_order, directory):\n",
      "\n",
      "    ##request image cube for the specified date and area by WCS.\n",
      "    #firstly we get the temporal length of avaliable NDVI data from the DescribeCoverage of WCS\n",
      "    endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='DescribeCoverage'\n",
      "    field['COVERAGEID']='modis_11c2_cov'#'trmm_3b42_coverage_1'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    data = urllib.urlopen(full_url).read()\n",
      "    root = etree.fromstring(data)\n",
      "    lc = root.find(\".//{http://www.opengis.net/gml/3.2}lowerCorner\").text\n",
      "    uc = root.find(\".//{http://www.opengis.net/gml/3.2}upperCorner\").text\n",
      "    start_date=int((lc.split(' '))[2])\n",
      "    end_date=int((uc.split(' '))[2])\n",
      "    #print [start_date, end_date]\n",
      "\n",
      "    #generate the dates list \n",
      "    cur_date=datetime.strptime(from_date_order,\"%Y-%m-%d\")\n",
      "    startt=145775\n",
      "    start=datetime.fromtimestamp((start_date-(datetime(1970,01,01)-datetime(1601,01,01)).days)*24*60*60)\n",
      "    #print start\n",
      "    tmp_date=datetime(start.year,cur_date.month,cur_date.day)\n",
      "    if tmp_date > start :\n",
      "        start=(tmp_date-datetime(1601,01,01)).days\n",
      "    else: start=(datetime(start.year+1,cur_date.month,cur_date.day)-datetime(1601,01,01)).days\n",
      "    datelist=range(start+1,end_date-1,365)\n",
      "    #print datelist\n",
      "\n",
      "    #find the position of the requested date in the datelist\n",
      "    cur_epoch=(cur_date-datetime(1601,01,01)).days\n",
      "    cur_pos=min(range(len(datelist)),key=lambda x:abs(datelist[x]-cur_epoch))\n",
      "    #print ('Current position:',cur_pos)\n",
      "    #retrieve the data cube\n",
      "    cube_arr=[]\n",
      "    for d in datelist:\n",
      "        field={}\n",
      "        field['SERVICE']='WCS'\n",
      "        field['VERSION']='2.0.1'\n",
      "        field['REQUEST']='GetCoverage'\n",
      "        field['COVERAGEID']='modis_11c2_cov'#'trmm_3b42_coverage_1'\n",
      "        field['SUBSET']=['ansi('+str(d)+')',\n",
      "                         'Lat('+str(bbox_order[1])+','+str(bbox_order[3])+')',\n",
      "                        'Long('+str(bbox_order[0])+','+str(bbox_order[2])+')']\n",
      "        field['FORMAT']='image/tiff'\n",
      "        url_values = urllib.urlencode(field,doseq=True)\n",
      "        full_url = endpoint + '?' + url_values\n",
      "        #print full_url\n",
      "        tmpfilename='test'+str(d)+'.tif'\n",
      "        f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "        #print h\n",
      "        ds=gdal.Open(tmpfilename)\n",
      "\n",
      "        cube_arr.append(ds.ReadAsArray())\n",
      "        #print d\n",
      "\n",
      "    ##calculate the regional VCI\n",
      "    cube_arr_ma=ma.masked_equal(numpy.asarray(cube_arr),-3000)\n",
      "    ##VCI=(cube_arr_ma[cur_pos,:,:]-numpy.amin(cube_arr_ma,0))*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    TCI=(numpy.amax(cube_arr_ma,0)-cube_arr_ma[cur_pos,:,:])*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    \n",
      "#     TCI *= 1000\n",
      "#     TCI //= (1000 - 0 + 1) / 255. #instead of 256\n",
      "#     TCI = TCI.astype(numpy.uint8)\n",
      "#     TCI += 1 #so mask values are reserverd for 0 \n",
      "\n",
      "    ##write the result VCI to disk\n",
      "    # get parameters\n",
      "    geotransform = ds.GetGeoTransform()\n",
      "    spatialreference = ds.GetProjection()\n",
      "    ncol = ds.RasterXSize\n",
      "    nrow = ds.RasterYSize\n",
      "    nband = 1\n",
      "\n",
      "    # create dataset for output\n",
      "    fmt = 'GTiff'\n",
      "    #tciFileName = 'TCI'+cur_date.strftime(\"%Y%m%d\")+'.tif'\n",
      "    \n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm     \n",
      "    \n",
      "    driver = gdal.GetDriverByName(fmt)\n",
      "    dst_dataset = driver.Create(directory, ncol, nrow, nband, gdal.GDT_Byte)\n",
      "    dst_dataset.SetGeoTransform(geotransform)\n",
      "    dst_dataset.SetProjection(spatialreference)\n",
      "    dst_dataset.GetRasterBand(1).WriteArray(TCI)\n",
      "    dst_dataset = None\n",
      "    print directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def _VCIvhi_CAL(date,spl_arr):\n",
      "\n",
      "    ##request image cube for the specified date and area by WCS.\n",
      "    #firstly we get the temporal length of avaliable NDVI data from the DescribeCoverage of WCS\n",
      "    endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='DescribeCoverage'\n",
      "    field['COVERAGEID']='modis_13c1_cov'#'trmm_3b42_coverage_1'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    data = urllib.urlopen(full_url).read()\n",
      "    root = etree.fromstring(data)\n",
      "    lc = root.find(\".//{http://www.opengis.net/gml/3.2}lowerCorner\").text\n",
      "    uc = root.find(\".//{http://www.opengis.net/gml/3.2}upperCorner\").text\n",
      "    start_date=int((lc.split(' '))[2])\n",
      "    end_date=int((uc.split(' '))[2])\n",
      "    #print [start_date, end_date]\n",
      "\n",
      "    #generate the dates list \n",
      "    cur_date=datetime.strptime(date,\"%Y-%m-%d\")\n",
      "    startt=145775\n",
      "    start=datetime.fromtimestamp((start_date-(datetime(1970,01,01)-datetime(1601,01,01)).days)*24*60*60)\n",
      "    #print start\n",
      "    tmp_date=datetime(start.year,cur_date.month,cur_date.day)\n",
      "    if tmp_date > start :\n",
      "        start=(tmp_date-datetime(1601,01,01)).days\n",
      "    else: start=(datetime(start.year+1,cur_date.month,cur_date.day)-datetime(1601,01,01)).days\n",
      "    datelist=range(start+1,end_date-1,365)\n",
      "    #print datelist\n",
      "\n",
      "    #find the position of the requested date in the datelist\n",
      "    cur_epoch=(cur_date-datetime(1601,01,01)).days\n",
      "    cur_pos=min(range(len(datelist)),key=lambda x:abs(datelist[x]-cur_epoch))\n",
      "    #print ('Current position:',cur_pos)\n",
      "    #retrieve the data cube\n",
      "    cube_arr=[]\n",
      "    for d in datelist:\n",
      "        field={}\n",
      "        field['SERVICE']='WCS'\n",
      "        field['VERSION']='2.0.1'\n",
      "        field['REQUEST']='GetCoverage'\n",
      "        field['COVERAGEID']='modis_13c1_cov'#'trmm_3b42_coverage_1'\n",
      "        field['SUBSET']=['ansi('+str(d)+')',\n",
      "                         'Lat('+str(spl_arr[1])+','+str(spl_arr[3])+')',\n",
      "                        'Long('+str(spl_arr[0])+','+str(spl_arr[2])+')']\n",
      "        field['FORMAT']='image/tiff'\n",
      "        url_values = urllib.urlencode(field,doseq=True)\n",
      "        full_url = endpoint + '?' + url_values\n",
      "        #print full_url\n",
      "        tmpfilename='test'+str(d)+'.tif'\n",
      "        f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "        #print h\n",
      "        ds=gdal.Open(tmpfilename)\n",
      "\n",
      "        cube_arr.append(ds.ReadAsArray())\n",
      "        #print d\n",
      "\n",
      "    ##calculate the regional VCI\n",
      "    cube_arr_ma=ma.masked_equal(numpy.asarray(cube_arr),-3000)\n",
      "    VCI=(cube_arr_ma[cur_pos,:,:]-numpy.amin(cube_arr_ma,0))*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    \n",
      "    #VCI *= 1000\n",
      "    #VCI //= (1000 - 0 + 1) / 256.\n",
      "    #VCI = VCI.astype(numpy.uint8) \n",
      "    return VCI,ds\n",
      "\n",
      "def _TCIvhi_CAL(date,spl_arr):\n",
      "\n",
      "    ##request image cube for the specified date and area by WCS.\n",
      "    #firstly we get the temporal length of avaliable NDVI data from the DescribeCoverage of WCS\n",
      "    endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='DescribeCoverage'\n",
      "    field['COVERAGEID']='modis_11c2_cov'#'trmm_3b42_coverage_1'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    data = urllib.urlopen(full_url).read()\n",
      "    root = etree.fromstring(data)\n",
      "    lc = root.find(\".//{http://www.opengis.net/gml/3.2}lowerCorner\").text\n",
      "    uc = root.find(\".//{http://www.opengis.net/gml/3.2}upperCorner\").text\n",
      "    start_date=int((lc.split(' '))[2])\n",
      "    end_date=int((uc.split(' '))[2])\n",
      "    #print [start_date, end_date]\n",
      "\n",
      "    #generate the dates list \n",
      "    cur_date=datetime.strptime(date,\"%Y-%m-%d\")\n",
      "    startt=145775\n",
      "    start=datetime.fromtimestamp((start_date-(datetime(1970,01,01)-datetime(1601,01,01)).days)*24*60*60)\n",
      "    #print start\n",
      "    tmp_date=datetime(start.year,cur_date.month,cur_date.day)\n",
      "    if tmp_date > start :\n",
      "        start=(tmp_date-datetime(1601,01,01)).days\n",
      "    else: start=(datetime(start.year+1,cur_date.month,cur_date.day)-datetime(1601,01,01)).days\n",
      "    datelist=range(start+1,end_date-1,365)\n",
      "    #print datelist\n",
      "\n",
      "    #find the position of the requested date in the datelist\n",
      "    cur_epoch=(cur_date-datetime(1601,01,01)).days\n",
      "    cur_pos=min(range(len(datelist)),key=lambda x:abs(datelist[x]-cur_epoch))\n",
      "    #print ('Current position:',cur_pos)\n",
      "    #retrieve the data cube\n",
      "    cube_arr=[]\n",
      "    for d in datelist:\n",
      "        field={}\n",
      "        field['SERVICE']='WCS'\n",
      "        field['VERSION']='2.0.1'\n",
      "        field['REQUEST']='GetCoverage'\n",
      "        field['COVERAGEID']='modis_11c2_cov'#'trmm_3b42_coverage_1'\n",
      "        field['SUBSET']=['ansi('+str(d)+')',\n",
      "                         'Lat('+str(spl_arr[1])+','+str(spl_arr[3])+')',\n",
      "                        'Long('+str(spl_arr[0])+','+str(spl_arr[2])+')']\n",
      "        field['FORMAT']='image/tiff'\n",
      "        url_values = urllib.urlencode(field,doseq=True)\n",
      "        full_url = endpoint + '?' + url_values\n",
      "        #print full_url\n",
      "        tmpfilename='test'+str(d)+'.tif'\n",
      "        f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "        #print h\n",
      "        ds=gdal.Open(tmpfilename)\n",
      "\n",
      "        cube_arr.append(ds.ReadAsArray())\n",
      "        #print d\n",
      "\n",
      "    ##calculate the regional VCI\n",
      "    cube_arr_ma=ma.masked_equal(numpy.asarray(cube_arr),-3000)\n",
      "    ##VCI=(cube_arr_ma[cur_pos,:,:]-numpy.amin(cube_arr_ma,0))*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    TCI=(numpy.amax(cube_arr_ma,0)-cube_arr_ma[cur_pos,:,:])*1.0/(numpy.amax(cube_arr_ma,0)-numpy.amin(cube_arr_ma,0))\n",
      "    \n",
      "    return TCI, cur_date\n",
      "\n",
      "def _VHI_CAL(coverageID, request_name, from_date_order,bbox_order, directory,alpha = 0.5):\n",
      "    \n",
      "    TCI, cur_date = _TCIvhi_CAL(from_date_order,bbox_order)\n",
      "    VCI, ds = _VCIvhi_CAL(from_date_order,bbox_order)\n",
      "    VHI = (alpha * VCI ) + ((1-alpha)* TCI)\n",
      "    \n",
      "#     VHI *= 1000\n",
      "#     VHI //= (1000 - 0 + 1) / 255. #instead of 256\n",
      "#     VHI = VHI.astype(numpy.uint8)\n",
      "#     VHI += 1 #so mask values are reserverd for 0 \n",
      "\n",
      "    ##write the result VCI to disk\n",
      "    # get parameters\n",
      "    geotransform = ds.GetGeoTransform()\n",
      "    spatialreference = ds.GetProjection()\n",
      "    ncol = ds.RasterXSize\n",
      "    nrow = ds.RasterYSize\n",
      "    nband = 1\n",
      "\n",
      "    # create dataset for output\n",
      "    fmt = 'GTiff'\n",
      "    #vhiFileName = 'VHI'+cur_date.strftime(\"%Y%m%d\")+'.tif'\n",
      "    \n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm  \n",
      "    \n",
      "    driver = gdal.GetDriverByName(fmt)\n",
      "    dst_dataset = driver.Create(directory, ncol, nrow, nband, gdal.GDT_Byte)\n",
      "    dst_dataset.SetGeoTransform(geotransform)\n",
      "    dst_dataset.SetProjection(spatialreference)\n",
      "    dst_dataset.GetRasterBand(1).WriteArray(VHI)\n",
      "    dst_dataset = None\n",
      "    print directory "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def email(info_order, url_link):\n",
      "    msg = MIMEMultipart()\n",
      "    msg['From'] = 'm.vanhoek@radi.ac.cn'\n",
      "    msg['To'] = info_order[-1]\n",
      "    msg['Subject'] = 'Data request East-Asian Drought monitoring system'\n",
      "    message =  \"\"\"\n",
      "    Dear %(name)s,\n",
      "\n",
      "    Thanks for your interesting in the East-Asian Drought monitoring system.\n",
      "\n",
      "    Your request has been automatically generated and the files are ready\n",
      "    to be downloaded.\n",
      "\n",
      "    Please follow the following link:\n",
      "\n",
      "    %(link_to_outfolder)s\n",
      "\n",
      "    We hope the request serves your need.\n",
      "\n",
      "    Best of luck,\n",
      "\n",
      "    Team East-Asian Drought monitoring system\n",
      "    RADI-CAS\n",
      "\n",
      "\n",
      "    p.s Please cite the corresponding paper to support continous future support\n",
      "    of the website\n",
      "\n",
      "    \"\"\" % {\"name\":info_order[2].capitalize(),\"link_to_outfolder\":url_link}\n",
      "    msg.attach(MIMEText(message))\n",
      "\n",
      "    mailserver = smtplib.SMTP('smtp.radi.ac.cn',25)\n",
      "    # identify ourselves to smtp gmail client\n",
      "    mailserver.ehlo()\n",
      "    # secure our email with tls encryption\n",
      "    mailserver.starttls()\n",
      "    # re-identify ourselves as an encrypted connection\n",
      "    mailserver.ehlo()\n",
      "    mailserver.login('m.vanhoek@radi.ac.cn', 'Radi2014')\n",
      "    mailserver.sendmail('m.vanhoek@radi.ac.cn',info_order[-1],msg.as_string())\n",
      "    mailserver.quit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get a UUID - URL safe, Base64\n",
      "def get_a_uuid():\n",
      "    r_uuid = base64.urlsafe_b64encode(uuid.uuid4().bytes)\n",
      "    return r_uuid.replace('=', '')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory):    \n",
      "\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='GetCoverage'\n",
      "    field['COVERAGEID']=coverageID#'trmm_3b42_coverage_1'\n",
      "    field['SUBSET']=['ansi(\"'+str(from_date_order)+'\")',\n",
      "                     'Lat('+str(bbox_order[1])+','+str(bbox_order[3])+')',\n",
      "                    'Long('+str(bbox_order[0])+','+str(bbox_order[2])+')']\n",
      "    field['FORMAT']='image/tiff'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values    \n",
      "    print full_url    \n",
      "    \n",
      "    flnm=request_name+'_'+from_date_order+'_'+str(bbox_order[0])+'_'+str(bbox_order[1])+'_'+str(bbox_order[2])+'_'+str(bbox_order[3])\n",
      "    flnm=re.sub('[^0-9a-zA-Z]+', '_',flnm)\n",
      "    flnm+='.tif'\n",
      "    directory+=flnm\n",
      "    f,h = urllib.urlretrieve(full_url,directory)\n",
      "    \n",
      "    print directory\n",
      "    #return directory,f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def collect_data(array_order, from_date_order,bbox_order, endpoint, directory):\n",
      "    for i in array_order:\n",
      "        if i == 'p_gpcp':            \n",
      "            coverageID = 'None'\n",
      "            #getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory):\n",
      "        if i == 'p_trmm':\n",
      "            coverageID = 'trmm_3b42_coverage_1'\n",
      "            #getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory):\n",
      "        if i == 't_lst':\n",
      "            coverageID = 'modis_11c2_cov'\n",
      "            request_name = i\n",
      "            getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory)\n",
      "        if i == 'et_radi':\n",
      "            coverageID = 'radi_et_v1'\n",
      "            #getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory):\n",
      "        if i == 'ndvi_modis':\n",
      "            coverageID = 'modis_13c1_cov'\n",
      "            request_name = i        \n",
      "            getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory)\n",
      "        if i == 'di_pap':\n",
      "            coverageID = 'gpcp'\n",
      "            request_name = i        \n",
      "            PRECIP_DI_CAL(coverageID, request_name, from_date_order,bbox_order, directory)\n",
      "        if i == 'di_vci':\n",
      "            coverageID = 'modis_13c1_cov'\n",
      "            request_name = i        \n",
      "            _VCI_CAL(coverageID, request_name, from_date_order,bbox_order, directory)\n",
      "        if i == 'di_tci':\n",
      "            coverageID = 'modis_11c2_cov'\n",
      "            request_name = i        \n",
      "            _TCI_CAL(coverageID, request_name, from_date_order,bbox_order, directory)\n",
      "        if i == 'di_vhi':\n",
      "            coverageID = 'modis_11c2_cov'\n",
      "            request_name = i        \n",
      "            _VHI_CAL(coverageID, request_name, from_date_order,bbox_order, directory,alpha = 0.5)\n",
      "        if i == 'di_nvai':\n",
      "            coverageID = 'modis_11c2_cov'\n",
      "            request_name = i        \n",
      "            _NVAI_CAL(coverageID, request_name, from_date_order,bbox_order, directory)\n",
      "        if i == 'di_ntai':\n",
      "            coverageID = 'modis_11c2_cov'\n",
      "            request_name = i        \n",
      "            _NTAI_CAL(coverageID, request_name, from_date_order,bbox_order, directory)\n",
      "        if i == 'di_netai':\n",
      "            coverageID = 'modis_11c2_cov'\n",
      "            #request_name = i        \n",
      "            #getData(coverageID, request_name, from_date_order, bbox_order, endpoint, directory): "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Process(WPSProcess):\n",
      "\n",
      "\n",
      "    def __init__(self):\n",
      "\n",
      "        ##\n",
      "        # Process initialization\n",
      "        WPSProcess.__init__(self,\n",
      "            identifier = \"WPS_ORDER\",\n",
      "            title=\"Compute the order\",\n",
      "            abstract=\"\"\"Module to order data\"\"\",\n",
      "            version = \"1.0\",\n",
      "            storeSupported = True,\n",
      "            statusSupported = True)\n",
      "\n",
      "        ##\n",
      "        # Adding process inputs\n",
      "\n",
      "        self.fromDateIn = self.addLiteralInput(identifier=\"from_date_order\",\n",
      "                    title = \"The start date to be calcualted\",\n",
      "                                          type=type(''))\n",
      "\n",
      "        #self.toDateIn = self.addLiteralInput(identifier=\"to_date\",\n",
      "        #            title = \"The final date to be calcualted\",\n",
      "        #                                  type=type(''))   \n",
      "        \n",
      "        self.bboxIn = self.addLiteralInput(identifier=\"bbox_order\",\n",
      "                    title=\"spatial area\",\n",
      "                    type=type(''))\n",
      "\n",
      "        self.arrayIn = self.addLiteralInput(identifier=\"array_order\",\n",
      "                    title=\"client selection\",\n",
      "                    type=type(''))\n",
      "\n",
      "        self.infoIn = self.addLiteralInput(identifier=\"info_order\",\n",
      "                    title = \"client info\",\n",
      "                    type=type(''))       \n",
      "    ##\n",
      "    # Execution part of the process\n",
      "    def execute(self):\n",
      "        # 1. Load the data\n",
      "        from_date_order = self.fromDateIn.getValue()\n",
      "        bbox_order = self.bboxIn.getValue()\n",
      "        array_order = self.arrayIn.getValue() \n",
      "        info_order = self.infoIn.getValue() \n",
      "\n",
      "        logging.info(from_date_order)\n",
      "        logging.info(bbox_order)\n",
      "        logging.info(array_order)\n",
      "        logging.info(info_order)          \n",
      "        \n",
      "        # 2. Do the Work\n",
      "        # set endpoint\n",
      "        endpoint='http://159.226.117.95:8080/rasdaman/ows'\n",
      "\n",
      "        # get unique user ID and create path\n",
      "        uuid_in = get_a_uuid()\n",
      "        server_path = r'D:\\GoogleChromeDownloads\\MyWebSites'+'\\\\'+uuid_in+'\\\\'\n",
      "        client_path = 'http://159.226.117.95/wpsoutputs/'+uuid_in\n",
      "        if not os.path.exists(server_path):\n",
      "            os.makedirs(server_path)\n",
      "\n",
      "        # request and prepare all data\n",
      "        collect_data(array_order, from_date_order,bbox_order, endpoint, server_path)\n",
      "        \n",
      "        # 3. Output \n",
      "        # send the goddamn email\n",
      "        email(info_order,client_path)        \n",
      "        \n",
      "        return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from_date_order = '2014-01-01'\n",
      "# bbox_order = [108.1, 32.5, 126.5, 43.8]\n",
      "# array_order = [\"p_gpcp\",\"p_trmm\",\"t_lst\",\"et_modis\",\"et_radi\",\"ndvi_modis\",\"di_pap\",\"di_vci\",\"di_tci\",\"di_vhi\",\"di_nvai\",\"di_ntai\",\"di_netai\"]\n",
      "# info_order = [\"0.15\", \"ascii\", \"mattijn\", \"radi\", \"mattijn@gmail.com\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "urlIn = '107.5,27,133.2,45.2'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "map(float, urlIn.split(','))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[107.5, 27.0, 133.2, 45.2]"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}