{
 "metadata": {
  "name": "",
  "signature": "sha256:b85c2a06b50d6e727137b3da0240bcfee3dc7c9d687b57290889bd0be640af41"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import json\n",
      "import pandas as pd\n",
      "from osgeo import ogr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Merge two geopackages of China and Taiwan\n",
      "Create a new merge geopackage using China gpkg\n",
      "\n",
      "    `ogr2ogr -f GPKG D:\\Data\\ChinaShapefile\\CHN_TWN_adm_gpkg\\CHN_TWN_adm.gpkg D:\\Data\\ChinaShapefile\\CHN_adm_gpkg\\CHN_adm.gpkg`\n",
      "\n",
      "And merge/append the Taiwan geopackage\n",
      "\n",
      "    `ogr2ogr -f GPKG -update -append D:\\Data\\ChinaShapefile\\CHN_TWN_adm_gpkg\\CHN_TWN_adm.gpkg D:\\Data\\ChinaShapefile\\TWN_adm_gpkg\\TWN_adm.gpkg -nln merge`\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the merged geopackage and get layer 3 \n",
      "geopackage = r'D:\\Data\\ChinaShapefile\\CHN_adm_gpkg\\CHN_adm.gpkg'\n",
      "driver = ogr.GetDriverByName(\"GPKG\")\n",
      "dataSource = driver.Open(geopackage, 0)\n",
      "layer = dataSource.GetLayer(3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the headers of the attribute table of this layer\n",
      "layerDefinition = layer.GetLayerDefn()\n",
      "for i in range(layerDefinition.GetFieldCount()):\n",
      "    print layerDefinition.GetFieldDefn(i).GetName()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ID_0\n",
        "ISO\n",
        "NAME_0\n",
        "ID_1\n",
        "NAME_1\n",
        "ID_2\n",
        "NAME_2\n",
        "HASC_2\n",
        "CCN_2\n",
        "CCA_2\n",
        "TYPE_2\n",
        "ENGTYPE_2\n",
        "NL_NAME_2\n",
        "VARNAME_2\n",
        "Shape_Length\n",
        "Shape_Area\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "province = []\n",
      "region = []\n",
      "county = []\n",
      "for feature in layer:\n",
      "    province.append( feature.GetField(\"NAME_1\") )\n",
      "    region.append( feature.GetField(\"NAME_2\") )    \n",
      "    county.append( feature.GetField(\"NAME_3\") )    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# job done, but also include the part that iterates over all this to create file used for the javascropt drop-down list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.DataFrame([province,region,county]).T\n",
      "df.columns = ['NAME_1', 'NAME_2','NAME_3']\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.sort('NAME_1', inplace=True)\n",
      "df.set_index(['NAME_1','NAME_2','NAME_3'], inplace=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "provinces_list=[]\n",
      "regions_list=[]\n",
      "counties_list=[]\n",
      "\n",
      "ix_chn = 0\n",
      "provinces = np.unique(df.index.get_level_values('NAME_1').values)\n",
      "\n",
      "province_code = str(ix_chn)\n",
      "province_names = np.unique(df.index.get_level_values('NAME_1').values).tolist()\n",
      "\n",
      "# append provinces to its list\n",
      "provinces_list.append(province_code)\n",
      "provinces_list.append(province_names)\n",
      "\n",
      "for ix_pr, pr in enumerate(provinces):\n",
      "    region_list = []\n",
      "    #print ix_pr\n",
      "    #print pr\n",
      "\n",
      "    df_prov = df.xs(pr, level='NAME_1', drop_level=False)    \n",
      "    regions = np.unique(df_prov.index.get_level_values('NAME_2').values)\n",
      "    \n",
      "    region_code = str(ix_chn)+'_'+str(ix_pr)\n",
      "    region_name = np.unique(df_prov.index.get_level_values('NAME_2').values).tolist()\n",
      "    \n",
      "    region_list.append(region_code)\n",
      "    region_list.append(region_name)\n",
      "    \n",
      "    regions_list.append(region_list)\n",
      "    \n",
      "    for ix_rg, rg in enumerate(regions):\n",
      "        \n",
      "        county_list = []\n",
      "        #print ix_rg\n",
      "        #print rg\n",
      "        \n",
      "        df_regions = df.xs(rg, level='NAME_2', drop_level=False)\n",
      "        \n",
      "        county_code = str(ix_chn)+'_'+str(ix_pr)+'_'+str(ix_rg)\n",
      "        county_names = np.unique(df_regions.index.get_level_values('NAME_3').values).tolist()\n",
      "        \n",
      "        county_list.append(county_code)\n",
      "        county_list.append(county_names)\n",
      "        \n",
      "        counties_list.append(county_list)\n",
      "        #print county_list\n",
      "print provinces_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(r'D:\\GoogleChromeDownloads\\MyWebSites\\CHINA_DROPDOWN\\js\\counties_china_v03.txt', 'w') as thefile:\n",
      "    for item in counties_list:\n",
      "        thefile.write(\"%s\\n\" % json.dumps(item))\n",
      "    for item in regions_list:\n",
      "        thefile.write(\"%s\\n\" % json.dumps(item))\n",
      "    for item in provinces_list:\n",
      "        thefile.write(\"%s\\n\" % json.dumps(item))        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# python done"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In notepad++ update the last line, so the provinces are following same structure as the other lines. Then change the first character `[` into `this.add(`, do this by Replacing `^` (zero length match) with `this.add(` using `regular expression` in `search mode`. Next using `normal expression` search for `this.add[` and replace with `this.add(` and replace `]]` with `]);`. Now copy into the javascript file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ExtractGeoJSON(NAME_1in, NAME_2in, NAME_3in):\n",
      "    \"\"\"\n",
      "    Function to query OGC GeoPackage of China to extract county boundary as JSON\n",
      "    input\n",
      "    NAME_1in = Province/Shang (e.g: 'Anhui')\n",
      "    NAME_2in = Regon/Shi (e.g: 'Bengbu')\n",
      "    NAME_3in = County/Qian (e.g: 'Guzhen')\n",
      "    \n",
      "    output\n",
      "    Boundary of County in GeoJSON format    \n",
      "    \"\"\"\n",
      "    path_base = \"D:\\Data\\ChinaShapefile\\CHN_adm_gpkg\"\n",
      "    CHN_adm_gpkg = os.path.join(path_base, \"CHN_adm.gpkg\")\n",
      "    CHN_adm_geojson = os.path.join(path_base, \"CHN_adm_selection3.geojson\")\n",
      "    if os.path.exists(CHN_adm_geojson):\n",
      "        os.remove(CHN_adm_geojson)\n",
      "        print ('removed') \n",
      "    print (CHN_adm_geojson)\n",
      "    \n",
      "    command = [\"ogr2ogr\", \"-f\", \"GeoJSON\", CHN_adm_geojson, \"-sql\",\n",
      "               \"SELECT NAME_1, NAME_2, NAME_3 FROM CHN_adm3 WHERE NAME_1 = \"+NAME_1in+\" and NAME_2 = \"+NAME_2in+\" and NAME_3 = \"+NAME_3in+\"\",\n",
      "               CHN_adm_gpkg, \"-s_srs\", \"EPSG:4326\",\"-t_srs\",\"EPSG:900913\", \"-skipfailures\", \"-nlt\", \"LINESTRING\"]\n",
      "\n",
      "    print (sp.list2cmdline(command))\n",
      "    \n",
      "    norm = sp.Popen(sp.list2cmdline(command), shell=True)  \n",
      "    norm.communicate()     \n",
      "\n",
      "    with open(CHN_adm_geojson) as f:\n",
      "        geojson2ol = json.load(f)    \n",
      "    return geojson2ol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NAME_1in = \"'Anhui'\"\n",
      "NAME_2in = \"'Bengbu'\"\n",
      "NAME_3in = \"'Guzhen'\"\n",
      "geoout = ExtractGeoJSON(NAME_1in, NAME_2in, NAME_3in)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Get Coverage using extent and clip based on boundary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import geojson\n",
      "import subprocess as sp\n",
      "import json\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import urllib\n",
      "from osgeo import gdal\n",
      "import numpy\n",
      "import numpy as np\n",
      "import numpy.ma as ma\n",
      "from lxml import etree\n",
      "from datetime import datetime, timedelta\n",
      "import matplotlib\n",
      "import matplotlib.colors as mcolors\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spl_arr=[75,25.5,103.75,39] # left, bottom, right, top\n",
      "extent = [117.04640962322863,33.00404358318741,117.59765626636589,33.50222015793983]\n",
      "d = 150842\n",
      "endpoint='http://192.168.1.104:8080/rasdaman/ows'\n",
      "field={}\n",
      "field['SERVICE']='WCS'\n",
      "field['VERSION']='2.0.1'\n",
      "field['REQUEST']='GetCoverage'\n",
      "field['COVERAGEID']='NDAI_1km'#'trmm_3b42_coverage_1'\n",
      "field['SUBSET']=['ansi('+str(d)+')',\n",
      "                 'Lat('+str(extent[1])+','+str(extent[3])+')',\n",
      "                'Long('+str(extent[0])+','+str(extent[2])+')']\n",
      "field['FORMAT']='image/tiff'\n",
      "url_values = urllib.urlencode(field,doseq=True)\n",
      "full_url = endpoint + '?' + url_values\n",
      "print full_url\n",
      "tmpfilename='test'+str(d)+'.tif'\n",
      "f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "print h\n",
      "\n",
      "ds=gdal.Open(tmpfilename)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds=gdal.Open(tmpfilename)\n",
      "tmpfilename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#polygon = r'D:\\GitHub\\pynotebook\\ipynotebooks\\Python2.7//polygon.geojson'\n",
      "#output_tif = r'D:\\GitHub\\pynotebook\\ipynotebooks\\Python2.7//output.tif'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#command = [\"gdalwarp\", \"-dstnodata\", \"-9999\", \"-co\", \"COMPRESS=DEFLATE\", \"-of\", \"GTiff\", \"-r\", \"near\", \n",
      "#           \"-crop_to_cutline\", \"-cutline\", polygon, tmpfilename, output_tif]\n",
      "#print (sp.list2cmdline(command))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#norm = sp.Popen(sp.list2cmdline(command), shell=True)  \n",
      "#norm.communicate() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clippedfilename='test'+str(d)+'clip.tif'\n",
      "clippedfilename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_base = \"D:\\Data\\ChinaShapefile\\CHN_adm_gpkg\"\n",
      "CHN_adm_gpkg = os.path.join(path_base, \"CHN_adm.gpkg\")\n",
      "CHN_adm_gpkg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NAME_1in = \"'Anhui'\"\n",
      "NAME_2in = \"'Bengbu'\"\n",
      "NAME_3in = \"'Guzhen'\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "command = [\"gdalwarp\", \"-cutline\", CHN_adm_gpkg, \"-csql\", \"SELECT NAME_3 FROM CHN_adm3 WHERE NAME_1 = \"+NAME_1in+\" and NAME_2 = \"+NAME_2in+\" and NAME_3 = \"+NAME_3in+\"\",\n",
      "           \"-crop_to_cutline\", \"-of\", \"GTiff\", \"-dstnodata\",\"-9999\",tmpfilename, clippedfilename, \"-overwrite\"] # \n",
      "\n",
      "print (sp.list2cmdline(command))\n",
      "\n",
      "norm = sp.Popen(sp.list2cmdline(command), shell=True)  \n",
      "norm.communicate() "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds=gdal.Open(clippedfilename)\n",
      "ds_clip = ds.ReadAsArray()\n",
      "ds_clip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_clip_ma = np.ma.masked_equal(ds_clip, -9999)\n",
      "ds_clip_ma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##write the result VCI to disk\n",
      "# get parameters\n",
      "geotransform = ds.GetGeoTransform()\n",
      "spatialreference = ds.GetProjection()\n",
      "ncol = ds.RasterXSize\n",
      "nrow = ds.RasterYSize\n",
      "nband = 1\n",
      "\n",
      "trans = ds.GetGeoTransform()\n",
      "extent = (trans[0], trans[0] + ds.RasterXSize*trans[1],\n",
      "  trans[3] + ds.RasterYSize*trans[5], trans[3])\n",
      "\n",
      "# Create figure\n",
      "fig = plt.imshow(ds_clip_ma, extent=extent, interpolation='nearest')#vmin=-0.4, vmax=0.4\n",
      "plt.colorbar(fig)\n",
      "plt.axis('off')\n",
      "#plt.colorbar()\n",
      "fig.axes.get_xaxis().set_visible(False)\n",
      "fig.axes.get_yaxis().set_visible(False)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_hist_data = ds_clip[ds_clip != -9999]\n",
      "y,binEdges=np.histogram(ds_hist_data,bins=100, range=(-1,1), normed=True)\n",
      "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
      "plt.plot(bincenters,y,'-')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Process(WPSProcess):\n",
      "\n",
      "\n",
      "    def __init__(self):\n",
      "\n",
      "        ##\n",
      "        # Process initialization\n",
      "        WPSProcess.__init__(self,\n",
      "            identifier = \"WPS_HISTOGRAM\",\n",
      "            title=\"Histogram computation based on County \",\n",
      "            abstract=\"\"\"Module to compute Histograms of numerous NDAI observations\"\"\",\n",
      "            version = \"1.0\",\n",
      "            storeSupported = True,\n",
      "            statusSupported = True)\n",
      "\n",
      "        ##\n",
      "        # Adding process inputs\n",
      "        self.NAME_1 = self.addLiteralInput(identifier=\"Province\",\n",
      "                    title=\"Chinese Province\",\n",
      "                    type=type(''))\n",
      "\n",
      "        self.NAME_2 = self.addLiteralInput(identifier=\"Prefecture\",\n",
      "                    title=\"Chinese Prefecture\",\n",
      "                    type=type(''))\n",
      "\n",
      "        self.NAME_3 = self.addLiteralInput(identifier=\"County\",\n",
      "                    title = \"Chinese County\",\n",
      "                    type=type(''))\n",
      "\n",
      "        self.bboxCounty = self.addLiteralInput(identifier=\"ExtentCounty\",\n",
      "                    title = \"The Extent of the web-based selected County\",\n",
      "                    type=type(''))   \n",
      "        \n",
      "        self.date = self.addLiteralInput(identifier=\"date\",\n",
      "                    title=\"The selected date of interest\",\n",
      "                    type=type(''))\n",
      "\n",
      "        self.no_observations = self.addLiteralInput(identifier=\"num_observations\",\n",
      "                    title=\"The number of succeeding observations to consider (output is num_observations+1)\",\n",
      "                    type=type(''))        \n",
      "\n",
      "        ##\n",
      "        # Adding process outputs\n",
      "\n",
      "        self.hist_ts1 = self.addComplexOutput(identifier  = \"hist_ts1\", \n",
      "                                              title       = \"Histogram of the first observations\",\n",
      "                                              formats     = [{'mimeType':'text/xml'}]) \n",
      "        \n",
      "        self.hist_ts2 = self.addComplexOutput(identifier  = \"hist_ts2\", \n",
      "                                              title       = \"Histogram of the first observations\",\n",
      "                                              formats     = [{'mimeType':'text/xml'}]) \n",
      "        \n",
      "        self.hist_ts3 = self.addComplexOutput(identifier  = \"hist_ts3\", \n",
      "                                              title       = \"Histogram of the first observations\",\n",
      "                                              formats     = [{'mimeType':'text/xml'}]) \n",
      "        \n",
      "        self.hist_ts4 = self.addComplexOutput(identifier  = \"hist_ts4\", \n",
      "                                              title       = \"Histogram of the first observations\",\n",
      "                                              formats     = [{'mimeType':'text/xml'}]) \n",
      "        \n",
      "        self.hist_ts5 = self.addComplexOutput(identifier  = \"hist_ts5\", \n",
      "                                              title       = \"Histogram of the first observations\",\n",
      "                                              formats     = [{'mimeType':'text/xml'}])         \n",
      "\n",
      "\n",
      "    ##\n",
      "    # Execution part of the process\n",
      "    def execute(self):\n",
      "        # Load the data\n",
      "        NAME_1 = str(self.NAME_1.getValue())\n",
      "        NAME_2 = str(self.NAME_2.getValue())\n",
      "        NAME_3 = str(self.NAME_3.getValue())                \n",
      "        \n",
      "        extent = list(self.bboxCounty.getValue())\n",
      "        date = str(self.date.getValue())        \n",
      "        no_observations = int(self.no_observations.getValue())\n",
      "        \n",
      "        # Do the Work\n",
      "        # do something\n",
      "        \n",
      "        # Save to out\n",
      "        self.hist_ts1.setValue( hist_ts1 )\n",
      "        self.hist_ts2.setValue( hist_ts2 )\n",
      "        self.hist_ts3.setValue( hist_ts3 )\n",
      "        self.hist_ts4.setValue( hist_ts4 )\n",
      "        self.hist_ts5.setValue( hist_ts5 )        \n",
      "        return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from datetime import datetime, timedelta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NAME_1 = \"Anhui\"\n",
      "NAME_2 = \"Bengbu\"\n",
      "NAME_3 = \"Guzhen\"\n",
      "extent = [117.04640962322863,33.00404358318741,117.59765626636589,33.50222015793983] # left, bottom, right, top\n",
      "date = \"2014-01-01\"\n",
      "no_observations = 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "j.toordinal()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert all required dates in ISO date format\n",
      "date_start = datetime(int(date[0:4]),int(date[5:7]),int(date[8:10]))\n",
      "date_list = []\n",
      "date_list.append(date_start)\n",
      "for i in range(1,no_observations+1):\n",
      "    #print i\n",
      "    date_list.append(date_start + (i *timedelta(days=8)))\n",
      "\n",
      "# request data use WCS service baed on extend and clip based on sql query\n",
      "array_NDAI = []\n",
      "endpoint='http://192.168.1.104:8080/rasdaman/ows'\n",
      "for j in date_list:\n",
      "    #d = 150842\n",
      "    date_in_string = '\"'+str(j.year)+'-'+str(j.month).zfill(2)+'-'+str(j.day).zfill(2)+'\"'\n",
      "    field={}\n",
      "    field['SERVICE']='WCS'\n",
      "    field['VERSION']='2.0.1'\n",
      "    field['REQUEST']='GetCoverage'\n",
      "    field['COVERAGEID']='NDAI_1km'#'trmm_3b42_coverage_1'\n",
      "    field['SUBSET']=['ansi('+date_in_string+')',#['ansi('+str(d)+')',\n",
      "                     'Lat('+str(extent[1])+','+str(extent[3])+')',\n",
      "                    'Long('+str(extent[0])+','+str(extent[2])+')']\n",
      "    field['FORMAT']='image/tiff'\n",
      "    url_values = urllib.urlencode(field,doseq=True)\n",
      "    full_url = endpoint + '?' + url_values\n",
      "    print full_url\n",
      "    tmpfilename='test'+str(j.toordinal())+'.tif'\n",
      "    f,h = urllib.urlretrieve(full_url,tmpfilename)\n",
      "    print h\n",
      "\n",
      "    #ds=gdal.Open(tmpfilename)\n",
      "    clippedfilename='test'+str(j.toordinal())+'clip.tif' \n",
      "\n",
      "    path_base = \"D:\\Data\\ChinaShapefile\\CHN_adm_gpkg\"\n",
      "    CHN_adm_gpkg = os.path.join(path_base, \"CHN_adm.gpkg\")\n",
      "    \n",
      "    command = [\"gdalwarp\", \"-cutline\", CHN_adm_gpkg, \"-csql\", \"SELECT NAME_3 FROM CHN_adm3 WHERE NAME_1 = \"+NAME_1+\" and NAME_2 = \"+NAME_2+\" and NAME_3 = \"+NAME_3+\"\",\n",
      "               \"-crop_to_cutline\", \"-of\", \"GTiff\", \"-dstnodata\",\"-9999\",tmpfilename, clippedfilename, \"-overwrite\"] # \n",
      "\n",
      "    print (sp.list2cmdline(command))\n",
      "\n",
      "    norm = sp.Popen(sp.list2cmdline(command), shell=True)  \n",
      "    norm.communicate()   \n",
      "\n",
      "    ds=gdal.Open(clippedfilename)\n",
      "    ds_clip = ds.ReadAsArray() \n",
      "    \n",
      "    array_NDAI.append(ds_clip)\n",
      "array_NDAI = np.asarray(array_NDAI)\n",
      "array_NDAI_ma = np.ma.masked_equal(array_NDAI, -9999)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_list=[]\n",
      "bincenters_list=[]\n",
      "for k in range(0,no_observations):\n",
      "    ds_hist_data = array_NDAI[k][array_NDAI[k] != -9999]\n",
      "    y,binEdges=np.histogram(ds_hist_data,bins=100, range=(-1,1), normed=True)\n",
      "    bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
      "    y_list.append(y)\n",
      "    bincenters_list.append(bincenters)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_list[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for l in range(0,no_observations):\n",
      "    plt.plot(bincenters_list[l],y_list[l])\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_hist_data = array_NDAI[0][array_NDAI[0] != -9999]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_hist_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ds_hist_data = array_NDAI[ds_clip != -9999]\n",
      "y,binEdges=np.histogram(ds_hist_data,bins=100, range=(-1,1), normed=True)\n",
      "bincenters = 0.5*(binEdges[1:]+binEdges[:-1])\n",
      "plt.plot(bincenters,y,'-')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "array_NDAI.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "date_start+8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}